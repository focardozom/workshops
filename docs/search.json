[
  {
    "objectID": "COC/coc.html",
    "href": "COC/coc.html",
    "title": "Código de Conducta",
    "section": "",
    "text": "Los asistentes a este taller estamos comprometidos con la creación de un entorno inclusivo, respetuoso y seguro para todas las personas involucradas. Este Código de Conducta establece nuestras expectativas sobre el comportamiento de todos los participantes.\n\n\n\n\nRespeto Mutuo: Trata a todos con respeto y cortesía.\nInclusividad: Promueve un ambiente inclusivo y acogedor para todos los participantes.\nColaboración: Fomenta la colaboración y el trabajo en equipo.\nEscucha Activa: Presta atención a las opiniones y preguntas de otros, y da retroalimentación constructiva.\n\n\n\n\n\nDiscriminación o Acoso: Cualquier forma de discriminación o acoso.\nLenguaje Ofensivo: El uso de lenguaje inapropiado, obsceno o insultante.\nIntimidación: Amenazas, acoso, o cualquier otra forma de intimidación.\n\n\n\n\nCualquier participante que viole este Código de Conducta podría enfrentar medidas que van desde advertencias hasta la expulsión del evento, a discreción de los organizadores.\n\n\n\nSi eres víctima o testigo de un comportamiento inaceptable, informa a los organizadores lo más pronto posible."
  },
  {
    "objectID": "COC/coc.html#introducción",
    "href": "COC/coc.html#introducción",
    "title": "Código de Conducta",
    "section": "",
    "text": "Los asistentes a este taller estamos comprometidos con la creación de un entorno inclusivo, respetuoso y seguro para todas las personas involucradas. Este Código de Conducta establece nuestras expectativas sobre el comportamiento de todos los participantes."
  },
  {
    "objectID": "COC/coc.html#comportamiento-esperado",
    "href": "COC/coc.html#comportamiento-esperado",
    "title": "Código de Conducta",
    "section": "",
    "text": "Respeto Mutuo: Trata a todos con respeto y cortesía.\nInclusividad: Promueve un ambiente inclusivo y acogedor para todos los participantes.\nColaboración: Fomenta la colaboración y el trabajo en equipo.\nEscucha Activa: Presta atención a las opiniones y preguntas de otros, y da retroalimentación constructiva."
  },
  {
    "objectID": "COC/coc.html#comportamientos-inaceptables",
    "href": "COC/coc.html#comportamientos-inaceptables",
    "title": "Código de Conducta",
    "section": "",
    "text": "Discriminación o Acoso: Cualquier forma de discriminación o acoso.\nLenguaje Ofensivo: El uso de lenguaje inapropiado, obsceno o insultante.\nIntimidación: Amenazas, acoso, o cualquier otra forma de intimidación."
  },
  {
    "objectID": "COC/coc.html#medidas-disciplinarias",
    "href": "COC/coc.html#medidas-disciplinarias",
    "title": "Código de Conducta",
    "section": "",
    "text": "Cualquier participante que viole este Código de Conducta podría enfrentar medidas que van desde advertencias hasta la expulsión del evento, a discreción de los organizadores."
  },
  {
    "objectID": "COC/coc.html#informes",
    "href": "COC/coc.html#informes",
    "title": "Código de Conducta",
    "section": "",
    "text": "Si eres víctima o testigo de un comportamiento inaceptable, informa a los organizadores lo más pronto posible."
  },
  {
    "objectID": "archive/2023-11-icfes/2-taller-icfes.html",
    "href": "archive/2023-11-icfes/2-taller-icfes.html",
    "title": "Taller Introducción a Machine Learning en el 14° Seminario Internacional de Investigación sobre la Calidad de la Educación - SiiCE",
    "section": "",
    "text": "Hay muchas formas de estimar modelos en R\n\nlm(formula, data, ...)\nstan_glm(formula, data, family= \"gaussian\",...)\nglmnet(x=matrix, y=vector, family=\"gaussian\",...)\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nlm(): Ajusta un modelo de regresión lineal a los datos.\nstan_glm(): Ajusta un modelo de regresión utilizando el paquete Stan.\nglmnet(): Ajusta un modelo de regresión utilizando la regularización Lasso o Ridge.\n\n\n\nTidymodels ofrece una sintaxis general para estimar los modelos\n\nEspecificar el tipo de modelo\n\nlinear_reg(), logistic_reg(), decition_tree()\n\nEspecificar el tipo de outcome\n\nRegresión para outcomes continuos\nClasificación: multinomial, ordinal, binaria\n\n\n\nlinear_reg() |&gt; \n  set_engine(\"lm\") \n\nLinear Regression Model Specification (regression)\n\nComputational engine: lm \n\nlinear_reg() |&gt; \n    set_engine(\"glmnet\") \n\nLinear Regression Model Specification (regression)\n\nComputational engine: glmnet \n\nlinear_reg() |&gt;\n    set_engine(\"stan\") \n\nLinear Regression Model Specification (regression)\n\nComputational engine: stan \n\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nlibrary(): Carga el paquete tidymodels en R.\ntidymodels_prefer(): Establece el paquete tidymodels como el preferido para las funciones de modelado en R.\nlinear_reg(): Crea una especificación de modelo de regresión lineal en el marco de trabajo tidymodels.\nset_engine(): Establece el motor de cálculo para un objeto de especificación de modelo. Se establece en “lm” para la primera llamada a linear_reg(), “glmnet” para la segunda llamada y “stan” para la tercera.\n\n\n\nPara estimar un modelo hay que hacer los siguientes pasos:\n\n\n\nlm_model &lt;-\n    logistic_reg() %&gt;% \n    set_engine(\"glm\", family=\"binomial\") |&gt;\n    set_mode(\"classification\")\n\nEspecificar un modelo de regresión logística. Se establece el “paquete”, en este caso “glm” y opciones del paquete (la distribución de la variable de respuesta). Además, se establece el modo de modelado en “classification” para indicar que es una variable categórica. El resultado se almacena en el objeto lm_model.\n\n\n\n\nlm_results &lt;- lm_model |&gt;\n    fit(puntaje ~ ., data = taller_icfes)\n\nAquí se ajusta-estima el modelo utilizando la función fit(). Se especifica la variable de respuesta (puntaje) y los predictores (.) y se utiliza el objeto taller_icfes como base de datos.\n\n\n\n\nlm_results |&gt; tidy() \n\n# A tibble: 49 × 5\n   term                                     estimate std.error statistic p.value\n   &lt;chr&gt;                                       &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n 1 (Intercept)                              -1.64       0.500    -3.28   1.03e-3\n 2 fami_personashogar_9                     -0.243      0.0418   -5.82   5.73e-9\n 3 fami_cuartoshogar_92                      0.100      0.161     0.622  5.34e-1\n 4 fami_cuartoshogar_93                      0.230      0.162     1.42   1.56e-1\n 5 fami_cuartoshogar_94                      0.209      0.178     1.18   2.38e-1\n 6 fami_cuartoshogar_95                      0.287      0.224     1.28   1.99e-1\n 7 fami_cuartoshogar_96                      0.0285     0.253     0.113  9.10e-1\n 8 fami_educacionpadre_9No aplica            0.00678    0.158     0.0428 9.66e-1\n 9 fami_educacionpadre_9Primaria            -0.149      0.0894   -1.67   9.57e-2\n10 fami_educacionpadre_9Técnico o Tecnólogo  0.555      0.0921    6.02   1.70e-9\n# ℹ 39 more rows\n\nlm_results |&gt; glance()\n\n# A tibble: 1 × 8\n  null.deviance df.null logLik   AIC   BIC deviance df.residual  nobs\n          &lt;dbl&gt;   &lt;int&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;       &lt;int&gt; &lt;int&gt;\n1         7781.    5888 -3420. 6938. 7265.    6840.        5840  5889\n\n\n\n\ntidy(): Esta función se utiliza para convertir los resultados de un modelo en un marco de datos “ordenado” que muestra los coeficientes del modelo, los errores estándar, los valores t y los valores p para cada variable independiente.\nglance(): Esta función se utiliza para resumir los resultados de un modelo como estadísticas globales del modelo, por ejemplo, R-cuadrado ajustado, el AIC y el BIC.\n\n\n\n\n\n\n\n\nTip\n\n\n\n\n\n\nlm_results |&gt; tidy(exp=TRUE, conf.int=TRUE)\n\n# A tibble: 49 × 7\n   term                  estimate std.error statistic p.value conf.low conf.high\n   &lt;chr&gt;                    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n 1 (Intercept)              0.194    0.500    -3.28   1.03e-3   0.0684     0.494\n 2 fami_personashogar_9     0.784    0.0418   -5.82   5.73e-9   0.722      0.851\n 3 fami_cuartoshogar_92     1.11     0.161     0.622  5.34e-1   0.809      1.52 \n 4 fami_cuartoshogar_93     1.26     0.162     1.42   1.56e-1   0.919      1.74 \n 5 fami_cuartoshogar_94     1.23     0.178     1.18   2.38e-1   0.873      1.75 \n 6 fami_cuartoshogar_95     1.33     0.224     1.28   1.99e-1   0.860      2.07 \n 7 fami_cuartoshogar_96     1.03     0.253     0.113  9.10e-1   0.626      1.69 \n 8 fami_educacionpadre_…    1.01     0.158     0.0428 9.66e-1   0.736      1.37 \n 9 fami_educacionpadre_…    0.862    0.0894   -1.67   9.57e-2   0.722      1.03 \n10 fami_educacionpadre_…    1.74     0.0921    6.02   1.70e-9   1.45       2.09 \n# ℹ 39 more rows\n\n\ntidy(exp=TRUE, conf.int=TRUE): Esta función se utiliza para convertir los resultados de un modelo en un marco de datos “ordenado” que muestra los coeficientes del modelo, los errores estándar, los valores t y los valores p para cada variable independiente. Los argumentos exp y conf.int se utilizan para incluir los intervalos de confianza y los exponentes en los resultados"
  },
  {
    "objectID": "archive/2023-11-icfes/2-taller-icfes.html#estimar-un-modelo",
    "href": "archive/2023-11-icfes/2-taller-icfes.html#estimar-un-modelo",
    "title": "Taller Introducción a Machine Learning en el 14° Seminario Internacional de Investigación sobre la Calidad de la Educación - SiiCE",
    "section": "",
    "text": "Hay muchas formas de estimar modelos en R\n\nlm(formula, data, ...)\nstan_glm(formula, data, family= \"gaussian\",...)\nglmnet(x=matrix, y=vector, family=\"gaussian\",...)\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nlm(): Ajusta un modelo de regresión lineal a los datos.\nstan_glm(): Ajusta un modelo de regresión utilizando el paquete Stan.\nglmnet(): Ajusta un modelo de regresión utilizando la regularización Lasso o Ridge.\n\n\n\nTidymodels ofrece una sintaxis general para estimar los modelos\n\nEspecificar el tipo de modelo\n\nlinear_reg(), logistic_reg(), decition_tree()\n\nEspecificar el tipo de outcome\n\nRegresión para outcomes continuos\nClasificación: multinomial, ordinal, binaria\n\n\n\nlinear_reg() |&gt; \n  set_engine(\"lm\") \n\nLinear Regression Model Specification (regression)\n\nComputational engine: lm \n\nlinear_reg() |&gt; \n    set_engine(\"glmnet\") \n\nLinear Regression Model Specification (regression)\n\nComputational engine: glmnet \n\nlinear_reg() |&gt;\n    set_engine(\"stan\") \n\nLinear Regression Model Specification (regression)\n\nComputational engine: stan \n\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nlibrary(): Carga el paquete tidymodels en R.\ntidymodels_prefer(): Establece el paquete tidymodels como el preferido para las funciones de modelado en R.\nlinear_reg(): Crea una especificación de modelo de regresión lineal en el marco de trabajo tidymodels.\nset_engine(): Establece el motor de cálculo para un objeto de especificación de modelo. Se establece en “lm” para la primera llamada a linear_reg(), “glmnet” para la segunda llamada y “stan” para la tercera.\n\n\n\nPara estimar un modelo hay que hacer los siguientes pasos:\n\n\n\nlm_model &lt;-\n    logistic_reg() %&gt;% \n    set_engine(\"glm\", family=\"binomial\") |&gt;\n    set_mode(\"classification\")\n\nEspecificar un modelo de regresión logística. Se establece el “paquete”, en este caso “glm” y opciones del paquete (la distribución de la variable de respuesta). Además, se establece el modo de modelado en “classification” para indicar que es una variable categórica. El resultado se almacena en el objeto lm_model.\n\n\n\n\nlm_results &lt;- lm_model |&gt;\n    fit(puntaje ~ ., data = taller_icfes)\n\nAquí se ajusta-estima el modelo utilizando la función fit(). Se especifica la variable de respuesta (puntaje) y los predictores (.) y se utiliza el objeto taller_icfes como base de datos.\n\n\n\n\nlm_results |&gt; tidy() \n\n# A tibble: 49 × 5\n   term                                     estimate std.error statistic p.value\n   &lt;chr&gt;                                       &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n 1 (Intercept)                              -1.64       0.500    -3.28   1.03e-3\n 2 fami_personashogar_9                     -0.243      0.0418   -5.82   5.73e-9\n 3 fami_cuartoshogar_92                      0.100      0.161     0.622  5.34e-1\n 4 fami_cuartoshogar_93                      0.230      0.162     1.42   1.56e-1\n 5 fami_cuartoshogar_94                      0.209      0.178     1.18   2.38e-1\n 6 fami_cuartoshogar_95                      0.287      0.224     1.28   1.99e-1\n 7 fami_cuartoshogar_96                      0.0285     0.253     0.113  9.10e-1\n 8 fami_educacionpadre_9No aplica            0.00678    0.158     0.0428 9.66e-1\n 9 fami_educacionpadre_9Primaria            -0.149      0.0894   -1.67   9.57e-2\n10 fami_educacionpadre_9Técnico o Tecnólogo  0.555      0.0921    6.02   1.70e-9\n# ℹ 39 more rows\n\nlm_results |&gt; glance()\n\n# A tibble: 1 × 8\n  null.deviance df.null logLik   AIC   BIC deviance df.residual  nobs\n          &lt;dbl&gt;   &lt;int&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;       &lt;int&gt; &lt;int&gt;\n1         7781.    5888 -3420. 6938. 7265.    6840.        5840  5889\n\n\n\n\ntidy(): Esta función se utiliza para convertir los resultados de un modelo en un marco de datos “ordenado” que muestra los coeficientes del modelo, los errores estándar, los valores t y los valores p para cada variable independiente.\nglance(): Esta función se utiliza para resumir los resultados de un modelo como estadísticas globales del modelo, por ejemplo, R-cuadrado ajustado, el AIC y el BIC.\n\n\n\n\n\n\n\n\nTip\n\n\n\n\n\n\nlm_results |&gt; tidy(exp=TRUE, conf.int=TRUE)\n\n# A tibble: 49 × 7\n   term                  estimate std.error statistic p.value conf.low conf.high\n   &lt;chr&gt;                    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n 1 (Intercept)              0.194    0.500    -3.28   1.03e-3   0.0684     0.494\n 2 fami_personashogar_9     0.784    0.0418   -5.82   5.73e-9   0.722      0.851\n 3 fami_cuartoshogar_92     1.11     0.161     0.622  5.34e-1   0.809      1.52 \n 4 fami_cuartoshogar_93     1.26     0.162     1.42   1.56e-1   0.919      1.74 \n 5 fami_cuartoshogar_94     1.23     0.178     1.18   2.38e-1   0.873      1.75 \n 6 fami_cuartoshogar_95     1.33     0.224     1.28   1.99e-1   0.860      2.07 \n 7 fami_cuartoshogar_96     1.03     0.253     0.113  9.10e-1   0.626      1.69 \n 8 fami_educacionpadre_…    1.01     0.158     0.0428 9.66e-1   0.736      1.37 \n 9 fami_educacionpadre_…    0.862    0.0894   -1.67   9.57e-2   0.722      1.03 \n10 fami_educacionpadre_…    1.74     0.0921    6.02   1.70e-9   1.45       2.09 \n# ℹ 39 more rows\n\n\ntidy(exp=TRUE, conf.int=TRUE): Esta función se utiliza para convertir los resultados de un modelo en un marco de datos “ordenado” que muestra los coeficientes del modelo, los errores estándar, los valores t y los valores p para cada variable independiente. Los argumentos exp y conf.int se utilizan para incluir los intervalos de confianza y los exponentes en los resultados"
  },
  {
    "objectID": "archive/2023-11-icfes/2-taller-icfes.html#dividir-los-datos",
    "href": "archive/2023-11-icfes/2-taller-icfes.html#dividir-los-datos",
    "title": "Taller Introducción a Machine Learning en el 14° Seminario Internacional de Investigación sobre la Calidad de la Educación - SiiCE",
    "section": "Dividir los datos",
    "text": "Dividir los datos\n\nDividir los datos en dos conjuntos\n\nEntrenamiento\n\nLa mayoría de los datos (¿70%, 80%?)\nAquí se ajusta el modelo\n\nPrueba\n\nUn pequeño conjunto de datos\nAquí se evaluará el modelo final\n\n\n\nLos datos de prueba se utilizan una sola vez, si se utilizan más de una vez, se convierten en parte del proceso de entrenamiento.\n\n\n\n\n\n\nWarning\n\n\n\nLa división de los datos se hace al nivel de unidad independiente de observación.\nEvitar a toda costa la contaminación del los datos de prueba (information leakage), es decir, no se puede filtrar la información de una base a la otra.\n\n\nEntonces, uno puede crear dos bases de datos con por ejemplo 80% y 20% de los datos. Pero, ¿cómo se hace esto en R?\n\nset.seed(1234)\n\ndatos_divididos &lt;- initial_split(taller_icfes, prop = 0.8, strata = \"puntaje\")\n\ndatos_entrenamiento &lt;- training(datos_divididos)\ndatos_prueba &lt;- testing(datos_divididos)\n\nLa opción strata es para que los datos de entrenamiento y prueba tengan la misma distribución de la variable puntaje\nA veces la selección aleatoria de la muestra es problemática, por ejemplo cuando hay una componente de tiempo en los datos. En este caso, se puede usar la función initial_time_split().\n\n\n\n\n\n\nTip\n\n\n\nset.seed(): se utiliza para establecer una semilla para la generación de números aleatorios en R. En este caso, se utiliza para establecer la semilla en 1234, lo que garantiza que los resultados sean reproducibles. Esto es especialmente importante cuando se trabaja con modelos de aprendizaje automático, ya que los resultados pueden variar según la semilla utilizada para la generación de números aleatorios.\ninitial_split(): Esta función se utiliza para dividir un data frame o tibble en conjuntos de entrenamiento y prueba. En este caso, se utiliza para dividir el objeto “taller_icfes” en conjuntos de entrenamiento y prueba en una proporción de 80/20, y estratificando por la columna “puntaje”.\ntraining(): Esta función se utiliza para extraer el conjunto de entrenamiento de un objeto creado con la función initial_split(). En este caso, se utiliza para extraer el conjunto de entrenamiento del objeto “datos_divididos”.\ntesting(): Esta función se utiliza para extraer el conjunto de prueba de un objeto creado con la función initial_split(). En este caso, se utiliza para extraer el conjunto de prueba del objeto “datos_divididos”.\n\n\nAhora, podemos repetir la estimación del modelo anterior, pero solo vamos a necesitar los pasos 2 y 3."
  },
  {
    "objectID": "archive/2023-11-icfes/2-taller-icfes.html#estimar-el-modelo-1",
    "href": "archive/2023-11-icfes/2-taller-icfes.html#estimar-el-modelo-1",
    "title": "Taller Introducción a Machine Learning en el 14° Seminario Internacional de Investigación sobre la Calidad de la Educación - SiiCE",
    "section": "2. Estimar el modelo",
    "text": "2. Estimar el modelo\nEstimación del modelo: Se utiliza la función lm_model() y fit() para ajustar un modelo de regresión lineal. La fórmula puntaje ~ . indica que se está modelando la variable puntaje como una función de todas las otras variables en el dataframe “datos_entrenamiento”.\n\nlm_results &lt;- lm_model |&gt;\n    fit(puntaje ~ ., data = datos_entrenamiento)"
  },
  {
    "objectID": "archive/2023-11-icfes/2-taller-icfes.html#visualizar-los-resultados-del-modelo",
    "href": "archive/2023-11-icfes/2-taller-icfes.html#visualizar-los-resultados-del-modelo",
    "title": "Taller Introducción a Machine Learning en el 14° Seminario Internacional de Investigación sobre la Calidad de la Educación - SiiCE",
    "section": "3. Visualizar los resultados del modelo",
    "text": "3. Visualizar los resultados del modelo\nVisualizar los resultados del modelo: Se utiliza la función tidy para obtener un resumen limpio y ordenado de los resultados del modelo. En el segundo uso de tidy, se exponencian los coeficientes y los intervalos de confianza.\n\nlm_results |&gt; tidy()\n\n# A tibble: 49 × 5\n   term                                     estimate std.error statistic p.value\n   &lt;chr&gt;                                       &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n 1 (Intercept)                               -1.68      0.524    -3.21   1.31e-3\n 2 fami_personashogar_9                      -0.261     0.0474   -5.50   3.76e-8\n 3 fami_cuartoshogar_92                       0.197     0.186     1.06   2.90e-1\n 4 fami_cuartoshogar_93                       0.358     0.187     1.91   5.62e-2\n 5 fami_cuartoshogar_94                       0.332     0.205     1.62   1.05e-1\n 6 fami_cuartoshogar_95                       0.485     0.255     1.90   5.74e-2\n 7 fami_cuartoshogar_96                       0.117     0.286     0.411  6.81e-1\n 8 fami_educacionpadre_9No aplica             0.0173    0.177     0.0979 9.22e-1\n 9 fami_educacionpadre_9Primaria             -0.0868    0.0992   -0.875  3.81e-1\n10 fami_educacionpadre_9Técnico o Tecnólogo   0.574     0.103     5.57   2.54e-8\n# ℹ 39 more rows\n\n\nPero,\n¿Cómo sabemos que el modelo es bueno?"
  },
  {
    "objectID": "archive/2023-11-icfes/2-taller-icfes.html#evaluar-el-modelo",
    "href": "archive/2023-11-icfes/2-taller-icfes.html#evaluar-el-modelo",
    "title": "Taller Introducción a Machine Learning en el 14° Seminario Internacional de Investigación sobre la Calidad de la Educación - SiiCE",
    "section": "4. Evaluar el modelo",
    "text": "4. Evaluar el modelo\nEvaluación del modelo: se hace una “predicción” utilizando el modelo ajustado. Primero, se seleccionan algunos valores de datos_entrenamiento para predecir. Luego, se utiliza la función predict para obtener las predicciones del modelo. En el segundo uso de predict, se solicita la probabilidad de las predicciones.\n\npredecir_estos_valores &lt;- datos_entrenamiento %&gt;% \n    select(-puntaje) %&gt;% \n    slice(1:10)\n\npredict(lm_results, predecir_estos_valores)\n\n# A tibble: 10 × 1\n   .pred_class\n   &lt;fct&gt;      \n 1 0          \n 2 0          \n 3 0          \n 4 0          \n 5 0          \n 6 0          \n 7 1          \n 8 0          \n 9 0          \n10 0          \n\n\n\npredict(lm_results, predecir_estos_valores, type=\"prob\")\n\n# A tibble: 10 × 2\n   .pred_0 .pred_1\n     &lt;dbl&gt;   &lt;dbl&gt;\n 1   0.923  0.0766\n 2   0.633  0.367 \n 3   0.772  0.228 \n 4   0.849  0.151 \n 5   0.703  0.297 \n 6   0.676  0.324 \n 7   0.475  0.525 \n 8   0.537  0.463 \n 9   0.700  0.300 \n10   0.788  0.212"
  },
  {
    "objectID": "archive/2023-11-icfes/2-taller-icfes.html#predicción-en-el-conjunto-completo-de-datos",
    "href": "archive/2023-11-icfes/2-taller-icfes.html#predicción-en-el-conjunto-completo-de-datos",
    "title": "Taller Introducción a Machine Learning en el 14° Seminario Internacional de Investigación sobre la Calidad de la Educación - SiiCE",
    "section": "Predicción en el conjunto completo de datos",
    "text": "Predicción en el conjunto completo de datos\nAhora vamos a realizar una predicción en todo el conjunto de datos de entrenamiento y los vamos a unir con los datos de entrenamiento originales. Luego, vamos a seleccionar y reordenar las columnas.\n\nentrenamiento &lt;- datos_entrenamiento %&gt;% \n    select(-puntaje)\n\nprediccion &lt;- predict(lm_results, entrenamiento)\n\nresultados_prueba &lt;- cbind(prediccion, datos_entrenamiento) |&gt; \n  select(.pred_class, puntaje, everything()) |&gt; \n  tibble()\n\nresultados_prueba  |&gt;  head(10)\n\n# A tibble: 10 × 16\n   .pred_class puntaje fami_personashogar_9 fami_cuartoshogar_9\n   &lt;fct&gt;       &lt;fct&gt;                  &lt;dbl&gt; &lt;chr&gt;              \n 1 0           0                          5 4                  \n 2 0           0                          3 3                  \n 3 0           0                          4 4                  \n 4 0           0                          4 3                  \n 5 0           0                          5 5                  \n 6 0           0                          5 3                  \n 7 1           0                          3 3                  \n 8 0           0                          4 4                  \n 9 0           0                          3 2                  \n10 0           0                          3 3                  \n# ℹ 12 more variables: fami_educacionpadre_9 &lt;chr&gt;,\n#   fami_educacionmadre_9 &lt;chr&gt;, fami_tienecomputador_9 &lt;chr&gt;,\n#   fami_tienelavadora_9 &lt;chr&gt;, fami_tienehornomicroogas_9 &lt;chr&gt;,\n#   fami_tieneautomovil_9 &lt;chr&gt;, fami_tieneconsolavideojuegos_9 &lt;chr&gt;,\n#   fami_tieneinternet_9 &lt;chr&gt;, fami_tieneserviciotv_9 &lt;chr&gt;,\n#   fami_trabajolaborpadre_9 &lt;chr&gt;, fami_trabajolabormadre_9 &lt;chr&gt;,\n#   fami_numlibros_9 &lt;chr&gt;"
  },
  {
    "objectID": "archive/2023-11-icfes/2-taller-icfes.html#métricas-para-evaluar-el-modelo",
    "href": "archive/2023-11-icfes/2-taller-icfes.html#métricas-para-evaluar-el-modelo",
    "title": "Taller Introducción a Machine Learning en el 14° Seminario Internacional de Investigación sobre la Calidad de la Educación - SiiCE",
    "section": "Métricas para evaluar el modelo",
    "text": "Métricas para evaluar el modelo\nAccuracy (Exactitud): Es una métrica que mide la proporción de predicciones correctas realizadas por un modelo en comparación con el total de predicciones realizadas. Es decir, la cantidad de veces que el modelo acertó sobre el total de datos que se le presentaron.\nSensitivity (Sensibilidad): Es la proporción de verdaderos positivos (TP) que son identificados correctamente por el modelo en relación con el total de verdaderos positivos y falsos negativos (FN). La sensibilidad mide la capacidad del modelo para detectar correctamente los casos positivos.\nSpecificity (Especificidad): Es la proporción de verdaderos negativos (TN) que son identificados correctamente por el modelo en relación con el total de verdaderos negativos y falsos positivos (FP). La especificidad mide la capacidad del modelo para detectar correctamente los casos negativos.\nPrecision (Precisión): Es la proporción de verdaderos positivos (TP) que son identificados correctamente por el modelo en relación con el total de verdaderos positivos y falsos positivos (FP). La precisión mide la capacidad del modelo para no identificar falsamente un caso como positivo.\nRecall (Recuperación): Es la proporción de verdaderos positivos (TP) que son identificados correctamente por el modelo en relación con el total de verdaderos positivos y falsos negativos (FN). El recall mide la capacidad del modelo para identificar todos los casos positivos.\nF-measure (Puntuación F): Es una métrica que combina la precisión y el recall en una sola puntuación. El valor de la F-measure oscila entre 0 y 1, siendo 1 el valor óptimo.\nKappa (Coeficiente Kappa): Es una medida de concordancia que compara la cantidad de acuerdos observados entre el modelo y las observaciones reales con la cantidad de acuerdos que se esperarían por casualidad. Un valor de kappa cercano a 1 indica una concordancia casi perfecta entre el modelo y las observaciones reales.\nMatthews Correlation Coefficient (Coeficiente de Correlación de Matthews): Es una medida que se utiliza para evaluar la calidad de la clasificación binaria. El coeficiente de correlación de Matthews oscila entre -1 y 1, siendo 1 el valor óptimo. Un valor cercano a 1 indica una clasificación perfecta, mientras que un valor cercano a -1 indica una clasificación completamente incorrecta."
  },
  {
    "objectID": "archive/2023-11-icfes/2-taller-icfes.html#calcular-las-métricas",
    "href": "archive/2023-11-icfes/2-taller-icfes.html#calcular-las-métricas",
    "title": "Taller Introducción a Machine Learning en el 14° Seminario Internacional de Investigación sobre la Calidad de la Educación - SiiCE",
    "section": "Calcular las métricas",
    "text": "Calcular las métricas\n\nconf_mat(resultados_prueba, truth = puntaje,\n         estimate = .pred_class)\n\n          Truth\nPrediction    0    1\n         0 2522  990\n         1  430  768\n\naccuracy(resultados_prueba, truth = puntaje,\n         estimate = .pred_class)\n\n# A tibble: 1 × 3\n  .metric  .estimator .estimate\n  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;\n1 accuracy binary         0.699\n\nsens(resultados_prueba, truth = puntaje,\n    estimate = .pred_class, \n    event_level = \"second\")\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 sens    binary         0.437\n\nspec(resultados_prueba, truth = puntaje,\n    estimate = .pred_class, \n    event_level = \"second\")\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 spec    binary         0.854\n\nprecision(resultados_prueba, truth = puntaje,\n    estimate = .pred_class,\n    event_level = \"second\")\n\n# A tibble: 1 × 3\n  .metric   .estimator .estimate\n  &lt;chr&gt;     &lt;chr&gt;          &lt;dbl&gt;\n1 precision binary         0.641\n\nrecall(resultados_prueba, truth = puntaje,\n    estimate = .pred_class,\n    event_level = \"second\")\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 recall  binary         0.437\n\nkap(resultados_prueba, truth = puntaje,\n    estimate = .pred_class,\n    event_level = \"second\")\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 kap     binary         0.311\n\n\nTambién se pueden calcular con menos repetición del código\n\ncustom_metrics &lt;- metric_set(accuracy, sens, spec, precision, recall, f_meas, kap, mcc)\n\ncustom_metrics(resultados_prueba,\n  truth = puntaje,\n  estimate = .pred_class,\n  event_level = \"second\"\n)\n\n# A tibble: 8 × 3\n  .metric   .estimator .estimate\n  &lt;chr&gt;     &lt;chr&gt;          &lt;dbl&gt;\n1 accuracy  binary         0.699\n2 sens      binary         0.437\n3 spec      binary         0.854\n4 precision binary         0.641\n5 recall    binary         0.437\n6 f_meas    binary         0.520\n7 kap       binary         0.311\n8 mcc       binary         0.323\n\n\nY las podemos guardar en una tabla.\n\nlm_metrics &lt;- custom_metrics(resultados_prueba,\n  truth = puntaje,\n  estimate = .pred_class,\n  event_level = \"second\"\n) |&gt;\n  mutate(model = \"lm\")"
  },
  {
    "objectID": "archive/2023-11-icfes/2-taller-icfes.html#área-bajo-la-curva",
    "href": "archive/2023-11-icfes/2-taller-icfes.html#área-bajo-la-curva",
    "title": "Taller Introducción a Machine Learning en el 14° Seminario Internacional de Investigación sobre la Calidad de la Educación - SiiCE",
    "section": "Área bajo la curva",
    "text": "Área bajo la curva\nLa función roc_auc() se utiliza para calcular el área bajo la curva (AUC) de la curva (ROC).\nLa curva ROC es una representación gráfica de la sensibilidad frente a la especificidad para un sistema clasificador binario.\nEl AUC es una métrica de rendimiento para los modelos de clasificación. Su valor varía de 0 a 1, donde un valor de 1 indica que el modelo tiene una capacidad de clasificación perfecta, mientras que un valor de 0.5 indica que el modelo no tiene capacidad de clasificación, es decir, clasifica al azar.\nEn general, un modelo se considera bueno si el AUC es 0.7 o superior. Sin embargo, esto puede variar dependiendo del contexto y del problema específico que se esté abordando.\n\nprediccion_auc &lt;- predict(lm_results, entrenamiento, type = \"prob\")\n\nresultados_prueba_auc &lt;- cbind(prediccion_auc, datos_entrenamiento) |&gt;\n  tibble()\n\nroc_auc(resultados_prueba_auc,\n  truth = puntaje,\n  `.pred_1`,\n  event_level = \"second\"\n)\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 roc_auc binary         0.728\n\n\nY se puede crear una gráfica\n\nroc_curve(resultados_prueba_auc,\nevent_level = \"second\",\n  truth = puntaje,\n  .pred_1\n) |&gt; autoplot()\n\n\n\n\nAhora, ¿cómo podemos mejorar el modelo?"
  },
  {
    "objectID": "archive/2023-11-icfes/2-taller-icfes.html#árboles-de-decisión",
    "href": "archive/2023-11-icfes/2-taller-icfes.html#árboles-de-decisión",
    "title": "Taller Introducción a Machine Learning en el 14° Seminario Internacional de Investigación sobre la Calidad de la Educación - SiiCE",
    "section": "Árboles de decisión",
    "text": "Árboles de decisión\nLos árboles de decisión son un tipo de modelo de aprendizaje automático que se utiliza para resolver problemas de clasificación y regresión. El objetivo es tomar decisiones basadas en preguntas y respuestas que se hacen a los datos para llegar a una conclusión o predicción. En un árbol de decisión, cada punto o “nodo” representa una característica de los datos que estamos estudiando. Cada “rama” del árbol muestra una respuesta posible a esa característica."
  },
  {
    "objectID": "archive/2023-11-icfes/2-taller-icfes.html#arbusto",
    "href": "archive/2023-11-icfes/2-taller-icfes.html#arbusto",
    "title": "Taller Introducción a Machine Learning en el 14° Seminario Internacional de Investigación sobre la Calidad de la Educación - SiiCE",
    "section": "Arbusto",
    "text": "Arbusto\nPara estimar un árbol pequeño, hay que seguir los mismos pasos que para estimar un modelo de regresión logística, como hicimos anteriormente.\n\nEspecificación del modelo: Se especifica un modelo de árbol de decisión con un parámetro de complejidad de 0. Se utiliza el paquete rpart y se establece el modo en classification.\n\n\ntree_spec &lt;- \n  decision_tree(cost_complexity= 0.01) |&gt; \n  set_engine(\"rpart\") |&gt; \n  set_mode(\"classification\") \n\n\nAjuste del modelo: Se ajusta el modelo de árbol de decisión utilizando la fórmula puntaje ~ ., lo que significa que se está modelando puntaje como una función de todas las otras variables en el dataframe taller_icfes.\n\n\ntree_results &lt;- tree_spec |&gt;\n    fit(puntaje ~ ., data = taller_icfes)\n\n\nVisualización del árbol de decisión: Se extrae el modelo ajustado del resultado del ajuste y se visualiza utilizando la función tree_diagram del paquete treemisc.\n\n\ncart_tree_fit &lt;- tree_results$fit\n\ntreemisc::tree_diagram(cart_tree_fit, roundint = FALSE)\n\n\n\n\n¿Cómo se decide por dónde cortar los datos en un árbol de decisión? ver esto"
  },
  {
    "objectID": "archive/2023-11-icfes/2-taller-icfes.html#árboles-de-clasificación-y-regresión-cart",
    "href": "archive/2023-11-icfes/2-taller-icfes.html#árboles-de-clasificación-y-regresión-cart",
    "title": "Taller Introducción a Machine Learning en el 14° Seminario Internacional de Investigación sobre la Calidad de la Educación - SiiCE",
    "section": "Árboles de clasificación y regresión (CART)",
    "text": "Árboles de clasificación y regresión (CART)\nAhora, que ya sabemos cómo se construye el árbol, utilicemos todos los datos.\nPaso 1. Especificar el modelo\n\ntree_spec &lt;- \n  decision_tree() |&gt; \n  set_mode(\"classification\") |&gt; \n  set_engine(\"rpart\")\n\nPaso 2. Estimar el modelo\n\ntree_results &lt;- tree_spec |&gt;\n  fit(puntaje ~ ., data = datos_entrenamiento)\n\nAhora, vamos a pasar a evaluar el model.\n\nentrenamiento &lt;- datos_entrenamiento %&gt;%\n  select(-puntaje)\n\nprediccion_tree &lt;- predict(tree_results, entrenamiento)\n\nresultados_prueba_tree &lt;- cbind(prediccion_tree, datos_entrenamiento) |&gt;\n  tibble()\n\nY calculemos las métricas\n\ntree_metrics &lt;- custom_metrics(resultados_prueba_tree,\n  truth = puntaje,\n  estimate = .pred_class, \n  event_level= \"second\"\n) |&gt;\n  mutate(model = \"tree\")\n\nrbind(tree_metrics, lm_metrics) |&gt;\n  pivot_wider(names_from = model, values_from = .estimate)\n\n# A tibble: 8 × 4\n  .metric   .estimator  tree    lm\n  &lt;chr&gt;     &lt;chr&gt;      &lt;dbl&gt; &lt;dbl&gt;\n1 accuracy  binary     0.678 0.699\n2 sens      binary     0.296 0.437\n3 spec      binary     0.906 0.854\n4 precision binary     0.652 0.641\n5 recall    binary     0.296 0.437\n6 f_meas    binary     0.408 0.520\n7 kap       binary     0.227 0.311\n8 mcc       binary     0.261 0.323"
  },
  {
    "objectID": "archive/2023-11-icfes/2-taller-icfes.html#cart-con-hiperparámetros",
    "href": "archive/2023-11-icfes/2-taller-icfes.html#cart-con-hiperparámetros",
    "title": "Taller Introducción a Machine Learning en el 14° Seminario Internacional de Investigación sobre la Calidad de la Educación - SiiCE",
    "section": "CART con hiperparámetros",
    "text": "CART con hiperparámetros\nLos hiperparámetros son valores específicos para los modelos que se pueden ajustar y que permiten controlar el proceso de entrenamiento de un modelo.\n\ntree_spec &lt;- \n  decision_tree(min_n = 5, cost_complexity = 0.001) |&gt; \n  set_mode(\"classification\") |&gt; \n  set_engine(\"rpart\")\n\nEn este caso, se están indicando dos hiperparámetros para el modelo de árbol de decisión:\n\nmin_n: Es el número mínimo de observaciones que se requieren para dividir un nodo en un árbol de decisión. Un valor más alto de min_n implica que el árbol será menos profundo, ya que se requerirán más muestras para realizar una división en cada nodo.\ncost_complexity: Es un parámetro de regularización. Es una medida de la penalización que se aplica al árbol en función de su complejidad. Un valor más alto de cost_complexity implica una penalización más fuerte en la complejidad del árbol, lo que lleva a un árbol más pequeño y menos profundo.\n\nAhora, a estimar el modelo\n\ntree2_results &lt;- tree_spec |&gt;\n    fit(puntaje ~ ., data = datos_entrenamiento)\n\nPodemos obtener las predicciones\n\ntree2_predicciones &lt;- predict(tree2_results, entrenamiento)\n\nresultados_prueba_tree2 &lt;- cbind(tree2_predicciones, datos_entrenamiento) |&gt;\n  tibble()\n\ntree2_metrics &lt;- custom_metrics(resultados_prueba_tree2,\n  truth = puntaje,\n  estimate = .pred_class,\n  event_level = \"second\"\n) |&gt;\n  mutate(model = \"tree2\")\n\nY finalmente, podemos comparar los modelos\n\nrbind(tree2_metrics, tree_metrics, lm_metrics) |&gt;\n  pivot_wider(names_from = model, values_from = .estimate)\n\n# A tibble: 8 × 5\n  .metric   .estimator tree2  tree    lm\n  &lt;chr&gt;     &lt;chr&gt;      &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 accuracy  binary     0.773 0.678 0.699\n2 sens      binary     0.572 0.296 0.437\n3 spec      binary     0.892 0.906 0.854\n4 precision binary     0.760 0.652 0.641\n5 recall    binary     0.572 0.296 0.437\n6 f_meas    binary     0.653 0.408 0.520\n7 kap       binary     0.489 0.227 0.311\n8 mcc       binary     0.500 0.261 0.323"
  },
  {
    "objectID": "archive/2023-11-icfes/2-taller-icfes.html#pero-todo-esto-pasa-en-los-datos-de-prueba",
    "href": "archive/2023-11-icfes/2-taller-icfes.html#pero-todo-esto-pasa-en-los-datos-de-prueba",
    "title": "Taller Introducción a Machine Learning en el 14° Seminario Internacional de Investigación sobre la Calidad de la Educación - SiiCE",
    "section": "¡Pero todo esto pasa en los datos de prueba!",
    "text": "¡Pero todo esto pasa en los datos de prueba!"
  },
  {
    "objectID": "archive/2023-11-icfes/2-taller-icfes.html#por-qué-es-malo",
    "href": "archive/2023-11-icfes/2-taller-icfes.html#por-qué-es-malo",
    "title": "Taller Introducción a Machine Learning en el 14° Seminario Internacional de Investigación sobre la Calidad de la Educación - SiiCE",
    "section": "¿Por qué es malo?",
    "text": "¿Por qué es malo?\nUno puede crear un modelo que tenga cerro error en los datos de prueba. Pero, ¿cómo sabemos que el modelo es bueno?\n\n# Seleccionar el valor del puntaje\ndatos_prueba2_out &lt;- \n  datos_prueba |&gt; \n    select(puntaje) \n\n# Utilizar los datos de prueba para predecir el puntaje utilizando el modelo de regresión logística  \nlm_predicciones &lt;- cbind(predict(lm_results, datos_prueba), datos_prueba2_out)|&gt; mutate(model=\"lm\")\n\n# Utilizar los datos de prueba para predecir el puntaje utilizando el modelo de árbol de decisión\ntree_predicciones &lt;- cbind(predict(tree_results, datos_prueba), datos_prueba2_out)|&gt; mutate(model=\"tree\")\n\n\n# Utilizar los datos de prueba para predecir el puntaje utilizando el modelo de árbol de decisión con hiperparámetros\ntree2_predicciones &lt;- cbind(predict(tree2_results, datos_prueba), datos_prueba2_out) |&gt;  mutate(model=\"tree2\")\n\n# Unir los resultados\nall_models &lt;- \nrbind(lm_predicciones, tree_predicciones, tree2_predicciones) \n\n# all_models\n\nFinalmente, podemos comparar las métricas de los modelos.\n\nall_models2 &lt;- all_models |&gt; \n  group_split(model) %&gt;%\n   setNames(unique(all_models$model)) %&gt;%\n  map_dfr(., ~custom_metrics(.x,\n               truth = puntaje,\n               estimate = .pred_class), .id = \"names\")\n\nall_models2 |&gt; \n  pivot_wider(names_from = names, values_from = .estimate)\n\n# A tibble: 8 × 5\n  .metric   .estimator    lm  tree tree2\n  &lt;chr&gt;     &lt;chr&gt;      &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 accuracy  binary     0.703 0.686 0.681\n2 sens      binary     0.869 0.926 0.827\n3 spec      binary     0.425 0.284 0.436\n4 precision binary     0.717 0.685 0.711\n5 recall    binary     0.869 0.926 0.827\n6 f_meas    binary     0.786 0.787 0.765\n7 kap       binary     0.316 0.238 0.279\n8 mcc       binary     0.332 0.282 0.286"
  },
  {
    "objectID": "archive/2023-11-icfes/2-taller-icfes.html#cómo-vamos-a-elegir-el-mejor-modelo-si-solo-podemos-evaluar-un-modelo-en-los-datos-de-prueba",
    "href": "archive/2023-11-icfes/2-taller-icfes.html#cómo-vamos-a-elegir-el-mejor-modelo-si-solo-podemos-evaluar-un-modelo-en-los-datos-de-prueba",
    "title": "Taller Introducción a Machine Learning en el 14° Seminario Internacional de Investigación sobre la Calidad de la Educación - SiiCE",
    "section": "¿Cómo vamos a elegir el mejor modelo si solo podemos evaluar un modelo en los datos de prueba?",
    "text": "¿Cómo vamos a elegir el mejor modelo si solo podemos evaluar un modelo en los datos de prueba?\n\nSegunda idea: dividir los datos de entrenamiento en dos grupos, uno para entrenar y otro para validar, de tal manera que podamos estimar el error del modelo en los datos de prueba."
  },
  {
    "objectID": "archive/2023-11-icfes/2-taller-icfes.html#validación-cruzada",
    "href": "archive/2023-11-icfes/2-taller-icfes.html#validación-cruzada",
    "title": "Taller Introducción a Machine Learning en el 14° Seminario Internacional de Investigación sobre la Calidad de la Educación - SiiCE",
    "section": "Validación Cruzada",
    "text": "Validación Cruzada\nSupongamos que estamos trabajando en un problema de clasificación y disponemos de un conjunto de datos con 1000 observaciones. Queremos evaluar el rendimiento de un modelo de regresión logística utilizando la validación cruzada k-fold.\nPaso a paso del proceso de k-fold cross-validation:\nDividir el conjunto de datos: Primero, dividimos el conjunto de datos en k subconjuntos (folds) de igual tamaño. En este ejemplo, elegimos k=10, lo que significa que dividimos el conjunto de datos en 10 subconjuntos de 100 registros cada uno.\nEntrenar y evaluar el modelo: Luego, realizamos lo siguiente para cada uno de los k subconjuntos:\n\nTomamos un subconjunto como el conjunto de prueba (validación) y los k-1 subconjuntos restantes como el conjunto de entrenamiento. Por ejemplo, en la primera iteración, usamos el primer subconjunto como conjunto de prueba y los subconjuntos del 2 al 10 como conjunto de entrenamiento.\nEntrenamos el modelo de regresión logística utilizando el conjunto de entrenamiento.\nEvaluamos el rendimiento del modelo en el conjunto de prueba utilizando una métrica adecuada, como la precisión, la exhaustividad o el F1-score. Anotamos el resultado de la métrica para esta iteración.\n\nPromediar los resultados: Después de completar las k iteraciones, calculamos la media de los resultados de la métrica para todas las iteraciones. Esta media nos proporciona una estimación más robusta del rendimiento del modelo, ya que el modelo ha sido evaluado en diferentes subconjuntos del conjunto de datos.\nMás información aquí y aquí"
  },
  {
    "objectID": "archive/2023-11-icfes/2-taller-icfes.html#cart-con-hiperparametros-y-validación-cruzada",
    "href": "archive/2023-11-icfes/2-taller-icfes.html#cart-con-hiperparametros-y-validación-cruzada",
    "title": "Taller Introducción a Machine Learning en el 14° Seminario Internacional de Investigación sobre la Calidad de la Educación - SiiCE",
    "section": "CART con hiperparametros y validación cruzada",
    "text": "CART con hiperparametros y validación cruzada\nLo primero que vamos a necesitar es crear un objecto en R que contenga los datos organizados de tal manera que podamos implementar la validación cruzada. Para esto, vamos a utilizar la función vfold_cv() del paquete rsample.\n\ncrossvalidation &lt;-\n  vfold_cv(datos_entrenamiento, \n           v = 5,  # número de cajas\n           strata = \"puntaje\")\n\nAhora, vamos a especificar el modelo. Cuando se especifica un modelo de árbol de decisión, vamos a indicar que queremos que se prueben diferentes valores de los hiperparámetros “min_n” y “cost_complexity”. Para eso, vamos a utilizar el paquete tune.\n\ntree_spec &lt;- \n  decision_tree(\n    cost_complexity = tune(), \n    tree_depth = tune(),\n    min_n = tune()\n  ) |&gt; \n  set_mode(\"classification\") |&gt; \n  set_engine(\"rpart\")\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nCost_complexity: Cost_complexity es un parámetro de regularización. Es una medida de la penalización que se aplica al árbol en función de su complejidad. Un valor más alto de cost_complexity implica una penalización más fuerte en la complejidad del árbol, lo que lleva a un árbol más pequeño y menos profundo. La idea es encontrar un valor óptimo de cost_complexity que equilibre la precisión y la complejidad del árbol, reduciendo tanto el sesgo como la varianza.\nTree_depth (profundidad del árbol): Tree_depth se refiere a la longitud máxima del camino más largo desde la raíz hasta una hoja en un árbol de decisión. Un árbol más profundo es más complejo y puede capturar relaciones más complicadas en los datos. Sin embargo, un árbol demasiado profundo también puede ser propenso al sobreajuste, ya que puede adaptarse demasiado a las peculiaridades de los datos de entrenamiento.\nmin_n (mínimo número de muestras para dividir un nodo): Min_n es un parámetro que controla el número mínimo de datos requeridas para dividir un nodo en un árbol de decisión. Un valor más alto de min_n implica que el árbol será menos profundo, ya que se requerirán más muestras para realizar una división en cada nodo. Un valor más bajo de min_n permite que el árbol se divida más fácilmente y, por lo tanto, puede resultar en un árbol más complejo y profundo.\n\n\n\nAhora, vamos a especificar la rejilla de búsqueda. La rejilla de búsqueda es una tabla que contiene los valores que se van a probar para cada combinación de hiperparámetros.\n\ntree_grid &lt;- grid_regular(\n    cost_complexity(range = c(-10L, -1L)), \n    tree_depth (range = c(4L, 7L)), \n    min_n(range = c(10L, 30L)))\n\nEl siguiente paso es estimar el desempeño de los modelos en los datos de validación, utilizando los modelos creados con las diferentes combinaciones de hiperparámetros. Para esto, vamos a utilizar la función tune_grid() del paquete tune.\n\ndoParallel::registerDoParallel()\n\nset.seed(345)\ntree_rs &lt;-\n  tune_grid(\n    tree_spec,\n    puntaje ~ .,\n    resamples = crossvalidation,\n    grid = tree_grid,\n    metrics = metric_set(accuracy, roc_auc, sensitivity, specificity)\n  )\n\ndoParallel::stopImplicitCluster()\n\n\n\n\n\n\n\nTip\n\n\n\n\n\ndoParallel es un excelente paquete creado para facilitar la programación paralela en R. Utilizar R en “paralelo” permite aprovechar la potencia de los computadores para ahorrar tiempo.\n\n\n\nEsto nos va a dar una tabla con los resultados de cada modelo, y podemos pedir que nos muestre la combinación de hiperparámetros que tuvo el mejor desempeño.\n\nshow_best(tree_rs)\n\nWarning: No value of `metric` was given; metric 'accuracy' will be used.\n\n\n# A tibble: 5 × 9\n  cost_complexity tree_depth min_n .metric  .estimator  mean     n std_err\n            &lt;dbl&gt;      &lt;int&gt; &lt;int&gt; &lt;chr&gt;    &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt;\n1    0.0000000001          4    10 accuracy binary     0.673     5 0.00434\n2    0.00000316            4    10 accuracy binary     0.673     5 0.00434\n3    0.0000000001          4    20 accuracy binary     0.673     5 0.00434\n4    0.00000316            4    20 accuracy binary     0.673     5 0.00434\n5    0.0000000001          4    30 accuracy binary     0.673     5 0.00434\n# ℹ 1 more variable: .config &lt;chr&gt;\n\n\nY podemos visualizar los resultados\n\nautoplot(tree_rs)\n\n\n\n\nFinalmente, podemos seleccionar el mejor modelo y estimarlo con los datos de entrenamiento.\n\nsimpler_tree &lt;- select_best(tree_rs, min_n, metric = \"accuracy\")\n\nfinal_tree &lt;- finalize_model(tree_spec, simpler_tree)\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nLa función finalize_model permite actualizar la especificación del modelo con los hiperparámetros seleccionados.\n\n\n\nAhora, volvemos a hacer lo que hemos estado haciendo: estimar el modelo con los datos de entrenamiento.\n\nfinal_fit &lt;- fit(final_tree, puntaje ~ ., datos_entrenamiento)\n\nYa sabemos cómo evaluar el modelo, así que vamos a hacerlo. Para eso, vamos a utilizar la función last_fit(), que va a hacer un montón de trabajo por nosotros. Esta función va a estimar el modelo con los datos de entrenamiento y va a calcular las métricas de evaluación en los datos de entrenamiento y prueba.\n\nfinal_cart &lt;- last_fit(final_tree, puntaje ~ ., datos_divididos,\n  metrics = metric_set(accuracy, roc_auc, sensitivity, specificity),\n  control = control_grid(event_level = \"second\")\n)\n\nWarning: Unknown or uninitialised column: `.extracts`.\n\n\nY podemos recolectar las métricas\n\ncollect_metrics(final_cart)\n\n# A tibble: 4 × 4\n  .metric     .estimator .estimate .config             \n  &lt;chr&gt;       &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               \n1 accuracy    binary         0.683 Preprocessor1_Model1\n2 sensitivity binary         0.332 Preprocessor1_Model1\n3 specificity binary         0.892 Preprocessor1_Model1\n4 roc_auc     binary         0.632 Preprocessor1_Model1\n\n\n¿Y podemos visualizar el árbol?\n\nfinal_cart &lt;- last_fit(final_tree, puntaje ~ ., datos_divididos,\n  metrics = metric_set(accuracy, roc_auc, sensitivity, specificity))\n\ncart_trained &lt;- \n  final_cart  |&gt; extract_fit_parsnip()\n\ncart_tree_fit &lt;- cart_trained$fit\n\ntreemisc::tree_diagram(cart_tree_fit, roundint=FALSE)\n\nWarning: labs do not fit even at cex 0.15, there may be some overplotting\n\n\n\n\n\n\nExtra idea: los árboles son muy buenos para aprender la distribuación de los datos de prueba, pero a veces, tienden a sobre especializarse en los datos en los que son entrenados. Una forma de solucionar esto, es hacer muchos árboles, que podamos después promediar."
  },
  {
    "objectID": "archive/2023-11-icfes/2-taller-icfes.html#random-forest",
    "href": "archive/2023-11-icfes/2-taller-icfes.html#random-forest",
    "title": "Taller Introducción a Machine Learning en el 14° Seminario Internacional de Investigación sobre la Calidad de la Educación - SiiCE",
    "section": "Random Forest",
    "text": "Random Forest\nYa sabemos por qué es Forest, pero ¿por qué es random?\n\nNúmero de predictores que se usan para cada árbol (mtry)\nNúmero de observaciones por árbol\n\n\nRandom Forest\nLos pasos son los mismo, solo cambia la especificación del modelo.\n\nrf_spec &lt;- \n  rand_forest()  |&gt; \n  set_mode(\"classification\") |&gt; \n  set_engine(\"ranger\", importance = \"permutation\")\n\nHay algunos métodos para tratar de identificar cuáles fueron las variables más relevantes en el momento de hacer las mejores predicciones.\n\nrf_results &lt;- rf_spec |&gt; \nfit(puntaje ~ ., data = datos_entrenamiento)\n\nlibrary(vip)\nimportance_plot_rf &lt;- \n  rf_results |&gt; \n  vip() +\n  ggtitle(\"Random Forest\") +\n  theme_minimal() +\n  geom_bar(stat=\"identity\", \n  color=\"green\", fill=\"green\", alpha=0.2)\n\nAhora, a recolectar métricas.\n\nrf_predicciones &lt;- predict(rf_results, entrenamiento)\n\nresultados_rf &lt;- cbind(rf_predicciones,datos_entrenamiento) |&gt; \n  tibble()\n\nrf_metrics &lt;- custom_metrics(resultados_rf,\n               truth = puntaje,\n               estimate = .pred_class,\n               event_level= \"second\") |&gt;\n  mutate(model=\"rf\")\n\nY a comparar los modelos\n\nrbind(rf_metrics, tree2_metrics, tree_metrics, lm_metrics) |&gt; \n  pivot_wider(names_from = model, values_from = .estimate)\n\n# A tibble: 8 × 6\n  .metric   .estimator    rf tree2  tree    lm\n  &lt;chr&gt;     &lt;chr&gt;      &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 accuracy  binary     0.868 0.773 0.678 0.699\n2 sens      binary     0.711 0.572 0.296 0.437\n3 spec      binary     0.962 0.892 0.906 0.854\n4 precision binary     0.918 0.760 0.652 0.641\n5 recall    binary     0.711 0.572 0.296 0.437\n6 f_meas    binary     0.801 0.653 0.408 0.520\n7 kap       binary     0.705 0.489 0.227 0.311\n8 mcc       binary     0.718 0.500 0.261 0.323\n\n\nLa ley es que los datos de prueba se utilizan solo una vez, pero los hemos utilizado muchas veces. Veamos por última vez, cómo se comportaron los modelos en la base de prueba.\n\nrf_predicciones &lt;- cbind(predict(rf_results, datos_prueba), datos_prueba2_out) |&gt;  mutate(model=\"rf\")\n\nall_models &lt;- \nrbind(lm_predicciones, rf_predicciones,tree_predicciones, tree2_predicciones) \n\n\nall_models2 &lt;- all_models |&gt; \n  group_split(model) %&gt;%\n   setNames(unique(all_models$model)) %&gt;%\n  map_dfr(., ~custom_metrics(.x,\n               truth = puntaje,\n               estimate = .pred_class,\n               event_level= \"second\"), .id = \"names\")\nall_models2 |&gt; \n  pivot_wider(names_from = names, values_from = .estimate)\n\n# A tibble: 8 × 6\n  .metric   .estimator    lm    rf  tree tree2\n  &lt;chr&gt;     &lt;chr&gt;      &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 accuracy  binary     0.703 0.684 0.686 0.681\n2 sens      binary     0.425 0.386 0.284 0.436\n3 spec      binary     0.869 0.861 0.926 0.827\n4 precision binary     0.658 0.623 0.694 0.6  \n5 recall    binary     0.425 0.386 0.284 0.436\n6 f_meas    binary     0.517 0.477 0.403 0.505\n7 kap       binary     0.316 0.268 0.238 0.279\n8 mcc       binary     0.332 0.283 0.282 0.286"
  },
  {
    "objectID": "archive/2023-11-icfes/2-taller-icfes.html#sesgo-y-varianza",
    "href": "archive/2023-11-icfes/2-taller-icfes.html#sesgo-y-varianza",
    "title": "Taller Introducción a Machine Learning en el 14° Seminario Internacional de Investigación sobre la Calidad de la Educación - SiiCE",
    "section": "Sesgo y varianza",
    "text": "Sesgo y varianza\nEstos dos conceptos son cruciales para entender el equilibrio entre la complejidad del modelo y su capacidad para generalizar a nuevos datos.\nSesgo (Bias): a. Definición: El sesgo es la diferencia entre la predicción promedio de nuestro modelo y el valor verdadero que intentamos predecir.El sesgo, en términos estadísticos, se refiere a la diferencia sistemática entre la esperanza (o promedio) de las estimaciones que produce un estimador y el valor real del parámetro que se desea estimar. Un modelo con alta varianza es muy sensible a pequeñas variaciones en los datos de entrenamiento, lo que puede resultar en un sobreajuste. Es decir, el modelo se ajusta muy bien a los datos de entrenamiento, pero tiene un rendimiento deficiente en datos no vistos o de prueba.\n\nEjemplo: Un modelo de regresión lineal simple podría tener un alto sesgo si los datos reales tienen una relación no lineal.\nImplicaciones: Un modelo con alto sesgo es demasiado simple y no captura la estructura subyacente de los datos. Esto conduce a un bajo rendimiento en el conjunto de entrenamiento y prueba.\n\nVarianza (Variance): a. Definición: La varianza es la cantidad de variabilidad en las predicciones del modelo para un dato. b. Ejemplo: Un modelo de árbol de decisión muy profundo podría tener alta varianza, ya que es muy sensible a pequeñas variaciones en los datos de entrenamiento. c. Implicaciones: Un modelo con alta varianza tiende a sobreajustarse a los datos de entrenamiento, lo que resulta en un buen rendimiento en el conjunto de entrenamiento pero un bajo rendimiento en el conjunto de prueba.\nEl objetivo en Machine Learning es equilibrar el sesgo y la varianza para minimizar el error de predicción general en el modelo a. Objetivo: Encontrar un equilibrio entre sesgo y varianza que minimice el error total de predicción. b. Estrategias: Seleccionar un modelo con la complejidad adecuada, usar técnicas de regularización, y validar el modelo con conjuntos de datos de entrenamiento y prueba separados.\n\nTercera idea: en Machine Learning todo se trata de encontrar el mejor balance entre el sesgo y la varianza del modelo."
  },
  {
    "objectID": "archive/2023-11-icfes/2-taller-icfes.html#formas-de-disminur-el-sesgo",
    "href": "archive/2023-11-icfes/2-taller-icfes.html#formas-de-disminur-el-sesgo",
    "title": "Taller Introducción a Machine Learning en el 14° Seminario Internacional de Investigación sobre la Calidad de la Educación - SiiCE",
    "section": "Formas de disminur el sesgo",
    "text": "Formas de disminur el sesgo\nAumentar la complejidad del modelo: Un modelo más complejo puede capturar mejor la estructura subyacente de los datos. Por ejemplo, en lugar de utilizar una regresión lineal simple, podrías probar una regresión polinomial o un modelo de árbol de decisión.\nAñadir más variables: A veces, el sesgo puede ser el resultado de no tener en cuenta variables importantes que influyen en la variable objetivo. Añadir más variables relevantes puede ayudar a reducir el sesgo del modelo.\nUtilizar técnicas de “ingeniería de predictores”: Transformar o combinar las variables existentes para crear nuevas características puede ayudar a capturar mejor la relación entre las variables de entrada y salida. Por ejemplo, si estás trabajando en un problema de predicción de precios de viviendas, podrías crear una nueva característica que represente la relación entre el tamaño de la casa y el número de habitaciones.\nAumentar el tamaño del conjunto de datos: Si tu conjunto de datos es pequeño o no es representativo de la población general, es posible que el modelo tenga un sesgo alto. Aumentar el tamaño del conjunto de datos y asegurarte de que es representativo puede ayudar a reducir el sesgo.\nUtilizar ensembles de modelos: Combinar varios modelos en un ensemble puede ayudar a reducir el sesgo, ya que cada modelo puede capturar diferentes aspectos de la relación entre las variables de entrada y salida. Por ejemplo, puedes utilizar métodos de ensemble como Bagging, Boosting o Stacking."
  },
  {
    "objectID": "archive/2023-11-icfes/2-taller-icfes.html#técnicas-para-reducir-la-varianza",
    "href": "archive/2023-11-icfes/2-taller-icfes.html#técnicas-para-reducir-la-varianza",
    "title": "Taller Introducción a Machine Learning en el 14° Seminario Internacional de Investigación sobre la Calidad de la Educación - SiiCE",
    "section": "Técnicas para reducir la varianza",
    "text": "Técnicas para reducir la varianza\nReducir la complejidad del modelo: Un modelo más simple tiende a tener una menor varianza y es menos propenso al sobreajuste. Por ejemplo, podrías limitar la profundidad de un árbol de decisión.\nUtilizar regularización: La regularización es una técnica que añade una penalización a los coeficientes del modelo para evitar que se ajusten demasiado a los datos de entrenamiento.Por ejemplo, regularización L1 (Lasso) y L2 (Ridge).\nAumentar el tamaño del conjunto de datos: Si dispones de más datos, el modelo será menos sensible a pequeñas variaciones en los datos de entrenamiento y tendrá una menor varianza.\nEliminar características ruidosas: Si tu modelo incluye características que no están relacionadas con la variable objetivo o que contienen mucho ruido, estas pueden aumentar la varianza del modelo. Realizar un análisis de importancia de características y eliminar las características poco importantes puede ayudar a reducir la varianza.\nValidación cruzada (cross-validation): Utilizar la validación cruzada, como k-fold cross-validation, te permite evaluar el rendimiento del modelo en diferentes subconjuntos del conjunto de datos de entrenamiento. Esto puede ayudarte a identificar si el modelo está sobreajustando los datos y ajustar la complejidad del modelo en consecuencia.\nUtilizar diferentes modelos: Combinar varios modelos en un ensemble puede ayudar a reducir la varianza, ya que la variabilidad de cada modelo individual se promedia. Por ejemplo, puedes utilizar métodos de ensemble como Bagging (Bootstrap Aggregating) o Random Forest, que promedian las predicciones de múltiples árboles de decisión entrenados en subconjuntos aleatorios de los datos."
  },
  {
    "objectID": "archive/2023-10-Unal/index.html",
    "href": "archive/2023-10-Unal/index.html",
    "title": "Taller en la Universidad Nacional",
    "section": "",
    "text": "Este taller se llevará a cabo en la Universidad Nacional de Colombia el día 30 de octubre. En esta página pueden encontrar las diapositivas y otra información relevante para el taller."
  },
  {
    "objectID": "archive/2023-10-Unal/index.html#organizadores",
    "href": "archive/2023-10-Unal/index.html#organizadores",
    "title": "Taller en la Universidad Nacional",
    "section": "Organizadores",
    "text": "Organizadores\nFrancisco Cardozo.\nKaren Forero. Universidad Nacional.\nRoberto Posada. Universidad Nacional."
  },
  {
    "objectID": "archive/2023-03-Uniandes/index.html",
    "href": "archive/2023-03-Uniandes/index.html",
    "title": "Bienvenidos",
    "section": "",
    "text": "Le damos la bienvenida a este taller que se llevará a cabo en la Universidad de los Andes los días 26 y 27 de marzo. En el taller nos enfocaremos en algunas de las técnicas de aprendizaje automático más utilizadas en la actualidad. En esta página, hemos compilado todos los materiales necesarios para cada sesión, incluidas las diapositivas. Esperamos que estos recursos diseñados especialmente para ustedes sean de su agrado.\nEn este taller vamos a trabajar sobre tres ideas principales:\n\nEstimar del error de generalización.\nSeparar el error entre sesgo y varianza.\nRegularización."
  },
  {
    "objectID": "archive/2023-03-Uniandes/index.html#pasos-previos-al-taller",
    "href": "archive/2023-03-Uniandes/index.html#pasos-previos-al-taller",
    "title": "Bienvenidos",
    "section": "Pasos Previos al Taller",
    "text": "Pasos Previos al Taller\nPara aprovechar al máximo este taller, es necesario completar las siguientes tareas antes de que inicie el evento:\n\nCreación de una cuenta en Posit Cloud: Si aún no tienes una, por favor, crea una cuenta gratuita en Posit Cloud.\n\nEsperamos que este taller sea una experiencia enriquecedora para todos. Si tienen preguntas o inquietudes previas al evento, no duden en contactarnos."
  },
  {
    "objectID": "archive/2023-03-Uniandes/index.html#agenda-del-workshop",
    "href": "archive/2023-03-Uniandes/index.html#agenda-del-workshop",
    "title": "Bienvenidos",
    "section": "Agenda del Workshop",
    "text": "Agenda del Workshop\n\nDía 1\n\nIntroducción a Machine Learning\nProcesamiento de datos\nRegresión logística\nÁrboles de decisión\n\n\n\nDía 2\n\nRandom Forest\nRegresión lineal\nRegularización\n\n\n\nOrganizadores\n\nFrancisco Cardozo (foc9@miami.edu)\nMaría Fernanda Reyes\nEric C. Brown"
  },
  {
    "objectID": "archive/2023-03-Uniandes/index.html#día-1-1",
    "href": "archive/2023-03-Uniandes/index.html#día-1-1",
    "title": "Bienvenidos",
    "section": "Día 1",
    "text": "Día 1\n\n\nIntroducción\n\n\nPreprocesamiento de datos\n\n\nRegresión logística\n\n\nÁrboles de decisión"
  },
  {
    "objectID": "archive/2023-03-Uniandes/index.html#día-2-1",
    "href": "archive/2023-03-Uniandes/index.html#día-2-1",
    "title": "Bienvenidos",
    "section": "Día 2",
    "text": "Día 2\n\n\nRandom Forest\n\n\nRegresión\n\n\nRegularización"
  },
  {
    "objectID": "archive/2023-03-Uniandes/6-regresion.html#sesgo-y-varianza",
    "href": "archive/2023-03-Uniandes/6-regresion.html#sesgo-y-varianza",
    "title": "6. Regresión",
    "section": "Sesgo y varianza",
    "text": "Sesgo y varianza\nEstos dos conceptos son cruciales para entender el equilibrio entre la complejidad del modelo y su capacidad para generalizar a nuevos datos.\nSesgo (Bias): a. Definición: El sesgo es la diferencia entre la predicción promedio de nuestro modelo y el valor verdadero que intentamos predecir.El sesgo, en términos estadísticos, se refiere a la diferencia sistemática entre la esperanza (o promedio) de las estimaciones que produce un estimador y el valor real del parámetro que se desea estimar. Un modelo con alta varianza es muy sensible a pequeñas variaciones en los datos de entrenamiento, lo que puede resultar en un sobreajuste. Es decir, el modelo se ajusta muy bien a los datos de entrenamiento, pero tiene un rendimiento deficiente en datos no vistos o de prueba.\n\nEjemplo: Un modelo de regresión lineal simple podría tener un alto sesgo si los datos reales tienen una relación no lineal.\nImplicaciones: Un modelo con alto sesgo es demasiado simple y no captura la estructura subyacente de los datos. Esto conduce a un bajo rendimiento en el conjunto de entrenamiento y prueba.\n\nVarianza (Variance): a. Definición: La varianza es la cantidad de variabilidad en las predicciones del modelo para un punto de datos dado. b. Ejemplo: Un modelo de árbol de decisión muy profundo podría tener alta varianza, ya que es muy sensible a pequeñas variaciones en los datos de entrenamiento. c. Implicaciones: Un modelo con alta varianza tiende a sobreajustarse a los datos de entrenamiento, lo que resulta en un buen rendimiento en el conjunto de entrenamiento pero un bajo rendimiento en el conjunto de prueba.\nEl objetivo en Machine Learning es equilibrar el sesgo y la varianza para minimizar el error de predicción general en el modelo\n\nObjetivo: Encontrar un equilibrio entre sesgo y varianza que minimice el error total de predicción.\nEstrategias: Seleccionar un modelo con la complejidad adecuada, usar técnicas de regularización, y validar el modelo con conjuntos de datos de entrenamiento y prueba separados.\n\nFormas de disminur el sesgo\nAumentar la complejidad del modelo: Un modelo más complejo puede capturar mejor la estructura subyacente de los datos. Por ejemplo, en lugar de utilizar una regresión lineal simple, podrías probar una regresión polinomial o un modelo de árbol de decisión.\nAñadir más variables: A veces, el sesgo puede ser el resultado de no tener en cuenta variables importantes que influyen en la variable objetivo. Añadir más variables relevantes puede ayudar a reducir el sesgo del modelo.\nUtilizar técnicas de “ingeniería de predictores”: Transformar o combinar las variables existentes para crear nuevas características puede ayudar a capturar mejor la relación entre las variables de entrada y salida. Por ejemplo, si estás trabajando en un problema de predicción de precios de viviendas, podrías crear una nueva característica que represente la relación entre el tamaño de la casa y el número de habitaciones.\nAumentar el tamaño del conjunto de datos: Si tu conjunto de datos es pequeño o no es representativo de la población general, es posible que el modelo tenga un sesgo alto. Aumentar el tamaño del conjunto de datos y asegurarte de que es representativo puede ayudar a reducir el sesgo.\nUtilizar ensembles de modelos: Combinar varios modelos en un ensemble puede ayudar a reducir el sesgo, ya que cada modelo puede capturar diferentes aspectos de la relación entre las variables de entrada y salida. Por ejemplo, puedes utilizar métodos de ensemble como Bagging, Boosting o Stacking."
  },
  {
    "objectID": "archive/2023-03-Uniandes/6-regresion.html#técnicas-para-reducir-la-varianza",
    "href": "archive/2023-03-Uniandes/6-regresion.html#técnicas-para-reducir-la-varianza",
    "title": "6. Regresión",
    "section": "Técnicas para reducir la varianza",
    "text": "Técnicas para reducir la varianza\nReducir la complejidad del modelo: Un modelo más simple tiende a tener una menor varianza y es menos propenso al sobreajuste. Por ejemplo, podrías limitar la profundidad de un árbol de decisión.\nUtilizar regularización: La regularización es una técnica que añade una penalización a los coeficientes del modelo para evitar que se ajusten demasiado a los datos de entrenamiento.Por ejemplo, regularización L1 (Lasso) y L2 (Ridge).\nAumentar el tamaño del conjunto de datos: Si dispones de más datos, el modelo será menos sensible a pequeñas variaciones en los datos de entrenamiento y tendrá una menor varianza.\nEliminar características ruidosas: Si tu modelo incluye características que no están relacionadas con la variable objetivo o que contienen mucho ruido, estas pueden aumentar la varianza del modelo. Realizar un análisis de importancia de características y eliminar las características poco importantes puede ayudar a reducir la varianza.\n\nValidación cruzada (cross-validation): Utilizar la validación cruzada, como k-fold cross-validation, te permite evaluar el rendimiento del modelo en diferentes subconjuntos del conjunto de datos de entrenamiento. Esto puede ayudarte a identificar si el modelo está sobreajustando los datos y ajustar la complejidad del modelo en consecuencia.\nUtilizar diferentes modelos: Combinar varios modelos en un ensemble puede ayudar a reducir la varianza, ya que la variabilidad de cada modelo individual se promedia. Por ejemplo, puedes utilizar métodos de ensemble como Bagging (Bootstrap Aggregating) o Random Forest, que promedian las predicciones de múltiples árboles de decisión entrenados en subconjuntos aleatorios de los datos.\n\n\n\nMachine Learning"
  },
  {
    "objectID": "archive/2023-03-Uniandes/4-arboles.html#árboles-de-decisión",
    "href": "archive/2023-03-Uniandes/4-arboles.html#árboles-de-decisión",
    "title": "4. Árboles de decisión",
    "section": "Árboles de decisión",
    "text": "Árboles de decisión\n(mejorar esto) El objetivo es tomar una serie de decisiones, basadas en las respuestas a cada pregunta, para llegar a una conclusión o predicción final. Cada nodo del árbol representa una característica de los datos que se están analizando y cada rama representa una posible respuesta a esa característica.\nLos árboles de decisión son útiles porque proporcionan una forma fácil de visualizar y entender cómo se toman las decisiones en un modelo"
  },
  {
    "objectID": "archive/2023-03-Uniandes/4-arboles.html#arbusto",
    "href": "archive/2023-03-Uniandes/4-arboles.html#arbusto",
    "title": "4. Árboles de decisión",
    "section": "Arbusto",
    "text": "Arbusto\n\nmi_primer_arbol &lt;- los_datos |&gt; \n  select(\"PYALC\", \"GETALC\", \"GENDER\", \"GRADE\")\n\n\ntree_spec &lt;- \n  decision_tree() |&gt; \n  set_mode(\"classification\") |&gt; \n  set_engine(\"rpart\")\n\n\ntree_results &lt;- tree_spec |&gt;\n    fit(PYALC ~ ., data = mi_primer_arbol)\n\n\ncart_tree_fit &lt;- tree_results$fit\n\ntreemisc::tree_diagram(cart_tree_fit, roundint = FALSE)\n\nhttps://mlu-explain.github.io/decision-tree/\nÁrboles de clasificación y regresión (CART)\n\ntree_spec &lt;- \n  decision_tree() |&gt; \n  set_mode(\"classification\") |&gt; \n  set_engine(\"rpart\")\n\n\ntree_results &lt;- tree_spec |&gt;\n  fit(PYALC ~ ., data = datos_entrenamiento)\n\n\npredict(tree_results, predecir_estos_valores)\n\nentrenamiento &lt;- datos_entrenamiento %&gt;%\n  select(-PYALC)\n\nprediccion_tree &lt;- predict(tree_results, entrenamiento)\n\nresultados_prueba_tree &lt;- cbind(prediccion_tree, datos_entrenamiento) |&gt;\n  tibble()\n\n\ncustom_metrics(resultados_prueba_tree,\n  truth = PYALC,\n  estimate = .pred_class\n) |&gt;\n  mutate(model = \"tree\")\n\ntree_metrics &lt;- custom_metrics(resultados_prueba_tree,\n  truth = PYALC,\n  estimate = .pred_class\n) |&gt;\n  mutate(model = \"tree\")\n\nrbind(tree_metrics, lm_metrics) |&gt;\n  pivot_wider(names_from = model, values_from = .estimate)"
  },
  {
    "objectID": "archive/2023-03-Uniandes/4-arboles.html#por-qué-es-malo",
    "href": "archive/2023-03-Uniandes/4-arboles.html#por-qué-es-malo",
    "title": "4. Árboles de decisión",
    "section": "¿Por qué es malo?",
    "text": "¿Por qué es malo?\n\ndatos_prueba2_out &lt;- \n  datos_prueba |&gt; \n    select(PYALC) \n  \nlm_predicciones &lt;- cbind(predict(lm_results, datos_prueba), datos_prueba2_out)|&gt; mutate(model=\"lm\")\n\ntree_predicciones &lt;- cbind(predict(tree_results, datos_prueba), datos_prueba2_out)|&gt; mutate(model=\"tree\")\n\ntree2_predicciones &lt;- cbind(predict(tree2_results, datos_prueba), datos_prueba2_out) |&gt;  mutate(model=\"tree2\")\n\nall_models &lt;- \nrbind(lm_predicciones, tree_predicciones, tree2_predicciones) \n\nall_models\n\n\nall_models2 &lt;- all_models |&gt; \n  group_split(model) %&gt;%\n   setNames(unique(all_models$model)) %&gt;%\n  map_dfr(., ~custom_metrics(.x,\n               truth = PYALC,\n               estimate = .pred_class), .id = \"names\")\n\nall_models2 |&gt; \n  pivot_wider(names_from = names, values_from = .estimate)"
  },
  {
    "objectID": "archive/2023-03-Uniandes/2-procesamiento.html#nuevos-rumbos",
    "href": "archive/2023-03-Uniandes/2-procesamiento.html#nuevos-rumbos",
    "title": "2. Procesamiento de datos con tidyverse",
    "section": "Nuevos Rumbos",
    "text": "Nuevos Rumbos\n::: {.r-fit-text}\nIntroducción\n\nOrganización sin ánimo de lucro: Enfocada en la investigación y prevención de problemas sociales.\nÁreas de Interés: Consumo de sustancias, delincuencia, y violencia.\nAlcance Geográfico: Colombia y América Latina.\n\nFundación y Trayectoria\n\nEstablecida en Bogotá: Octubre de 2002.\nTrayectoria: Más de dos décadas comprometidas con la prevención y la investigación.\n\nColaboraciones y Alianzas\n\nOrganizaciones Locales: Alcaldías y gobernaciones, Ministerios de Salud y de Justicia, Instituto Colombiano de Bienestar Familiar.\nOrganizaciones Internacionales: Organización Panamericana de la Salud, Comisión Europea, CICAD/OEA.\nInstituciones Académicas: Universidades de New Jersey, Washington, y Miami.\n\nMás información aquí\n:::"
  },
  {
    "objectID": "archive/2023-03-Uniandes/2-procesamiento.html#base-de-datos",
    "href": "archive/2023-03-Uniandes/2-procesamiento.html#base-de-datos",
    "title": "2. Procesamiento de datos con tidyverse",
    "section": "Base de datos",
    "text": "Base de datos\n\nFactores de riesgo y de protección\n\nDisponibilidad percibida de drogas\nActitudes de la comunidad frente al consumo de drogas\nActitudes de los padres frente al consumo de drogas\nInvolucramiento en actividades comunitarias\n\nConsumo de alcohol y otras drogas\n\nConsumo de alcohol en la vida, 12 meses últimos 30 días\nHaber estado en una pelea\n\nCaracterísticas demográficas\n\nEdad\nSexo\nGrado"
  },
  {
    "objectID": "archive/2023-03-Uniandes/2-procesamiento.html#importar-la-base-de-datos",
    "href": "archive/2023-03-Uniandes/2-procesamiento.html#importar-la-base-de-datos",
    "title": "2. Procesamiento de datos con tidyverse",
    "section": "Importar la base de datos",
    "text": "Importar la base de datos\n\nlibrary(tidyverse)\nlibrary()\nlos_datos &lt;- readRDS(\"DATA/base_NR.rds\") |&gt; \n             as_tibble()\n\n\n\n\n\n\n\n\nTip\n\n\n\nreadRDS(): esta función se utiliza para leer un archivo de datos en formato RDS. En este caso, se utiliza para leer el archivo “base_NR.rds” y almacenar los datos en un objeto llamado “los_datos”.\n|&gt;:se puede leer como “siguiente”. Este operador se utiliza para encadenar varias operaciones juntas en una sola línea de código. En este caso, se utiliza para encadenar la función readRDS() a la función as_tibble().\nas_tibble(): esta función se utiliza para convertir un objeto en un tibble, que es una versión mejorada de un data frame en R. En este caso, se utiliza para convertir el objeto “los_datos” en un tibble."
  },
  {
    "objectID": "archive/2023-03-Uniandes/2-procesamiento.html#explorar-los-datos",
    "href": "archive/2023-03-Uniandes/2-procesamiento.html#explorar-los-datos",
    "title": "2. Procesamiento de datos con tidyverse",
    "section": "Explorar los datos",
    "text": "Explorar los datos\n\nlos_datos %&gt;% \n  glimpse()\n\n ::: {.callout-tip}\n\nglimpse(): Esta función se utiliza para imprimir una vista previa de los datos, incluyendo el tipo de datos de cada columna y las primeras filas de los datos. En este caso, se utiliza para explorar los datos almacenados en el objeto “los_datos”.\n\n:::"
  },
  {
    "objectID": "archive/2023-03-Uniandes/2-procesamiento.html#select",
    "href": "archive/2023-03-Uniandes/2-procesamiento.html#select",
    "title": "2. Procesamiento de datos con tidyverse",
    "section": "select()",
    "text": "select()\nEsta función selecciona columnas de una base de datos.\nEn este ejemplo, quiero una nueva base de datos que tenga la variable NHPROUD (“Hay gente en mi barrio que se siente orgullosa de mí cuando hago algo bien”)\n\nlos_datos |&gt; \n  select(NHPROUD) |&gt;\n  distinct()\n\n ::: {.callout-tip}\n\nselect(): Esta función se utiliza para seleccionar columnas específicas de un data frame o tibble. En este caso, se utiliza para seleccionar la columna “NHPROUD” del objeto “los_datos”.\ndistinct(): Esta función se utiliza para eliminar filas duplicadas de un data frame o tibble. En este caso, se utiliza para eliminar filas duplicadas de la columna “NHPROUD” del objeto “los_datos”.\n\n:::"
  },
  {
    "objectID": "archive/2023-03-Uniandes/2-procesamiento.html#select-1",
    "href": "archive/2023-03-Uniandes/2-procesamiento.html#select-1",
    "title": "2. Procesamiento de datos con tidyverse",
    "section": "select()",
    "text": "select()\nEn este ejemplo voy a seleccionar las variables GENDER, AWRMAR, AWRALC, AWRCIG\n\nGENDER: Sexo\n\n“Qué tan mal ven la mayoría de los adultos de tu barrio (aquellos más cercanos a ti) el que los jóvenes de tu edad…”\n\nAWRMAR = fumen marihuana\nAWRALC = Consuman alcohol\nAWRCIG = fumen cigarrillo\n\n\nlos_datos |&gt; \n  select(GENDER, AWRMAR, AWRALC, AWRCIG)"
  },
  {
    "objectID": "archive/2023-03-Uniandes/2-procesamiento.html#mutate",
    "href": "archive/2023-03-Uniandes/2-procesamiento.html#mutate",
    "title": "2. Procesamiento de datos con tidyverse",
    "section": "mutate()",
    "text": "mutate()\nEsta función crea una nueva variable -añade una nueva columna a la base de datos- o tranforma una variable que esté presente en la base de datos.\nPor ejemplo, si quiero transformar las tres variables del ejemplo anterior para asignar un puntaje de las percepciones de los estudiantes sobre las creencias de los adultos…\n¿Qué debo hacer?\n\nTransformar el texto que hay en la base por los valores: 1, 2, 3 y 4.\nCrear una nueva variable que calcule la media de los puntajes."
  },
  {
    "objectID": "archive/2023-03-Uniandes/2-procesamiento.html#mutate-1",
    "href": "archive/2023-03-Uniandes/2-procesamiento.html#mutate-1",
    "title": "2. Procesamiento de datos con tidyverse",
    "section": "mutate()",
    "text": "mutate()\n\nlos_datos |&gt; \n  select(AWRMAR, AWRALC, AWRCIG) |&gt; \n  mutate(AWRMAR = case_when(\n    AWRMAR == \"Muy mal\" ~ 1,\n    AWRMAR == \"Mal\" ~ 2,\n    AWRMAR == \"Notan mal\" ~ 3,\n    AWRMAR == \"Para nada mal\" ~ 4,\n   TRUE ~ NA\n  ))\n\nlos_datos |&gt; \n  select(AWRMAR, AWRALC, AWRCIG) |&gt; \n  mutate(across(everything(), transformar_respuesta)) |&gt; \n  mutate(TOTAL = (AWRMAR + AWRALC + AWRCIG)/3)\n\n\n\n\n\n\n\n\nTip\n\n\n\n## Pro\ntransformar_respuesta &lt;- function(x) {\n  case_when(\n    x == \"Muy mal\" ~ 1,\n    x == \"Mal\" ~ 2,\n    x == \"Notan mal\" ~ 3,\n    x == \"Para nada mal\" ~ 4,\n    TRUE ~ NA\n  )\n}\n\nlos_datos |&gt; \n  select(AWRMAR, AWRALC, AWRCIG) |&gt; \n  mutate(across(everything(), transformar_respuesta)) |&gt; \n   mutate(TOTAL = (AWRMAR + AWRALC + AWRCIG)/3)"
  },
  {
    "objectID": "archive/2023-03-Uniandes/2-procesamiento.html#mutate-2",
    "href": "archive/2023-03-Uniandes/2-procesamiento.html#mutate-2",
    "title": "2. Procesamiento de datos con tidyverse",
    "section": "mutate()",
    "text": "mutate()\n\n\n\n\n\n\nTip\n\n\n\ncase_when(): Esta función se utiliza para realizar una serie de comparaciones y asignar valores en función de las comparaciones. En este caso, se utiliza para asignar un valor numérico a la columna “AWRMAR” del objeto “los_datos” en función de los valores de texto que contiene.\nacross(): Esta función se utiliza para aplicar una función a varias columnas de un data frame o tibble. En este caso, se utiliza para aplicar la función transformar_respuesta() a todas las columnas del objeto “los_datos”.\neverything(): Esta función se utiliza para seleccionar todas las columnas de un data frame o tibble. En este caso, se utiliza para aplicar la función transformar_respuesta() a todas las columnas del objeto “los_datos”."
  },
  {
    "objectID": "archive/2023-03-Uniandes/2-procesamiento.html#filter",
    "href": "archive/2023-03-Uniandes/2-procesamiento.html#filter",
    "title": "2. Procesamiento de datos con tidyverse",
    "section": "filter()",
    "text": "filter()\nfilter() es una función que permite seleccionar filas de la base de datos según una condición.\nAhora voy a utilizar un filtro para seleccionar solamente las filas en las que los adultos respondieron “No tan mal” para el consumo de marihuana (AWRMAR).\n\nlos_datos |&gt; \n  select(GENDER, AWRMAR, AWRALC, AWRCIG) |&gt; \n  filter(AWRMAR == \"No tan mal\")\n\n\nCon este filtro puedo ver que en los primeros 10 casos, cuando un adulto juzga que no está tan mal fumar marihuana, el juicio de consumo de alcohol y cigarrillo parece seguir el mismo patrón."
  },
  {
    "objectID": "archive/2023-03-Uniandes/2-procesamiento.html#filter-1",
    "href": "archive/2023-03-Uniandes/2-procesamiento.html#filter-1",
    "title": "2. Procesamiento de datos con tidyverse",
    "section": "filter()",
    "text": "filter()\nAhora miremos qué pasa si filtro por la opción “Muy mal”\n\nlos_datos |&gt; \n  select(GENDER, AWRMAR, AWRALC, AWRCIG) |&gt; \n  filter(AWRMAR == \"Muy mal\")\n\n\nEs diferente al primer ejemplo, juzgar el consumo de marihuana como Muy mal parece también coincidir con el consumo de alcohol y cigarrillo.\n\n\n\n\n\n\nTip\n\n\n\nfilter(): Esta función se utiliza para seleccionar filas específicas de un data frame o tibble en función de una o varias condiciones. En este caso, se utiliza para seleccionar las filas del objeto “los_datos” en las que la columna “AWRMAR” es igual a “No tan mal”."
  },
  {
    "objectID": "archive/2023-03-Uniandes/2-procesamiento.html#summarise",
    "href": "archive/2023-03-Uniandes/2-procesamiento.html#summarise",
    "title": "2. Procesamiento de datos con tidyverse",
    "section": "summarise()",
    "text": "summarise()\nEsta función permiten obtener medidas de resumen de la base de datos, como por ejemplo, la media, moda, frecuencias, desviación estándar, etc.\n\n# Para marihuana\n\nlos_datos |&gt; \n  select(GENDER, AWRMAR, AWRALC, AWRCIG) |&gt; \n  mutate(across(starts_with(\"A\"),transformar_respuesta)) |&gt; \n  summarise(mean_AWRMAR = mean(AWRMAR, na.rm = TRUE),\n            sd_AWRMAR = sd(AWRMAR, na.rm = TRUE), \n            max_AWRMAR = max(AWRMAR, na.rm = TRUE), \n            min_AWRMAR = min(AWRMAR, na.rm = TRUE))\n\n\n\n\n\n\n\nTip\n\n\n\nsummarise(): Esta función se utiliza para obtener medidas de resumen de un data frame o tibble. En este caso, se utiliza para obtener la media, la desviación estándar, el valor máximo y el valor mínimo de la columna “AWRMAR” del objeto “los_datos”.\nstarts_with(): Esta función se utiliza para seleccionar columnas que comienzan con un determinado prefijo. En este caso, se utiliza para seleccionar las columnas que comienzan con “A” del objeto “los_datos”."
  },
  {
    "objectID": "archive/2023-03-Uniandes/2-procesamiento.html#explorar-los-datos-1-1",
    "href": "archive/2023-03-Uniandes/2-procesamiento.html#explorar-los-datos-1-1",
    "title": "2. Procesamiento de datos con tidyverse",
    "section": "Explorar los datos 1",
    "text": "Explorar los datos 1\n\nfactores_de_riesgo &lt;- c(\"CRPAD\", \"CRLNFD\", \"FRPFD\", \"FRPFM\", \"SRLCS\", \"PRFAD\", \n                        \"PRATA\", \"PRFUD\", \"PRIAP\", \"FPOPI\", \"FPRPI\", \"SPRPI\")\ndemograficas &lt;- c(\"YEAR\", \"GRADE\", \"GENDER\", \"AGE\")\nconsumo_alcohol &lt;- c(\"PYALC\")\n\n\n\nlos_datos %&gt;% \n  select(all_of(factores_de_riesgo), \n         all_of(demograficas), \n         all_of(consumo_alcohol)) %&gt;% \n  glimpse()\n\n\n\nmini_datos &lt;- los_datos %&gt;% \n  select(all_of(factores_de_riesgo), \n         all_of(demograficas), \n         all_of(consumo_alcohol)) \n\n\n\nmini_datos |&gt; \n  skimr::skim()\n\n\n\n\nMachine Learning"
  },
  {
    "objectID": "slides/workshop_document.html",
    "href": "slides/workshop_document.html",
    "title": "Imbalanced data in Machine Learning Modeling",
    "section": "",
    "text": "library(tidymodels)\nlibrary(gt)\nlibrary(dataUMworkshop)\ntidymodels_prefer()\n\n\n\nThere are many ways to estimate models in R\n\nlm(formula, data, ...)\nstan_glm(formula, data, family= \"gaussian\",...)\nglmnet(x=matrix, y=vector, family=\"gaussian\",...)\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nlibrary(): Load the tidymodels package into R.\ntidymodels_prefer(): Sets the tidymodels package as the preferred one for modeling functions in R.\nlm(): Fits a linear regression model to the data.\nstan_glm(): Fits a regression model using the stan package.\nglmnet(): Fits a regression model using Lasso or Ridge regularization.\n\n\n\nTidymodels provides a general syntax for estimating models\n\nSpecify the type of model\n\nlinear_reg(), logistic_reg(), decision_tree()\n\nSpecify the type of outcome\n\nRegression for continuous outcomes\nClassification: multinomial, ordinal, binary\n\n\n\nlinear_reg() |&gt;\n  set_engine(\"lm\")\n\nlinear_reg() |&gt;\n  set_engine(\"glmnet\")\n\nlinear_reg() |&gt;\n  set_engine(\"stan\")\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nlinear_reg(): Creates a linear regression model specification in the tidymodels framework.\nset_engine(): Sets the calculation engine for a model specification object. It is set to “lm” for the first call to linear_reg(), “glmnet” for the second call, and “stan” for the third.\n\n\n\nTo estimate a model:\n\n\n\n\nlm_model &lt;-\n  logistic_reg() %&gt;%\n  set_engine(\"glm\", family = \"binomial\") |&gt;\n  set_mode(\"classification\")\n\nSpecify a logistic regression model. Additionally, the modeling mode is set to “classification” to indicate that it is a categorical variable. The result is stored in the lm_model object.\n\n\n\n\n\n\n\n\n\nTip\n\n\n\n\n\n\ndata(dataUMworkshop)\n# The outcome variable is specified as a factor\nthe_data &lt;- dataUMworkshop |&gt;\n  select(-outcome_count) |&gt;\n  mutate(outcome = factor(outcome)) |&gt;\n  rename(P200 = P2)\n\n\n\n\n\nlm_results &lt;- lm_model |&gt;\n  fit(outcome ~ ., data = the_data)\n\nHere the model is fitted-estimated using the fit() function. The response variable (outcome) and the predictors (.) are specified and the the_data object is used as a database.\n\n\n\n\nlm_results |&gt; tidy()\n\n# A tibble: 41 × 5\n   term        estimate std.error statistic    p.value\n   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;      &lt;dbl&gt;\n 1 (Intercept)  -0.851     1.10      -0.773 0.440     \n 2 P2001        -2.08      0.546     -3.81  0.000141  \n 3 P2002         0.754     0.272      2.77  0.00553   \n 4 P2003        -1.44      0.320     -4.49  0.00000707\n 5 P2004        -0.142     0.281     -0.507 0.612     \n 6 P2005        -0.0850    0.445     -0.191 0.849     \n 7 P3           -0.0153    0.0118    -1.30  0.192     \n 8 P4            0.0137    0.0205     0.670 0.503     \n 9 P13          -0.388     0.186     -2.08  0.0374    \n10 P142         -0.209     0.382     -0.546 0.585     \n# ℹ 31 more rows\n\nlm_results |&gt;\n  glance() |&gt;\n  gt()\n\n\n\n\n\n\n\nnull.deviance\ndf.null\nlogLik\nAIC\nBIC\ndeviance\ndf.residual\nnobs\n\n\n\n\n1356.908\n1375\n-573.3018\n1228.604\n1442.908\n1146.604\n1335\n1376\n\n\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\n\n\n\ntidy(): This function is used to convert the results of a model into a “tidy” data frame that displays the model coefficients, standard errors, t-values, and p-values for each independent variable.\nglance(): This function is used to summarize the results of a model as global model statistics, for example, adjusted R-squared, the AIC, and the BIC.\n\n\nlm_results |&gt; tidy(exp = TRUE, conf.int = TRUE)\n\ntidy(exp=TRUE, conf.int=TRUE): This function is used to convert the results of a model into a “tidy” data frame that displays the model coefficients, standard errors, t-values, and t-values. p for each independent variable. The exp and conf.int arguments are used to include confidence intervals and exponents in the results\n\n\n\n\n\n\nAccuracy: This is how often the model makes correct predictions. It’s a simple ratio of the number of correct predictions to the total number of predictions.\nSensitivity: Also known as “True Positive Rate.” It measures how well the model identifies positive outcomes. In other words, it’s the percentage of actual positives that the model correctly predicts.\nSpecificity: Also known as “True Negative Rate.” This is about how well the model identifies negative outcomes. It tells us the percentage of actual negatives that the model correctly predicts.\nPrecision: This tells us how many of the model’s positive predictions are actually correct. It’s a ratio of true positive predictions to all positive predictions (including false positives).\nRecall: This is the same as sensitivity. It’s about how many of the actual positive cases the model can correctly identify.\nF-measure: This score combines precision and recall into a single number. It helps balance the trade-off between these two metrics. A higher F-measure means better model performance.\nKappa Coefficient: Kappa is about how much better the model is than random guessing. It compares the model’s accuracy with what would be expected by chance. A higher Kappa means the model is much better than just guessing.\n\n\naugmented_results &lt;- lm_results |&gt;\n  augment(the_data)\n\naccuracy(augmented_results,\n  truth = outcome,\n  estimate = .pred_class\n) |&gt; pretty_table()\n\n\n\n\n\n\n\nMetric\nEstimate\n\n\n\n\nAccuracy\n0.818\n\n\n\n\n\n\nsens(augmented_results,\n  truth = outcome,\n  estimate = .pred_class,\n  event_level = \"second\"\n) |&gt; pretty_table()\n\n\n\n\n\n\n\nMetric\nEstimate\n\n\n\n\nSensitivity\n0.179\n\n\n\n\n\n\nspec(augmented_results,\n  truth = outcome,\n  estimate = .pred_class,\n  event_level = \"second\"\n) |&gt; pretty_table()\n\n\n\n\n\n\n\nMetric\nEstimate\n\n\n\n\nSpecificity\n0.972\n\n\n\n\n\n\nf_meas(augmented_results,\n  truth = outcome,\n  estimate = .pred_class,\n  event_level = \"second\"\n) |&gt; pretty_table()\n\n\n\n\n\n\n\nMetric\nEstimate\n\n\n\n\nF1\n0.277"
  },
  {
    "objectID": "slides/workshop_document.html#estimating-a-model-in-r",
    "href": "slides/workshop_document.html#estimating-a-model-in-r",
    "title": "Imbalanced data in Machine Learning Modeling",
    "section": "",
    "text": "There are many ways to estimate models in R\n\nlm(formula, data, ...)\nstan_glm(formula, data, family= \"gaussian\",...)\nglmnet(x=matrix, y=vector, family=\"gaussian\",...)\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nlibrary(): Load the tidymodels package into R.\ntidymodels_prefer(): Sets the tidymodels package as the preferred one for modeling functions in R.\nlm(): Fits a linear regression model to the data.\nstan_glm(): Fits a regression model using the stan package.\nglmnet(): Fits a regression model using Lasso or Ridge regularization.\n\n\n\nTidymodels provides a general syntax for estimating models\n\nSpecify the type of model\n\nlinear_reg(), logistic_reg(), decision_tree()\n\nSpecify the type of outcome\n\nRegression for continuous outcomes\nClassification: multinomial, ordinal, binary\n\n\n\nlinear_reg() |&gt;\n  set_engine(\"lm\")\n\nlinear_reg() |&gt;\n  set_engine(\"glmnet\")\n\nlinear_reg() |&gt;\n  set_engine(\"stan\")\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nlinear_reg(): Creates a linear regression model specification in the tidymodels framework.\nset_engine(): Sets the calculation engine for a model specification object. It is set to “lm” for the first call to linear_reg(), “glmnet” for the second call, and “stan” for the third.\n\n\n\nTo estimate a model:"
  },
  {
    "objectID": "slides/workshop_document.html#specify-the-model",
    "href": "slides/workshop_document.html#specify-the-model",
    "title": "Imbalanced data in Machine Learning Modeling",
    "section": "",
    "text": "lm_model &lt;-\n  logistic_reg() %&gt;%\n  set_engine(\"glm\", family = \"binomial\") |&gt;\n  set_mode(\"classification\")\n\nSpecify a logistic regression model. Additionally, the modeling mode is set to “classification” to indicate that it is a categorical variable. The result is stored in the lm_model object."
  },
  {
    "objectID": "slides/workshop_document.html#estimate-the-model",
    "href": "slides/workshop_document.html#estimate-the-model",
    "title": "Imbalanced data in Machine Learning Modeling",
    "section": "",
    "text": "Tip\n\n\n\n\n\n\ndata(dataUMworkshop)\n# The outcome variable is specified as a factor\nthe_data &lt;- dataUMworkshop |&gt;\n  select(-outcome_count) |&gt;\n  mutate(outcome = factor(outcome)) |&gt;\n  rename(P200 = P2)\n\n\n\n\n\nlm_results &lt;- lm_model |&gt;\n  fit(outcome ~ ., data = the_data)\n\nHere the model is fitted-estimated using the fit() function. The response variable (outcome) and the predictors (.) are specified and the the_data object is used as a database."
  },
  {
    "objectID": "slides/workshop_document.html#check-the-model-results",
    "href": "slides/workshop_document.html#check-the-model-results",
    "title": "Imbalanced data in Machine Learning Modeling",
    "section": "",
    "text": "lm_results |&gt; tidy()\n\n# A tibble: 41 × 5\n   term        estimate std.error statistic    p.value\n   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;      &lt;dbl&gt;\n 1 (Intercept)  -0.851     1.10      -0.773 0.440     \n 2 P2001        -2.08      0.546     -3.81  0.000141  \n 3 P2002         0.754     0.272      2.77  0.00553   \n 4 P2003        -1.44      0.320     -4.49  0.00000707\n 5 P2004        -0.142     0.281     -0.507 0.612     \n 6 P2005        -0.0850    0.445     -0.191 0.849     \n 7 P3           -0.0153    0.0118    -1.30  0.192     \n 8 P4            0.0137    0.0205     0.670 0.503     \n 9 P13          -0.388     0.186     -2.08  0.0374    \n10 P142         -0.209     0.382     -0.546 0.585     \n# ℹ 31 more rows\n\nlm_results |&gt;\n  glance() |&gt;\n  gt()\n\n\n\n\n\n\n\nnull.deviance\ndf.null\nlogLik\nAIC\nBIC\ndeviance\ndf.residual\nnobs\n\n\n\n\n1356.908\n1375\n-573.3018\n1228.604\n1442.908\n1146.604\n1335\n1376\n\n\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\n\n\n\ntidy(): This function is used to convert the results of a model into a “tidy” data frame that displays the model coefficients, standard errors, t-values, and p-values for each independent variable.\nglance(): This function is used to summarize the results of a model as global model statistics, for example, adjusted R-squared, the AIC, and the BIC.\n\n\nlm_results |&gt; tidy(exp = TRUE, conf.int = TRUE)\n\ntidy(exp=TRUE, conf.int=TRUE): This function is used to convert the results of a model into a “tidy” data frame that displays the model coefficients, standard errors, t-values, and t-values. p for each independent variable. The exp and conf.int arguments are used to include confidence intervals and exponents in the results"
  },
  {
    "objectID": "slides/workshop_document.html#metrics-to-evaluate-the-model",
    "href": "slides/workshop_document.html#metrics-to-evaluate-the-model",
    "title": "Imbalanced data in Machine Learning Modeling",
    "section": "",
    "text": "Accuracy: This is how often the model makes correct predictions. It’s a simple ratio of the number of correct predictions to the total number of predictions.\nSensitivity: Also known as “True Positive Rate.” It measures how well the model identifies positive outcomes. In other words, it’s the percentage of actual positives that the model correctly predicts.\nSpecificity: Also known as “True Negative Rate.” This is about how well the model identifies negative outcomes. It tells us the percentage of actual negatives that the model correctly predicts.\nPrecision: This tells us how many of the model’s positive predictions are actually correct. It’s a ratio of true positive predictions to all positive predictions (including false positives).\nRecall: This is the same as sensitivity. It’s about how many of the actual positive cases the model can correctly identify.\nF-measure: This score combines precision and recall into a single number. It helps balance the trade-off between these two metrics. A higher F-measure means better model performance.\nKappa Coefficient: Kappa is about how much better the model is than random guessing. It compares the model’s accuracy with what would be expected by chance. A higher Kappa means the model is much better than just guessing.\n\n\naugmented_results &lt;- lm_results |&gt;\n  augment(the_data)\n\naccuracy(augmented_results,\n  truth = outcome,\n  estimate = .pred_class\n) |&gt; pretty_table()\n\n\n\n\n\n\n\nMetric\nEstimate\n\n\n\n\nAccuracy\n0.818\n\n\n\n\n\n\nsens(augmented_results,\n  truth = outcome,\n  estimate = .pred_class,\n  event_level = \"second\"\n) |&gt; pretty_table()\n\n\n\n\n\n\n\nMetric\nEstimate\n\n\n\n\nSensitivity\n0.179\n\n\n\n\n\n\nspec(augmented_results,\n  truth = outcome,\n  estimate = .pred_class,\n  event_level = \"second\"\n) |&gt; pretty_table()\n\n\n\n\n\n\n\nMetric\nEstimate\n\n\n\n\nSpecificity\n0.972\n\n\n\n\n\n\nf_meas(augmented_results,\n  truth = outcome,\n  estimate = .pred_class,\n  event_level = \"second\"\n) |&gt; pretty_table()\n\n\n\n\n\n\n\nMetric\nEstimate\n\n\n\n\nF1\n0.277"
  },
  {
    "objectID": "slides/workshop_document.html#split-the-data",
    "href": "slides/workshop_document.html#split-the-data",
    "title": "Imbalanced data in Machine Learning Modeling",
    "section": "Split the data",
    "text": "Split the data\n\nSplit the data into two sets\n\nTraining\n\nMost of the data (70%, 80%?)\nHere the model is adjusted\n\nTest\n\nA small data set\nHere the final model will be evaluated\n\n\n\nTest data is used only once, if it is used more than once it becomes part of the training process.\n\n\n\n\n\n\nWarning\n\n\n\nThe division of the data is done at the level of the independent unit of observation.\nAvoid contamination of test data (information leakage) at all costs, that is, information cannot be leaked from one database to the other.\n\n\nSo, one can create two databases with for example 80% and 20% of the data. But how do you do this in R?\n\nset.seed(193945)\n\nsplit_data &lt;- initial_split(the_data, prop = 0.8, strata = \"outcome\")\n\ntraining_data &lt;- training(split_data)\ntest_data &lt;- testing(split_data)\n\nThe strata option is so that the training and test data have the same distribution of the variable score\nSometimes random sample selection is not simple, for example when there is a time component to the data.\n\n\n\n\n\n\nTip\n\n\n\n\n\nset.seed() - Used to set a seed for random number generation in R. In this case, it is used to set the seed to 193945, ensuring that the results are reproducible. This is especially important when working with machine learning models, as results can vary depending on the seed used for random number generation.\ninitial_split(): This function is used to split a data frame into training and test sets. In this case, it is used to split the “the_data” object into training and test sets in an 80/20 ratio, and stratifying by the “outcome” column.\ntraining(): This function is used to extract the training set from an object created with the initial_split() function. In this case, it is used to extract the training set from the “split_data” object.\ntesting(): This function is used to extract the test set from an object created with the initial_split() function. In this case, it is used to extract the test set from the “split_data” object.\n\n\n\nNow, we can repeat the previous model estimation steps, but we will use the training data."
  },
  {
    "objectID": "slides/workshop_document.html#estimate-the-model-1",
    "href": "slides/workshop_document.html#estimate-the-model-1",
    "title": "Imbalanced data in Machine Learning Modeling",
    "section": "2. Estimate the model",
    "text": "2. Estimate the model\nModel Estimation: The lm_model() and fit() function is used to fit a linear regression model. The outcome ~ . indicates that the score variable is being modeled as a function of all the other variables in the “training_data” dataframe.\n\nlm_results &lt;- lm_model |&gt;\n  fit(outcome ~ ., data = training_data)"
  },
  {
    "objectID": "slides/workshop_document.html#model-results",
    "href": "slides/workshop_document.html#model-results",
    "title": "Imbalanced data in Machine Learning Modeling",
    "section": "3. Model results",
    "text": "3. Model results\nView model results: The tidy function is used to obtain a clean and tidy summary of the model results.\n\nlm_results |&gt;\n  tidy()\n\n# A tibble: 41 × 5\n   term        estimate std.error statistic     p.value\n   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;       &lt;dbl&gt;\n 1 (Intercept) -0.244      1.22      -0.199 0.842      \n 2 P2001       -1.98       0.555     -3.56  0.000368   \n 3 P2002        0.696      0.300      2.32  0.0204     \n 4 P2003       -2.02       0.390     -5.19  0.000000208\n 5 P2004       -0.189      0.308     -0.613 0.540      \n 6 P2005       -0.378      0.502     -0.752 0.452      \n 7 P3          -0.0243     0.0132    -1.84  0.0664     \n 8 P4           0.00650    0.0228     0.285 0.776      \n 9 P13         -0.257      0.210     -1.22  0.221      \n10 P142        -0.482      0.449     -1.07  0.283      \n# ℹ 31 more rows\n\n\nPredictions: The augment function is used to obtain the predictions of the model on the training data.\n\nlm_augmented_results &lt;- lm_results |&gt;\n  augment(training_data)\n\nMetrics: The custom_metrics function is used to calculate the accuracy, sensitivity, specificity, and F-measure of the model on the training data. The results are stored in the “lm_metrics” object.\n\ncustom_metrics &lt;- metric_set(accuracy, sens, spec, f_meas)\n\ncustom_metrics(lm_augmented_results,\n  truth = outcome,\n  estimate = .pred_class,\n  event_level = \"second\"\n) |&gt; pretty_table()\n\n\n\n\n\n\n\nMetric\nEstimate\n\n\n\n\nAccuracy\n0.817\n\n\nSensitivity\n0.168\n\n\nSpecificity\n0.974\n\n\nF1\n0.264\n\n\n\n\n\n\n\nWe can save them on a table. The results are stored in the “lm_results” object.\n\nlm_metrics_training &lt;- custom_metrics(lm_augmented_results,\n  truth = outcome,\n  estimate = .pred_class,\n  event_level = \"second\"\n) |&gt;\n  mutate(model = \"lm\")\n\nCan we improve the model?"
  },
  {
    "objectID": "slides/workshop_document.html#decision-trees",
    "href": "slides/workshop_document.html#decision-trees",
    "title": "Imbalanced data in Machine Learning Modeling",
    "section": "Decision trees",
    "text": "Decision trees\nDecision trees are a type of machine learning model used to solve classification and regression problems. The goal is to make decisions based on questions and answers asked of the data to reach a conclusion or prediction. In a decision tree, each point or “node” represents a characteristic of the data we are studying. Each “branch” of the tree shows a possible response to that characteristic.\n\nModel specification: A decision tree model is specified. The rpart package is used and the mode is set to classification.\n\n\ntree_spec &lt;-\n  decision_tree() |&gt;\n  set_engine(\"rpart\") |&gt;\n  set_mode(\"classification\")\n\n\nModel fitting: The decision tree model is fitted using the formula outcome ~ ., which means that score is being modeled as a function of all the other variables in the training_data dataframe.\n\n\ntree_results &lt;- tree_spec |&gt;\n  fit(outcome ~ ., data = training_data)\n\n\nDecision tree display: The fitted model is extracted from the fitting result and displayed using the tree_diagram() function of the treemisc package.\n\n\ncart_tree_fit &lt;- tree_results$fit\n\ntreemisc::tree_diagram(cart_tree_fit, roundint = FALSE)\n\n\n\n\nHow do you decide where to cut data in a decision tree? see this\nLet’s calculate the metrics\n\ntree_metrics_training &lt;- tree_results |&gt;\n  augment(training_data) |&gt;\n  custom_metrics(\n    truth = outcome,\n    estimate = .pred_class,\n    event_level = \"second\"\n  ) |&gt;\n  mutate(model = \"tree\")\n\nrbind(tree_metrics_training, lm_metrics_training) |&gt;\n  pivot_wider(names_from = model, values_from = .estimate) |&gt;\n  pretty_table()\n\n\n\n\n\n\n\nMetric\nTree\nLm\n\n\n\n\nAccuracy\n0.843\n0.817\n\n\nSensitivity\n0.290\n0.168\n\n\nSpecificity\n0.976\n0.974\n\n\nF1\n0.418\n0.264"
  },
  {
    "objectID": "slides/workshop_document.html#cart-with-hyperparameters",
    "href": "slides/workshop_document.html#cart-with-hyperparameters",
    "title": "Imbalanced data in Machine Learning Modeling",
    "section": "CART with hyperparameters",
    "text": "CART with hyperparameters\nHyperparameters are model-specific values that can be adjusted and that allow you to control the training process of a model.\n\ntree_spec_hyp_manual &lt;-\n  decision_tree(min_n = 5, cost_complexity = 0.001) |&gt;\n  set_mode(\"classification\") |&gt;\n  set_engine(\"rpart\")\n\nIn this case, two hyperparameters are being indicated for the decision tree:\n\nmin_n: It is the minimum number of observations required to divide a node in a decision tree. A higher value of min_n implies that the tree will be shallower, since more samples will be required to perform a split at each node.\ncost_complexity: It is a regularization parameter. It is a measure of the penalty that is applied to the tree based on its complexity. A higher value of cost_complexity implies a stronger penalty on the complexity of the tree, leading to a smaller and shallower tree.\n\nNow to estimate the model\n\ntree_spec_hyp_manual_results &lt;- tree_spec_hyp_manual |&gt;\n  fit(outcome ~ ., data = training_data)\n\nWe can get the predictions\n\ntree_spec_hyp_manual_training &lt;- tree_spec_hyp_manual_results |&gt;\n  augment(training_data) |&gt;\n  custom_metrics(,\n    truth = outcome,\n    estimate = .pred_class,\n    event_level = \"second\"\n  ) |&gt;\n  mutate(model = \"Tree hyp manual\")\n\nAnd finally, we can compare the models\n\nrbind(\n  lm_metrics_training,\n  tree_metrics_training,\n  tree_spec_hyp_manual_training\n) |&gt;\n  pivot_wider(names_from = model, values_from = .estimate) |&gt;\n  pretty_table()\n\n\n\n\n\n\n\nMetric\nLm\nTree\nTree_hyp_manual\n\n\n\n\nAccuracy\n0.817\n0.843\n0.939\n\n\nSensitivity\n0.168\n0.290\n0.818\n\n\nSpecificity\n0.974\n0.976\n0.968\n\n\nF1\n0.264\n0.418\n0.839"
  },
  {
    "objectID": "slides/workshop_document.html#but-all-this-happens-in-the-training-data",
    "href": "slides/workshop_document.html#but-all-this-happens-in-the-training-data",
    "title": "Imbalanced data in Machine Learning Modeling",
    "section": "But all this happens in the training data!",
    "text": "But all this happens in the training data!"
  },
  {
    "objectID": "slides/workshop_document.html#why-is-it-bad",
    "href": "slides/workshop_document.html#why-is-it-bad",
    "title": "Imbalanced data in Machine Learning Modeling",
    "section": "Why is it bad?",
    "text": "Why is it bad?\nWe can create a model that has zero errors in the training data. But how do we know that the model is good?\nWe could evaluate the model in unseen data, but we only have one test data set.\n\n# Use the test data to predict the score using the logistic regression model\nlm_predictions_test &lt;- lm_model |&gt;\n  last_fit(outcome ~ ., split_data,\n    metrics = custom_metrics,\n    control = control_resamples(event_level = \"second\")\n  ) |&gt;\n  collect_metrics() |&gt;\n  mutate(model = \"lm\")\n\n# Use the test data to predict the score using the decision tree model\ntree_prediction_test &lt;- tree_spec |&gt;\n  last_fit(outcome ~ ., split_data,\n    metrics = custom_metrics,\n    control = control_resamples(event_level = \"second\")\n  ) |&gt;\n  collect_metrics() |&gt;\n  mutate(model = \"Tree\")\n\n\n# Use the test data to predict the score using the hyperparameter decision tree model\ntree_hyp_predictions_test &lt;- tree_spec_hyp_manual |&gt;\n  last_fit(outcome ~ ., split_data,\n    metrics = custom_metrics,\n    control = control_resamples(event_level = \"second\")\n  ) |&gt;\n  collect_metrics() |&gt;\n  mutate(model = \"Tree Hype\")\n\n# Join the results\nall_models_test &lt;-\n  rbind(lm_predictions_test, tree_prediction_test, tree_hyp_predictions_test) |&gt;\n  pivot_wider(names_from = model, values_from = .estimate)\n\nall_models_test |&gt;\n  pretty_table()\n\n\n\n\n\n\n\nMetric\nLm\nTree\nTree_hype\n\n\n\n\nAccuracy\n0.815\n0.801\n0.674\n\n\nSensitivity\n0.222\n0.167\n0.259\n\n\nSpecificity\n0.959\n0.955\n0.775\n\n\nF1\n0.320\n0.247\n0.237"
  },
  {
    "objectID": "slides/workshop_document.html#cross-validation",
    "href": "slides/workshop_document.html#cross-validation",
    "title": "Imbalanced data in Machine Learning Modeling",
    "section": "Cross Validation",
    "text": "Cross Validation\nSuppose we are working on a classification problem and we have a data set with 1000 observations. We want to evaluate the performance of a logistic regression model using k-fold cross-validation.\nStep-by-step k-fold cross-validation process:\nDivide the data set: First, we divide the data set into k subsets (folds) of equal size. In this example, we choose k=10, which means we divide the data set into 10 subsets of 100 records each.\nTrain and evaluate the model: Then, we do the following for each of the k subsets:\nto. We take one subset as the test (validation) set and the remaining k-1 subsets as the training set. For example, in the first iteration, we use the first subset as the test set and subsets 2 to 10 as the training set.\n\nWe train the logistic regression model using the training set.\nWe evaluate the performance of the model on the test set using an appropriate metric, such as precision, completeness, or F1-score. We write down the result of the metric for this iteration.\n\nAveraging results: After completing k iterations, we average the metric results for all iterations. This means providing us with a more robust estimate of the model’s performance since the model has been evaluated on different subsets of the data set.\nMore information here and here"
  },
  {
    "objectID": "slides/workshop_document.html#first-path-cross-validation-object-to-estimate-performance",
    "href": "slides/workshop_document.html#first-path-cross-validation-object-to-estimate-performance",
    "title": "Imbalanced data in Machine Learning Modeling",
    "section": "First path: cross-validation object to estimate performance",
    "text": "First path: cross-validation object to estimate performance\nThe first thing we are going to need is to create an object in R that contains the data organized in such a way that we can implement cross-validation. For this, we are going to use the vfold_cv() function from the rsample package.\n\ncrossvalidation &lt;-\n  vfold_cv(training_data,\n    v = 5, # number of boxes\n    strata = \"outcome\"\n  ) # variable to stratify\n\n\nlm_model_resamples &lt;- lm_model |&gt;\n  fit_resamples(outcome ~ ., crossvalidation,\n    metrics = custom_metrics,\n    control = control_resamples(event_level = \"second\")\n  ) |&gt;\n  collect_metrics() |&gt;\n  mutate(model = \"lm_resamples\")\n\ntree_spec_resamples &lt;- tree_spec |&gt;\n  fit_resamples(outcome ~ ., crossvalidation,\n    metrics = custom_metrics,\n    control = control_resamples(event_level = \"second\")\n  ) |&gt;\n  collect_metrics() |&gt;\n  mutate(model = \"tree_resamples\")\n\ntree_spec_hyp_resamples &lt;- tree_spec_hyp_manual |&gt;\n  fit_resamples(outcome ~ ., crossvalidation,\n    metrics = custom_metrics,\n    control = control_resamples(event_level = \"second\")\n  ) |&gt;\n  collect_metrics() |&gt;\n  mutate(model = \"tree_hyp_resamples\")\n\nall_models_resamples &lt;-\n  rbind(lm_model_resamples, tree_spec_resamples, tree_spec_hyp_resamples) |&gt;\n  pivot_wider(names_from = model, values_from = mean, id_cols = .metric)\n\nall_models_resamples |&gt;\n  pretty_table()\n\n\n\n\n\n\n\nMetric\nLm_resamples\nTree_resamples\nTree_hyp_resamples\n\n\n\n\nAccuracy\n0.795\n0.776\n0.736\n\n\nF1\n0.219\n0.202\n0.298\n\n\nSensitivity\n0.150\n0.145\n0.289\n\n\nSpecificity\n0.951\n0.929\n0.844"
  },
  {
    "objectID": "slides/workshop_document.html#second-path-cross-validation-object-to-identify-the-best-model",
    "href": "slides/workshop_document.html#second-path-cross-validation-object-to-identify-the-best-model",
    "title": "Imbalanced data in Machine Learning Modeling",
    "section": "Second path: cross-validation object to identify the best model",
    "text": "Second path: cross-validation object to identify the best model\nWhen specifying a decision tree model, we will indicate that we want different values of the “min_n” and “cost_complexity” hyperparameters to be tested. For that, we are going to use the tune package.\n\ntree_spe_tune &lt;-\n  decision_tree(\n    cost_complexity = tune(),\n    tree_depth = tune(),\n    min_n = tune()\n  ) |&gt;\n  set_mode(\"classification\") |&gt;\n  set_engine(\"rpart\")\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nCost_complexity: Cost_complexity is a regularization parameter. It is a measure of the penalty that is applied to the tree based on its complexity. A higher value of cost_complexity implies a stronger penalty on the complexity of the tree, leading to a smaller and shallower tree. The idea is to find an optimal value of cost_complexity that balances the precision and complexity of the tree, reducing both bias and variance.\nTree_depth (tree depth): Tree_depth refers to the maximum length of the longest path from the root to a leaf in a decision tree. A deeper tree is more complex and can capture more complicated relationships in the data.\n\n\n\nNow, let’s specify the search grid. The lookup grid is a table that contains the values to test for each combination of hyperparameters.\n\ntree_grid &lt;- grid_regular(\n  cost_complexity(range = c(-3, -2)),\n  tree_depth(range = c(4L, 10L)),\n  min_n(range = c(10L, 40L))\n)\n\nThe next step is to estimate the performance of the models on the validation data, using the models created with the different combinations of hyperparameters. For this, we are going to use the tune_grid() function from the tune package.\n\ndoParallel::registerDoParallel()\n\nset.seed(345)\ntree_rs &lt;-\n  tune_grid(\n    tree_spe_tune,\n    outcome ~ .,\n    resamples = crossvalidation,\n    control = control_resamples(event_level = \"second\"),\n    grid = tree_grid,\n    metrics = custom_metrics\n  )\n\ndoParallel::stopImplicitCluster()\n\n\n\n\n\n\n\nTip\n\n\n\n\n\ndoParallel is an excellent package created to facilitate parallel programming in R. Using R in “parallel” allows you to take advantage of the power of computers to save time.\n\n\n\nThis will give us a table with the results of each model, and we can ask it to show us the combination of hyperparameters that had the best performance.\n\nautoplot(tree_rs)\n\n\n\n\n\nshow_best(tree_rs, metric = \"sens\")\n\n# A tibble: 5 × 9\n  cost_complexity tree_depth min_n .metric .estimator  mean     n std_err\n            &lt;dbl&gt;      &lt;int&gt; &lt;int&gt; &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt;\n1         0.001           10    10 sens    binary     0.294     5  0.0471\n2         0.00316         10    10 sens    binary     0.285     5  0.0422\n3         0.00316         10    25 sens    binary     0.238     5  0.0482\n4         0.001            7    10 sens    binary     0.233     5  0.0325\n5         0.001           10    25 sens    binary     0.233     5  0.0474\n# ℹ 1 more variable: .config &lt;chr&gt;\n\n\nFinally, we can select the best model and estimate it with the training data.\n\nbest_hyp_tree &lt;- select_best(tree_rs, min_n, metric = \"sens\")\n\ntree_tuned_final &lt;- finalize_model(tree_spe_tune, best_hyp_tree)\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nThe finalize_model function allows updating the model specification with the selected hyperparameters.\n\n\n\nNow, we go back to doing what we have been doing: estimating the model with the training data.\nWe already know how to evaluate the model, so let’s do it. For that, we’re going to use the fit_resamples() function, which is going to do a lot of work for us. This function will estimate the model with the training data and calculate the evaluation metrics on the validation data.\n\n# We will need this later to compare the models in the table metrics from training, which is not very useful, but fun.\ntree_tuned_training &lt;- tree_tuned_final |&gt;\n  fit(outcome ~ ., data = training_data) |&gt;\n  augment(training_data) |&gt;\n  custom_metrics(,\n    truth = outcome,\n    estimate = .pred_class,\n    event_level = \"second\"\n  ) |&gt;\n  mutate(model = \"Tree tunned\")\n\n\ntree_tuned_resample &lt;- tree_tuned_final |&gt;\n  fit_resamples(outcome ~ ., crossvalidation,\n    metrics = custom_metrics,\n    control = control_resamples(event_level = \"second\")\n  ) |&gt;\n  collect_metrics() |&gt;\n  mutate(model = \"Tree tunned\")\n\n\nall_models_resamples &lt;-\n  rbind(\n    lm_model_resamples,\n    tree_spec_resamples,\n    tree_spec_hyp_resamples,\n    tree_tuned_resample\n  ) |&gt;\n  pivot_wider(names_from = model, values_from = mean, id_cols = .metric)\n\nall_models_resamples |&gt; pretty_table()\n\n\n\n\n\n\n\nMetric\nLm_resamples\nTree_resamples\nTree_hyp_resamples\nTree_tunned\n\n\n\n\nAccuracy\n0.795\n0.776\n0.736\n0.752\n\n\nF1\n0.219\n0.202\n0.298\n0.314\n\n\nSensitivity\n0.150\n0.145\n0.289\n0.294\n\n\nSpecificity\n0.951\n0.929\n0.844\n0.862\n\n\n\n\n\n\n\n\nSecret ring: trees are very good at learning the distribution of training data, but sometimes, they tend to over-specialize on the data they are trained on. One way to solve this is to make many trees, which we can then average."
  },
  {
    "objectID": "slides/workshop_document.html#random-forest",
    "href": "slides/workshop_document.html#random-forest",
    "title": "Imbalanced data in Machine Learning Modeling",
    "section": "Random Forest",
    "text": "Random Forest\nWe already know why it is Forest, but why is it random?\n\nNumber of predictors used for each tree (mtry)\nNumber of observations per tree\n\nThe steps are the same, only the model specification changes.\n\nrf_spec &lt;-\n  rand_forest() |&gt;\n  set_mode(\"classification\") |&gt;\n  set_engine(\"ranger\", importance = \"permutation\")\n\nThere are some methods to try to identify which variables were most relevant when making the best predictions.\n\nrf_results_training &lt;- rf_spec |&gt;\n  fit(outcome ~ ., data = training_data)\n\nlibrary(vip)\nimportance_plot_rf &lt;-\n  rf_results_training |&gt;\n  vip() +\n  ggtitle(\"Random Forest\") +\n  theme_minimal() +\n  geom_bar(\n    stat = \"identity\",\n    color = \"green\", fill = \"green\", alpha = 0.2\n  )\nimportance_plot_rf\n\n\n\n\nNow, fit in resamples and collect metrics.\n\nrf_spec_resamples &lt;- rf_spec |&gt;\n  fit_resamples(outcome ~ ., crossvalidation,\n    metrics = custom_metrics,\n    control = control_resamples(event_level = \"second\")\n  ) |&gt;\n  collect_metrics() |&gt;\n  mutate(model = \"Random Forest\")\n\nall_models_resamples &lt;-\n  rbind(\n    lm_model_resamples,\n    tree_spec_resamples,\n    tree_spec_hyp_resamples,\n    tree_tuned_resample,\n    rf_spec_resamples\n  ) |&gt;\n  pivot_wider(names_from = model, values_from = mean, id_cols = .metric) |&gt;\n  pretty_table()\n\nall_models_resamples\n\n\n\n\n\n\n\nMetric\nLm_resamples\nTree_resamples\nTree_hyp_resamples\nTree_tunned\nRandom_forest\n\n\n\n\nAccuracy\n0.795\n0.776\n0.736\n0.752\n0.803\n\n\nF1\n0.219\n0.202\n0.298\n0.314\n0.055\n\n\nSensitivity\n0.150\n0.145\n0.289\n0.294\n0.023\n\n\nSpecificity\n0.951\n0.929\n0.844\n0.862\n0.991"
  },
  {
    "objectID": "slides/workshop_document.html#bias-and-variance",
    "href": "slides/workshop_document.html#bias-and-variance",
    "title": "Imbalanced data in Machine Learning Modeling",
    "section": "Bias and variance",
    "text": "Bias and variance\nThese two concepts are crucial to understanding the balance between model complexity and its ability to generalize to new data.\nBias: Bias is the difference between the average prediction of our model and the true value we are trying to predict. Bias, in statistical terms, refers to the systematic difference between the expectation (or average) of the estimates produced by an estimator and the real value of the parameter to be estimated.\n\nExample: A linear regression model could have high bias if the actual data has a nonlinear relationship.\nImplications: A model with high bias is too simple and does not capture the underlying structure of the data. This leads to poor performance on the training and test set.\n\nVariance: Variance is the amount of variability in the model’s predictions for a piece of data. A model with high variance is very sensitive to small variations in the training data, which can result in overfitting. That is, the model fits the training data very well but performs poorly on unseen or test data.\n\nExample: A very deep decision tree model could have high variance since it is very sensitive to small variations in the training data.\nImplications: A model with high variance tends to overfit the training data, resulting in good performance on the training set but poor performance on the test set."
  },
  {
    "objectID": "slides/workshop_document.html#upsampling",
    "href": "slides/workshop_document.html#upsampling",
    "title": "Imbalanced data in Machine Learning Modeling",
    "section": "Upsampling",
    "text": "Upsampling\nUpsampling is a method that consists of increasing the number of observations in the minority class to match the number of observations in the majority class. This is done by randomly selecting observations from the minority class with replacement. This method is used when the data set is small and the minority class is very small.\n\nupsampling_rec &lt;-\n  recipe(outcome ~ ., training_data) |&gt;\n  step_upsample(outcome)\n\nupsampling_rec |&gt;\n  prep(retain = TRUE) |&gt;\n  bake(new_data = NULL) |&gt;\n  count(outcome)\n\n# A tibble: 2 × 2\n  outcome     n\n  &lt;fct&gt;   &lt;int&gt;\n1 0         886\n2 1         886\n\nupsampling_workflow &lt;-\n  workflow() |&gt;\n  add_recipe(upsampling_rec) |&gt;\n  add_model(lm_model)\n\nlet’s fit the model\n\nupsample_fit &lt;- upsampling_workflow |&gt;\n  fit(data = training_data)\n\nFinally, let’s evaluate the model in the validation data\n\nupsample_fit_resamples &lt;- upsampling_workflow |&gt;\n  fit_resamples(\n    resamples = crossvalidation,\n    metrics = custom_metrics,\n    control = control_resamples(event_level = \"second\")\n  )\n\nupsample_resamples &lt;- collect_metrics(upsample_fit_resamples) |&gt;\n  mutate(model = \"upsampling\")\n\n\nall_models_resamples &lt;-\n  rbind(\n    lm_model_resamples,\n    downsample_resamples,\n    upsample_resamples,\n    tree_spec_resamples,\n    tree_spec_hyp_resamples,\n    tree_tuned_resample,\n    rf_spec_resamples\n  ) |&gt;\n  pivot_wider(names_from = model, values_from = mean, id_cols = .metric)\n\nall_models_resamples |&gt; pretty_table()\n\n\n\n\n\n\n\nMetric\nLm_resamples\nDownsample\nUpsampling\nTree_resamples\nTree_hyp_resamples\nTree_tunned\nRandom_forest\n\n\n\n\nAccuracy\n0.795\n0.631\n0.658\n0.776\n0.736\n0.752\n0.803\n\n\nF1\n0.219\n0.409\n0.419\n0.202\n0.298\n0.314\n0.055\n\n\nSensitivity\n0.150\n0.654\n0.626\n0.145\n0.289\n0.294\n0.023\n\n\nSpecificity\n0.951\n0.625\n0.666\n0.929\n0.844\n0.862\n0.991"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Imbalanced data in Machine Learning Modeling",
    "section": "",
    "text": "Imbalanced data is a term used to describe datasets where there’s an uneven representation of target outcomes across different categories. In such cases, one category often has a significantly higher frequency compared to others. A classic example can be seen in binary classification problems, where one class may have a disproportionate number of observations relative to its counterpart. This imbalance presents a unique challenge in modeling: standard algorithms, which are usually designed for more evenly distributed data, may inherently favor the more common class. This bias can result in suboptimal performance, particularly in accurately predicting the outcomes for the minority class. Imbalance datasets are a practical concern in various fields, including research on adolescent health issues and drug use, where some outcomes or behaviors might be notably less common but are crucial to identify correctly.\nIn this workshop, we will explore various modeling techniques and resampling methods tailored to this specific challenge. Key topics include cross-validation, estimation of empirical error, and the identification of model hyperparameters. This comprehensive approach will provide participants with a deep understanding of handling imbalanced datasets effectively.\nThis workshop will be held at the University of Miami on Tuesday, December 5, 2023. We will meet in room 1080A at Don Soffer Clinical Research Center.\nWe will utilize the R programming language along with the tidymodel package to implement our models. The workshop will include a range of practical exercises and illustrative examples. Participants are expected to have a basic understanding of R and familiarity with regression analysis."
  },
  {
    "objectID": "index.html#overview",
    "href": "index.html#overview",
    "title": "Imbalanced data in Machine Learning Modeling",
    "section": "",
    "text": "Imbalanced data is a term used to describe datasets where there’s an uneven representation of target outcomes across different categories. In such cases, one category often has a significantly higher frequency compared to others. A classic example can be seen in binary classification problems, where one class may have a disproportionate number of observations relative to its counterpart. This imbalance presents a unique challenge in modeling: standard algorithms, which are usually designed for more evenly distributed data, may inherently favor the more common class. This bias can result in suboptimal performance, particularly in accurately predicting the outcomes for the minority class. Imbalance datasets are a practical concern in various fields, including research on adolescent health issues and drug use, where some outcomes or behaviors might be notably less common but are crucial to identify correctly.\nIn this workshop, we will explore various modeling techniques and resampling methods tailored to this specific challenge. Key topics include cross-validation, estimation of empirical error, and the identification of model hyperparameters. This comprehensive approach will provide participants with a deep understanding of handling imbalanced datasets effectively.\nThis workshop will be held at the University of Miami on Tuesday, December 5, 2023. We will meet in room 1080A at Don Soffer Clinical Research Center.\nWe will utilize the R programming language along with the tidymodel package to implement our models. The workshop will include a range of practical exercises and illustrative examples. Participants are expected to have a basic understanding of R and familiarity with regression analysis."
  },
  {
    "objectID": "index.html#organizers",
    "href": "index.html#organizers",
    "title": "Imbalanced data in Machine Learning Modeling",
    "section": "Organizers",
    "text": "Organizers\nFrancisco Cardozo. University of Miami.\nEric C. Brown.. University of Miami. María Fernanda Reyes, Universidad de los Andes."
  },
  {
    "objectID": "index.html#first-ring---the-two-paths-of-destiny",
    "href": "index.html#first-ring---the-two-paths-of-destiny",
    "title": "Imbalanced data in Machine Learning Modeling",
    "section": "First Ring - The Two Paths of Destiny",
    "text": "First Ring - The Two Paths of Destiny\n\nDivide the data into two groups, some data to train the model and another to test it.\n\nIn an age long past, when the world was still uncharted, the First Ring emerged, gleaming with the promise of unexplored knowledge. It was said to hold the power to split the fabric of reality into two distinct paths: one leading through the verdant forests of Training, lush with learning and growth, and the other winding into the misty valleys of Testing, where truth is revealed in the shadows. Those who embark on this journey, much like the brave heroes of old, are fated to traverse these paths, each step a new chapter in their quest for wisdom."
  },
  {
    "objectID": "index.html#second-ring---the-mirror-of-fates",
    "href": "index.html#second-ring---the-mirror-of-fates",
    "title": "Imbalanced data in Machine Learning Modeling",
    "section": "Second Ring - The Mirror of Fates",
    "text": "Second Ring - The Mirror of Fates\n\nValidate the model with the data that was not used to train it.\n\nThe Second Ring was forged in the hidden realms, where magic and mystery intertwine. It was no ordinary artifact, for it held a mirror reflecting not just images but destinies. In the hands of the learned, this ring divided the waters of Training, creating a silent pool of Validation, serene yet profound. Here, seers and sages could gaze into the depths, discerning the hidden strengths and weaknesses of their creations, much like the ancient oracles who, in their sacred groves, saw truths beyond the ken of mortals."
  },
  {
    "objectID": "index.html#third-ring---the-balance-of-light-and-shadow",
    "href": "index.html#third-ring---the-balance-of-light-and-shadow",
    "title": "Imbalanced data in Machine Learning Modeling",
    "section": "Third Ring - The Balance of Light and Shadow",
    "text": "Third Ring - The Balance of Light and Shadow\n\nThe balance between bias and variance is the key to the power of the model.\n\nIn the great halls of knowledge, the Third Ring was revered as the most elusive and powerful. It was the embodiment of the eternal struggle between Light and Shadow, an artifact that sought the perfect equilibrium. In the hands of a master, it could weave together the threads of Variance and Bias, creating a tapestry as balanced and harmonious as the cycle of day and night. The quest for this balance was akin to a legendary saga, where heroes journeyed through realms of dazzling brilliance and profound darkness, seeking the ancient wisdom that would bring peace to the land.\n\nSecret ring: trees are very good at learning the distribution of training data, but sometimes, they tend to over-specialize on the data they are trained on. One way to solve this is to make many trees, which we can then average."
  },
  {
    "objectID": "archive/2023-03-Uniandes/1-introduccion.html#temas",
    "href": "archive/2023-03-Uniandes/1-introduccion.html#temas",
    "title": "1 - Introducción a Machine Learning in tidymodels",
    "section": "Temas",
    "text": "Temas\n\n\n\n\nTipos de modelos\n\nDescriptivo\nInferencial\nPredictivo\n\nMachine Learning - Supervised\n\nClasificación\nRegresión - Unsupervised\nClustering\n\nEquilibrio entre la varianza y el sesgo\nValidación Cruzada\n\n\n\nEvaluación de los Modelos - Separación entrenamiento y prueba - Remuestreo\n\nLeave One Out\nK-Fold\nBoostraping"
  },
  {
    "objectID": "archive/2023-03-Uniandes/1-introduccion.html#tipos-de-modelos",
    "href": "archive/2023-03-Uniandes/1-introduccion.html#tipos-de-modelos",
    "title": "1 - Introducción a Machine Learning in tidymodels",
    "section": "Tipos de modelos",
    "text": "Tipos de modelos\n\nDescriptivosInferencialPredictivo\n\n\n\nDescribir las características de una base de datos\nVisualizar los datos\nResumir los datos\nGenerar hipótesis\n\n\n\n\nEstimar la probabilidad de que ocurra un evento\nProducir una estimación de un parámetro poblacional\nProbar una hipótesis\nIdea predeterminada y se prueba\nValor p, intervalo de confianza\n\n\n\n\nAnticipar el valor de una variable\nAplicar una regla a un evento que no ha ocurrido\nMayor interés en la predicción que en la inferencia\nPuede ser que no importe el mecanismo"
  },
  {
    "objectID": "archive/2023-03-Uniandes/1-introduccion.html#otra-clasificación-es",
    "href": "archive/2023-03-Uniandes/1-introduccion.html#otra-clasificación-es",
    "title": "1 - Introducción a Machine Learning in tidymodels",
    "section": "Otra clasificación es",
    "text": "Otra clasificación es\n\nModelos explicativos\nModelos predictivos"
  },
  {
    "objectID": "archive/2023-03-Uniandes/1-introduccion.html#machine-learning",
    "href": "archive/2023-03-Uniandes/1-introduccion.html#machine-learning",
    "title": "1 - Introducción a Machine Learning in tidymodels",
    "section": "Machine Learning",
    "text": "Machine Learning\nMuchos modelos de machine learning son predictivos por ejemplo:\n\nk-nearest neighbors\nÁrboles de decisión\nRandom Forests\nSupport Vector Machines"
  },
  {
    "objectID": "archive/2023-03-Uniandes/1-introduccion.html#machine-learning-1",
    "href": "archive/2023-03-Uniandes/1-introduccion.html#machine-learning-1",
    "title": "1 - Introducción a Machine Learning in tidymodels",
    "section": "Machine Learning",
    "text": "Machine Learning\n\nMachine LearningUnsupervisedSupervised\n\n\n\n\n\nNo hay una variable de resultado\n\nComponentes principales\n\n\n\n\nHay una variable de resultado\n\nRegresión: variable de resultado continua\nClasificación: variable de resultado categórica"
  },
  {
    "objectID": "archive/2023-03-Uniandes/1-introduccion.html#cuál-es-el-proceso-del-análisis-de-datos",
    "href": "archive/2023-03-Uniandes/1-introduccion.html#cuál-es-el-proceso-del-análisis-de-datos",
    "title": "1 - Introducción a Machine Learning in tidymodels",
    "section": "Cuál es el proceso del análisis de datos",
    "text": "Cuál es el proceso del análisis de datos\n\n\n¿La creación del modelo es el primer paso?\n¿Limpiar los datos?\n¿Explorar los datos?\n¿Cómo se van a evaluar los modelos?"
  },
  {
    "objectID": "archive/2023-03-Uniandes/1-introduccion.html#gráfico-del-proceso-de-análisis-de-datos",
    "href": "archive/2023-03-Uniandes/1-introduccion.html#gráfico-del-proceso-de-análisis-de-datos",
    "title": "1 - Introducción a Machine Learning in tidymodels",
    "section": "Gráfico del proceso de análisis de datos",
    "text": "Gráfico del proceso de análisis de datos"
  },
  {
    "objectID": "archive/2023-03-Uniandes/1-introduccion.html#proceso-de-análisis-de-datos",
    "href": "archive/2023-03-Uniandes/1-introduccion.html#proceso-de-análisis-de-datos",
    "title": "1 - Introducción a Machine Learning in tidymodels",
    "section": "Proceso de análisis de datos",
    "text": "Proceso de análisis de datos\n\n\n\nExplorar los datos (EDA)\n“Ingeniería de variables”- crear nuevas variables\nAjustar-sintonizar los modelos\nEvaluar los modelos"
  },
  {
    "objectID": "archive/2023-03-Uniandes/1-introduccion.html#tres-ideas-importantes",
    "href": "archive/2023-03-Uniandes/1-introduccion.html#tres-ideas-importantes",
    "title": "1 - Introducción a Machine Learning in tidymodels",
    "section": "Tres ideas importantes",
    "text": "Tres ideas importantes\n\n\nUtilizar la muestra para estimar el error de generalización\nDescomponer el error en tres fuentes: varianza, sesgo y ruido.\nUtilizar recursos computacionales"
  },
  {
    "objectID": "archive/2023-03-Uniandes/1-introduccion.html#cuál-es-el-mejor-sofware-para-hacer-esto",
    "href": "archive/2023-03-Uniandes/1-introduccion.html#cuál-es-el-mejor-sofware-para-hacer-esto",
    "title": "1 - Introducción a Machine Learning in tidymodels",
    "section": "¿Cuál es el mejor sofware para hacer esto?",
    "text": "¿Cuál es el mejor sofware para hacer esto?\n\n\n\nPython\nR\nJulia\nMatlab\nProgramas\n\nMplus\nStata\nSAS\nSPSS"
  },
  {
    "objectID": "archive/2023-03-Uniandes/1-introduccion.html#tidyverse",
    "href": "archive/2023-03-Uniandes/1-introduccion.html#tidyverse",
    "title": "1 - Introducción a Machine Learning in tidymodels",
    "section": "Tidyverse",
    "text": "Tidyverse\n\n\nggplot2 - para visualización de gráficos\ndplyr - para el procesamiento de datos\ntidyr - para la transformación de datos en formato “tidy” (ordenado)\nreadr - para la lectura de datos en diferentes formatos (CSV, TSV, etc.)\npurrr - para la programación funcional\ntibble - para la creación de data frames en formato “tidy”\nstringr - para la manipulación de cadenas de texto\nforcats- para la manipulación de factores"
  },
  {
    "objectID": "archive/2023-03-Uniandes/1-introduccion.html#tidyverse-1",
    "href": "archive/2023-03-Uniandes/1-introduccion.html#tidyverse-1",
    "title": "1 - Introducción a Machine Learning in tidymodels",
    "section": "Tidyverse",
    "text": "Tidyverse\n\nEstilo\n\nPipe\nnombre_de_los_objetos\nuso de las comillas\nretorna un objeto de la misma clase\nprogramación funcional\n\n\n\n\n\nMachine Learning"
  },
  {
    "objectID": "archive/2023-03-Uniandes/3-modelos.html#agenda",
    "href": "archive/2023-03-Uniandes/3-modelos.html#agenda",
    "title": "3. Estimar un modelo",
    "section": "Agenda",
    "text": "Agenda\nParte I\n\nEspecificar un modelo\nEstimar un modelo\nVer los resultados del modelo\n\nParte II\n\nDividir los datos\nEspecificar un modelo\nEstimar un modelo\nEvaluar el modelo\nEstimar un modelo mejor"
  },
  {
    "objectID": "archive/2023-03-Uniandes/3-modelos.html#estimar-un-modelo",
    "href": "archive/2023-03-Uniandes/3-modelos.html#estimar-un-modelo",
    "title": "3. Estimar un modelo",
    "section": "Estimar un modelo",
    "text": "Estimar un modelo\n\nHay muchas formas de estimar modelos en R\n\nlm(formula, data, ...)\nstan_glm(formula, data, family= \"gaussian\",...)\nglmnet(x=matrix, y=vector, family=\"gaussian\",...)\n\n\n\n\n\n\n\nTip\n\n\nlm(): Ajusta un modelo de regresión lineal a los datos.\nstan_glm(): Ajusta un modelo de regresión utilizando el paquete Stan.\nglmnet(): Ajusta un modelo de regresión utilizando la regularización Lasso o Ridge."
  },
  {
    "objectID": "archive/2023-03-Uniandes/3-modelos.html#especificar-el-modelo-en-tidymodels",
    "href": "archive/2023-03-Uniandes/3-modelos.html#especificar-el-modelo-en-tidymodels",
    "title": "3. Estimar un modelo",
    "section": "Especificar el modelo en tidymodels",
    "text": "Especificar el modelo en tidymodels\nTidymodels ofrece una sintaxis general para estimar los modelos\nhttps://www.tidymodels.org/\n\nEspecificar el tipo de modelo\n\nlinear_reg(), logistic_reg(), decition_tree()\n\nEspecificar el tipo de outcome\n\nRegresión para outcomes continuos\nClasificación: multinomial, ordinal, binaria\n\n\n\n\nlibrary(tidymodels)\n\ntidymodels_prefer()\n\nlinear_reg() |&gt; \n  set_engine(\"lm\") \n\nlinear_reg() |&gt; \n    set_engine(\"glmnet\") \n    \nlinear_reg() |&gt;\n    set_engine(\"stan\")"
  },
  {
    "objectID": "archive/2023-03-Uniandes/3-modelos.html#especificar-el-modelo-en-tidymodels-1",
    "href": "archive/2023-03-Uniandes/3-modelos.html#especificar-el-modelo-en-tidymodels-1",
    "title": "3. Estimar un modelo",
    "section": "Especificar el modelo en tidymodels",
    "text": "Especificar el modelo en tidymodels\n\n\n\n\n\n\nTip\n\n\nlibrary(): Carga el paquete tidymodels en R.\ntidymodels_prefer(): Establece el paquete tidymodels como el preferido para las funciones de modelado en R.\nlinear_reg(): Crea una especificación de modelo de regresión lineal en el marco de trabajo tidymodels.\nset_engine(): Establece el motor de cálculo para un objeto de especificación de modelo. Se establece en “lm” para la primera llamada a linear_reg(), “glmnet” para la segunda llamada y “stan” para la tercera."
  },
  {
    "objectID": "archive/2023-03-Uniandes/3-modelos.html#estimar-un-modelo-1",
    "href": "archive/2023-03-Uniandes/3-modelos.html#estimar-un-modelo-1",
    "title": "3. Estimar un modelo",
    "section": "Estimar un modelo",
    "text": "Estimar un modelo\nEstimar un modelo de regresión logistica para evaluar la asociación entre el consumo de alcohol y los factores de riesgo\n\nmini_datos |&gt;\n    select(PYALC,factores_de_riesgo) |&gt;\n    table1::table1( ~ ., data=_)\n\n\n\nmini_datos |&gt;\n    select(PYALC,factores_de_riesgo) |&gt;\n    filter(!is.na(PYALC)) |&gt; \n    table1::table1( ~ . | PYALC, data=_)"
  },
  {
    "objectID": "archive/2023-03-Uniandes/3-modelos.html#explorar-los-datos-visualmente",
    "href": "archive/2023-03-Uniandes/3-modelos.html#explorar-los-datos-visualmente",
    "title": "3. Estimar un modelo",
    "section": "Explorar los datos visualmente",
    "text": "Explorar los datos visualmente\n\nmini_datos |&gt; \n  group_by(PYALC) |&gt; \n  summarise(across(\"CRPAD\":\"SPRPI\", \\(x) mean(x, na.rm = TRUE))) |&gt; \n  pivot_longer(-PYALC) |&gt; \n  filter(!is.na(PYALC)) |&gt; \n  ggplot(aes(value, fct_reorder(name, value), fill = PYALC)) +\n  geom_col(alpha = 0.8, position = \"dodge\") +\n  scale_x_continuous() +\n  labs(x = \"Promedio\", y = NULL, fill = NULL)"
  },
  {
    "objectID": "archive/2023-03-Uniandes/3-modelos.html#especificar-el-modelo",
    "href": "archive/2023-03-Uniandes/3-modelos.html#especificar-el-modelo",
    "title": "3. Estimar un modelo",
    "section": "1. Especificar el modelo",
    "text": "1. Especificar el modelo\n\nlm_model &lt;-\n    logistic_reg() %&gt;% \n    set_engine(\"glm\", family=\"binomial\") |&gt;\n    set_mode(\"classification\")\n\n\nEspecificar un modelo de regresión logística. Se establece el “paquete”, en este caso “glm” y opciones del paquete (la distribución de la variable de respuesta). Además, se establece el modo de modelado en “classification” para indicar que es una variable categórica. El resultado se almacena en el objeto lm_model."
  },
  {
    "objectID": "archive/2023-03-Uniandes/3-modelos.html#estimar-el-modelo",
    "href": "archive/2023-03-Uniandes/3-modelos.html#estimar-el-modelo",
    "title": "3. Estimar un modelo",
    "section": "2. Estimar el modelo",
    "text": "2. Estimar el modelo\n\nlm_results &lt;- lm_model |&gt;\n    fit(PYALC ~ ., data = mini_datos)\n\n\nAquí se ajusta-estima el modelo utilizando la función fit(). Se especifica la variable de respuesta (PYALC) y los predictores (.) y se utiliza el objeto mini_datos como base de datos."
  },
  {
    "objectID": "archive/2023-03-Uniandes/3-modelos.html#ver-los-resultados-del-modelo",
    "href": "archive/2023-03-Uniandes/3-modelos.html#ver-los-resultados-del-modelo",
    "title": "3. Estimar un modelo",
    "section": "3. Ver los resultados del modelo",
    "text": "3. Ver los resultados del modelo\n\nlm_results |&gt; tidy() \n\nlm_results |&gt; glance()\n\n\ntidy(): Esta función se utiliza para convertir los resultados de un modelo en un marco de datos “ordenado” que muestra los coeficientes del modelo, los errores estándar, los valores t y los valores p para cada variable independiente.\nglance(): Esta función se utiliza para resumir los resultados de un modelo como estadísticas globales del modelo, por ejemplo, R-cuadrado ajustado, el AIC y el BIC.\n\n\n\n\n\n\n\nTip\n\n\n\nlm_results |&gt; tidy(exp=TRUE, conf.int=TRUE)\n\ntidy(exp=TRUE, conf.int=TRUE): Esta función se utiliza para convertir los resultados de un modelo en un marco de datos “ordenado” que muestra los coeficientes del modelo, los errores estándar, los valores t y los valores p para cada variable independiente. Los argumentos exp y conf.int se utilizan para incluir los intervalos de confianza y los exponentes en los resultados"
  },
  {
    "objectID": "archive/2023-03-Uniandes/3-modelos.html#para-qué-necesitamos-los-datos",
    "href": "archive/2023-03-Uniandes/3-modelos.html#para-qué-necesitamos-los-datos",
    "title": "3. Estimar un modelo",
    "section": "Para qué necesitamos los datos?",
    "text": "Para qué necesitamos los datos?\nNecesitamos:\n- Estimar parametros\n- Seleccionar modelos\n- Sintonizar los modelos (tunning)\n- Evaluar los modelos\n¿Cómo gastarnos los datos de una forma que sea eficiente para todos estos pasos? (validación empírica)"
  },
  {
    "objectID": "archive/2023-03-Uniandes/3-modelos.html#dividir-los-datos",
    "href": "archive/2023-03-Uniandes/3-modelos.html#dividir-los-datos",
    "title": "3. Estimar un modelo",
    "section": "Dividir los datos",
    "text": "Dividir los datos\n\nDividir los datos en dos conjuntos\n\nEntrenamiento\n\nLa mayoría de los datos (¿70%, 80%?)\nAquí se ajusta el modelo\n\nPrueba\n\nUn pequeño conjunto de datos\nAquí se evaluará el modelo final\n\n\n\nLos datos de prueba se utilizan una sola vez, si se utilizan más de una vez, se convierten en parte del proceso de entrenamiento.\n\nLa división de los datos se hace al nivel de unidad independiente de observación."
  },
  {
    "objectID": "archive/2023-03-Uniandes/3-modelos.html#dividir-los-datos-1",
    "href": "archive/2023-03-Uniandes/3-modelos.html#dividir-los-datos-1",
    "title": "3. Estimar un modelo",
    "section": "Dividir los datos",
    "text": "Dividir los datos\nCrear dos bases: 80% y 20%\n\nset.seed(1234)\n\nmini_datos &lt;- mini_datos |&gt; drop_na()\n\ndatos_divididos &lt;- initial_split(mini_datos, prop = 0.8, strata = \"PYALC\")\n\ndatos_entrenamiento &lt;- training(datos_divididos)\ndatos_prueba &lt;- testing(datos_divididos)\n\n\nLa opción strata es para que los datos de entrenamiento y prueba tengan la misma distribución de la variable PYALC\n\nA veces la selección aleatoria de la muestra es problemática, por ejemplo cuando hay una componente de tiempo en los datos. En este caso, se puede usar la función initial_time_split()."
  },
  {
    "objectID": "archive/2023-03-Uniandes/3-modelos.html#dividir-los-datos-2",
    "href": "archive/2023-03-Uniandes/3-modelos.html#dividir-los-datos-2",
    "title": "3. Estimar un modelo",
    "section": "Dividir los datos",
    "text": "Dividir los datos\nset.seed(): se utiliza para establecer una semilla para la generación de números aleatorios en R. En este caso, se utiliza para establecer la semilla en 1234, lo que garantiza que los resultados sean reproducibles. Esto es especialmente importante cuando se trabaja con modelos de aprendizaje automático, ya que los resultados pueden variar según la semilla utilizada para la generación de números aleatorios.\ndrop_na(): Esta función se utiliza para eliminar filas con valores faltantes de un data frame o tibble. En este caso, se utiliza para eliminar filas con valores faltantes del objeto “mini_datos”.\ninitial_split(): Esta función se utiliza para dividir un data frame o tibble en conjuntos de entrenamiento y prueba. En este caso, se utiliza para dividir el objeto “mini_datos” en conjuntos de entrenamiento y prueba en una proporción de 80/20, y estratificando por la columna “PYALC”.\ntraining(): Esta función se utiliza para extraer el conjunto de entrenamiento de un objeto creado con la función initial_split(). En este caso, se utiliza para extraer el conjunto de entrenamiento del objeto “datos_divididos”.\ntesting(): Esta función se utiliza para extraer el conjunto de prueba de un objeto creado con la función initial_split(). En este caso, se utiliza para extraer el conjunto de prueba del objeto “datos_divididos”."
  },
  {
    "objectID": "archive/2023-03-Uniandes/3-modelos.html#especificar-el-modelo-1",
    "href": "archive/2023-03-Uniandes/3-modelos.html#especificar-el-modelo-1",
    "title": "3. Estimar un modelo",
    "section": "1. Especificar el modelo",
    "text": "1. Especificar el modelo\n\nlm_model &lt;-\n  logistic_reg() %&gt;%\n  set_engine(\"glm\", family = \"binomial\") |&gt;\n  set_mode(\"classification\")"
  },
  {
    "objectID": "archive/2023-03-Uniandes/3-modelos.html#estimar-el-modelo-1",
    "href": "archive/2023-03-Uniandes/3-modelos.html#estimar-el-modelo-1",
    "title": "3. Estimar un modelo",
    "section": "2. Estimar el modelo",
    "text": "2. Estimar el modelo\n\nlm_results &lt;- lm_model |&gt;\n    fit(PYALC ~ ., data = datos_entrenamiento)"
  },
  {
    "objectID": "archive/2023-03-Uniandes/3-modelos.html#ver-los-resultados-del-modelo-1",
    "href": "archive/2023-03-Uniandes/3-modelos.html#ver-los-resultados-del-modelo-1",
    "title": "3. Estimar un modelo",
    "section": "3. Ver los resultados del modelo",
    "text": "3. Ver los resultados del modelo\n\nlm_results |&gt; tidy()\n\n\nlm_results |&gt; tidy(exp=TRUE, conf.int=TRUE)"
  },
  {
    "objectID": "archive/2023-03-Uniandes/3-modelos.html#evaluar-el-modelo",
    "href": "archive/2023-03-Uniandes/3-modelos.html#evaluar-el-modelo",
    "title": "3. Estimar un modelo",
    "section": "4. Evaluar el modelo",
    "text": "4. Evaluar el modelo\n\npredecir_estos_valores &lt;- datos_entrenamiento %&gt;% \n    select(-PYALC) %&gt;% \n    slice(1:10)\n\npredict(lm_results, predecir_estos_valores)\n\n\npredict(lm_results, predecir_estos_valores, type=\"prob\")\n\n\nentrenamiento &lt;- datos_entrenamiento %&gt;% \n    select(-PYALC)\n\nprediccion &lt;- predict(lm_results, entrenamiento)\n\nresultados_prueba &lt;- cbind(prediccion, datos_entrenamiento) |&gt; \n  select(.pred_class, PYALC, everything()) |&gt; \n  tibble()"
  },
  {
    "objectID": "archive/2023-03-Uniandes/3-modelos.html#calcular-las-métricas",
    "href": "archive/2023-03-Uniandes/3-modelos.html#calcular-las-métricas",
    "title": "3. Estimar un modelo",
    "section": "Calcular las métricas",
    "text": "Calcular las métricas\n\nconf_mat(resultados_prueba, truth = PYALC,\n         estimate = .pred_class)\n\naccuracy(resultados_prueba, truth = PYALC,\n         estimate = .pred_class)\n\nsens(resultados_prueba, truth = PYALC,\n    estimate = .pred_class)"
  },
  {
    "objectID": "archive/2023-03-Uniandes/3-modelos.html#calcular-las-métricas-1",
    "href": "archive/2023-03-Uniandes/3-modelos.html#calcular-las-métricas-1",
    "title": "3. Estimar un modelo",
    "section": "Calcular las métricas",
    "text": "Calcular las métricas\n\nspec(resultados_prueba, truth = PYALC,\n    estimate = .pred_class)\n\nprecision(resultados_prueba, truth = PYALC,\n    estimate = .pred_class)\n\nrecall(resultados_prueba, truth = PYALC,\n    estimate = .pred_class)\n\nkap(resultados_prueba, truth = PYALC,\n    estimate = .pred_class)"
  },
  {
    "objectID": "archive/2023-03-Uniandes/3-modelos.html#calcular-las-métricas-2",
    "href": "archive/2023-03-Uniandes/3-modelos.html#calcular-las-métricas-2",
    "title": "3. Estimar un modelo",
    "section": "Calcular las métricas",
    "text": "Calcular las métricas\n\ncustom_metrics &lt;- metric_set(accuracy, sens, spec, precision, recall, f_meas, kap, mcc)\n\ncustom_metrics(resultados_prueba,\n  truth = PYALC,\n  estimate = .pred_class\n)\n\nlm_metrics &lt;- custom_metrics(resultados_prueba,\n  truth = PYALC,\n  estimate = .pred_class\n) |&gt;\n  mutate(model = \"lm\")"
  },
  {
    "objectID": "archive/2023-03-Uniandes/3-modelos.html#tabla-de-métricas",
    "href": "archive/2023-03-Uniandes/3-modelos.html#tabla-de-métricas",
    "title": "3. Estimar un modelo",
    "section": "Tabla de Métricas",
    "text": "Tabla de Métricas\n\nlibrary(gt)\n\ncustom_metrics(resultados_prueba,\n  truth = PYALC,\n  estimate = .pred_class\n) |&gt; gt()"
  },
  {
    "objectID": "archive/2023-03-Uniandes/3-modelos.html#área-bajo-la-curva",
    "href": "archive/2023-03-Uniandes/3-modelos.html#área-bajo-la-curva",
    "title": "3. Estimar un modelo",
    "section": "Área bajo la curva",
    "text": "Área bajo la curva\n\nprediccion_auc &lt;- predict(lm_results, entrenamiento, type = \"prob\")\n\nresultados_prueba_auc &lt;- cbind(prediccion_auc, datos_entrenamiento) |&gt;\n  tibble()\n\nroc_auc(resultados_prueba_auc,\n  truth = PYALC,\n  `.pred_No ha consumido`\n)\n\nroc_curve(resultados_prueba_auc,\n  truth = PYALC,\n  `.pred_No ha consumido`\n) |&gt; autoplot()"
  },
  {
    "objectID": "archive/2023-03-Uniandes/5-forest.html#validación-cruzada",
    "href": "archive/2023-03-Uniandes/5-forest.html#validación-cruzada",
    "title": "5. Random Forest",
    "section": "Validación Cruzada",
    "text": "Validación Cruzada\nSupongamos que estamos trabajando en un problema de clasificación binaria y disponemos de un conjunto de datos con 1000 registros. Queremos evaluar el rendimiento de un modelo de regresión logística utilizando la validación cruzada k-fold.\nPaso a paso del proceso de k-fold cross-validation:\nDividir el conjunto de datos: Primero, dividimos el conjunto de datos en k subconjuntos (folds) de igual tamaño. En este ejemplo, elegimos k=10, lo que significa que dividimos el conjunto de datos en 10 subconjuntos de 100 registros cada uno.\nEntrenar y evaluar el modelo: Luego, realizamos lo siguiente para cada uno de los k subconjuntos:\n\nTomamos un subconjunto como el conjunto de prueba (validación) y los k-1 subconjuntos restantes como el conjunto de entrenamiento. Por ejemplo, en la primera iteración, usamos el primer subconjunto como conjunto de prueba y los subconjuntos del 2 al 10 como conjunto de entrenamiento.\nEntrenamos el modelo de regresión logística utilizando el conjunto de entrenamiento.\nEvaluamos el rendimiento del modelo en el conjunto de prueba utilizando una métrica adecuada, como la precisión, la exhaustividad o el F1-score. Anotamos el resultado de la métrica para esta iteración.\n\nPromediar los resultados: Después de completar las k iteraciones, calculamos la media de los resultados de la métrica para todas las iteraciones. Esta media nos proporciona una estimación más robusta del rendimiento del modelo, ya que el modelo ha sido evaluado en diferentes subconjuntos del conjunto de datos.\nhttps://scikit-learn.org/stable/modules/cross_validation.html https://www.tmwr.org/resampling.html"
  },
  {
    "objectID": "archive/2023-03-Uniandes/5-forest.html#cart",
    "href": "archive/2023-03-Uniandes/5-forest.html#cart",
    "title": "5. Random Forest",
    "section": "CART",
    "text": "CART\nHay tres variables que están más relacionadas con no consumir alcohol.\n\ncrossvalidation &lt;-\n  vfold_cv(datos_entrenamiento, \n           v = 5,  # número de cajas\n           strata = \"PYALC\")\n\n\ntree_spec &lt;- \n  decision_tree(\n    cost_complexity = tune(), \n    tree_depth = tune(),\n    min_n = tune()\n  ) |&gt; \n  set_mode(\"classification\") |&gt; \n  set_engine(\"rpart\")\n\nCost_complexity (tmedida de complejidad alfa o parámetro de poda alfa):\nCost_complexity es un parámetro de regularización. Es una medida de la penalización que se aplica al árbol en función de su complejidad. Un valor más alto de cost_complexity implica una penalización más fuerte en la complejidad del árbol, lo que lleva a un árbol más pequeño y menos profundo. La idea es encontrar un valor óptimo de cost_complexity que equilibre la precisión y la complejidad del árbol, reduciendo tanto el sesgo como la varianza.\nTree_depth (profundidad del árbol):\nTree_depth se refiere a la longitud máxima del camino más largo desde la raíz hasta una hoja en un árbol de decisión. Un árbol más profundo es más complejo y puede capturar relaciones más complicadas en los datos. Sin embargo, un árbol demasiado profundo también puede ser propenso al sobreajuste, ya que puede adaptarse demasiado a las peculiaridades de los datos de entrenamiento.\nMin_n (mínimo número de muestras para dividir un nodo):\nMin_n es un parámetro que controla el número mínimo de datos requeridas para dividir un nodo en un árbol de decisión. Un valor más alto de min_n implica que el árbol será menos profundo, ya que se requerirán más muestras para realizar una división en cada nodo. Un valor más bajo de min_n permite que el árbol se divida más fácilmente y, por lo tanto, puede resultar en un árbol más complejo y profundo.\n\ntree_grid &lt;- grid_regular(cost_complexity(range = c(-10L, -1L)), \n                          tree_depth (range = c(5L, 10L)), \n                          min_n(range = c(5L, 30L)))\n\n\ndoParallel::registerDoParallel()\n\nset.seed(345)\ntree_rs &lt;-\n  tune_grid(\n    tree_spec,\n    PYALC ~ .,\n    resamples = crossvalidation,\n    grid = tree_grid,\n    metrics = metric_set(accuracy, roc_auc, sensitivity, specificity)\n  )\n\ndoParallel::stopImplicitCluster()\n\n\nshow_best(tree_rs)\n\nautoplot(tree_rs)\n\n\nsimpler_tree &lt;- select_best(tree_rs, min_n, metric = \"accuracy\")\n\nfinal_tree &lt;- finalize_model(tree_spec, simpler_tree)\n\n\nfinal_fit &lt;- fit(final_tree, PYALC ~ ., datos_entrenamiento)\n\n\nfinal_cart &lt;- last_fit(final_tree, PYALC ~ ., datos_divididos,\n  metrics = metric_set(accuracy, roc_auc, sensitivity, specificity)\n)\n\n\ncollect_metrics(final_cart)\n\n\ncart_trained &lt;- \n  final_cart  |&gt; extract_fit_parsnip()\n\ncart_tree_fit &lt;- cart_trained$fit\n\ntreemisc::tree_diagram(cart_tree_fit, roundint=FALSE)"
  },
  {
    "objectID": "archive/2023-03-Uniandes/5-forest.html#random-forest",
    "href": "archive/2023-03-Uniandes/5-forest.html#random-forest",
    "title": "5. Random Forest",
    "section": "Random Forest",
    "text": "Random Forest\n\nNúmero de predictores que se usan para cada árbol (mtry)\nNúmero de árboles (trees)\nProfundidad de los árboles (min_n)\n\nRandom Forest\n\nrf_spec &lt;- \n  rand_forest()  |&gt; \n  set_mode(\"classification\") |&gt; \n  set_engine(\"ranger\", importance = \"permutation\")\n\n\nrf_results &lt;- rf_spec |&gt; \nfit(PYALC ~ ., data = datos_entrenamiento)\n\nlibrary(vip)\nimportance_plot_rf &lt;- \n  rf_results |&gt; \n  vip() +\n  ggtitle(\"Random Forest\")\n\n\nrf_predicciones &lt;- predict(rf_results, entrenamiento)\n\nresultados_rf &lt;- cbind(rf_predicciones,datos_entrenamiento) |&gt; \n  tibble()\n\nrf_metrics &lt;- custom_metrics(resultados_rf,\n               truth = PYALC,\n               estimate = .pred_class) |&gt;\n  mutate(model=\"rf\")\n\nrbind(rf_metrics, tree2_metrics, tree_metrics, lm_metrics) |&gt; \n  pivot_wider(names_from = model, values_from = .estimate)\n\n\nrf_predicciones &lt;- cbind(predict(rf_results, datos_prueba), datos_prueba2_out) |&gt;  mutate(model=\"rf\")\n\nall_models &lt;- \nrbind(lm_predicciones, rf_predicciones,tree_predicciones, tree2_predicciones) \n\n\nall_models2 &lt;- all_models |&gt; \n  group_split(model) %&gt;%\n   setNames(unique(all_models$model)) %&gt;%\n  map_dfr(., ~custom_metrics(.x,\n               truth = PYALC,\n               estimate = .pred_class), .id = \"names\")\nall_models2 |&gt; \n  pivot_wider(names_from = names, values_from = .estimate)"
  },
  {
    "objectID": "archive/2023-03-Uniandes/5-forest.html#sesgo-y-varianza",
    "href": "archive/2023-03-Uniandes/5-forest.html#sesgo-y-varianza",
    "title": "5. Random Forest",
    "section": "Sesgo y varianza",
    "text": "Sesgo y varianza\nEstos dos conceptos son cruciales para entender el equilibrio entre la complejidad del modelo y su capacidad para generalizar a nuevos datos.\nSesgo (Bias): a. Definición: El sesgo es la diferencia entre la predicción promedio de nuestro modelo y el valor verdadero que intentamos predecir.El sesgo, en términos estadísticos, se refiere a la diferencia sistemática entre la esperanza (o promedio) de las estimaciones que produce un estimador y el valor real del parámetro que se desea estimar. Un modelo con alta varianza es muy sensible a pequeñas variaciones en los datos de entrenamiento, lo que puede resultar en un sobreajuste. Es decir, el modelo se ajusta muy bien a los datos de entrenamiento, pero tiene un rendimiento deficiente en datos no vistos o de prueba.\n\nEjemplo: Un modelo de regresión lineal simple podría tener un alto sesgo si los datos reales tienen una relación no lineal.\nImplicaciones: Un modelo con alto sesgo es demasiado simple y no captura la estructura subyacente de los datos. Esto conduce a un bajo rendimiento en el conjunto de entrenamiento y prueba.\n\nVarianza (Variance): a. Definición: La varianza es la cantidad de variabilidad en las predicciones del modelo para un punto de datos dado. b. Ejemplo: Un modelo de árbol de decisión muy profundo podría tener alta varianza, ya que es muy sensible a pequeñas variaciones en los datos de entrenamiento. c. Implicaciones: Un modelo con alta varianza tiende a sobreajustarse a los datos de entrenamiento, lo que resulta en un buen rendimiento en el conjunto de entrenamiento pero un bajo rendimiento en el conjunto de prueba.\nEl objetivo en Machine Learning es equilibrar el sesgo y la varianza para minimizar el error de predicción general en el modelo a. Objetivo: Encontrar un equilibrio entre sesgo y varianza que minimice el error total de predicción. b. Estrategias: Seleccionar un modelo con la complejidad adecuada, usar técnicas de regularización, y validar el modelo con conjuntos de datos de entrenamiento y prueba separados.\nFormas de disminur el sesgo\nAumentar la complejidad del modelo: Un modelo más complejo puede capturar mejor la estructura subyacente de los datos. Por ejemplo, en lugar de utilizar una regresión lineal simple, podrías probar una regresión polinomial o un modelo de árbol de decisión.\nAñadir más variables: A veces, el sesgo puede ser el resultado de no tener en cuenta variables importantes que influyen en la variable objetivo. Añadir más variables relevantes puede ayudar a reducir el sesgo del modelo.\nUtilizar técnicas de “ingeniería de predictores”: Transformar o combinar las variables existentes para crear nuevas características puede ayudar a capturar mejor la relación entre las variables de entrada y salida. Por ejemplo, si estás trabajando en un problema de predicción de precios de viviendas, podrías crear una nueva característica que represente la relación entre el tamaño de la casa y el número de habitaciones.\nAumentar el tamaño del conjunto de datos: Si tu conjunto de datos es pequeño o no es representativo de la población general, es posible que el modelo tenga un sesgo alto. Aumentar el tamaño del conjunto de datos y asegurarte de que es representativo puede ayudar a reducir el sesgo.\nUtilizar ensembles de modelos: Combinar varios modelos en un ensemble puede ayudar a reducir el sesgo, ya que cada modelo puede capturar diferentes aspectos de la relación entre las variables de entrada y salida. Por ejemplo, puedes utilizar métodos de ensemble como Bagging, Boosting o Stacking."
  },
  {
    "objectID": "archive/2023-03-Uniandes/5-forest.html#técnicas-para-reducir-la-varianza",
    "href": "archive/2023-03-Uniandes/5-forest.html#técnicas-para-reducir-la-varianza",
    "title": "5. Random Forest",
    "section": "Técnicas para reducir la varianza",
    "text": "Técnicas para reducir la varianza\nReducir la complejidad del modelo: Un modelo más simple tiende a tener una menor varianza y es menos propenso al sobreajuste. Por ejemplo, podrías limitar la profundidad de un árbol de decisión.\nUtilizar regularización: La regularización es una técnica que añade una penalización a los coeficientes del modelo para evitar que se ajusten demasiado a los datos de entrenamiento.Por ejemplo, regularización L1 (Lasso) y L2 (Ridge).\nAumentar el tamaño del conjunto de datos: Si dispones de más datos, el modelo será menos sensible a pequeñas variaciones en los datos de entrenamiento y tendrá una menor varianza.\nEliminar características ruidosas: Si tu modelo incluye características que no están relacionadas con la variable objetivo o que contienen mucho ruido, estas pueden aumentar la varianza del modelo. Realizar un análisis de importancia de características y eliminar las características poco importantes puede ayudar a reducir la varianza.\nValidación cruzada (cross-validation): Utilizar la validación cruzada, como k-fold cross-validation, te permite evaluar el rendimiento del modelo en diferentes subconjuntos del conjunto de datos de entrenamiento. Esto puede ayudarte a identificar si el modelo está sobreajustando los datos y ajustar la complejidad del modelo en consecuencia.\nUtilizar diferentes modelos: Combinar varios modelos en un ensemble puede ayudar a reducir la varianza, ya que la variabilidad de cada modelo individual se promedia. Por ejemplo, puedes utilizar métodos de ensemble como Bagging (Bootstrap Aggregating) o Random Forest, que promedian las predicciones de múltiples árboles de decisión entrenados en subconjuntos aleatorios de los datos.\n\n\n\nMachine Learning"
  },
  {
    "objectID": "archive/2023-03-Uniandes/7-regularizacion.html#usar-recetas",
    "href": "archive/2023-03-Uniandes/7-regularizacion.html#usar-recetas",
    "title": "7. Regularización",
    "section": "Usar recetas",
    "text": "Usar recetas\nConstruir la receta:\nrecipe(punt_matematicas_11 ~ ., data = datos_entrenamiento) crea un objeto recipe que especifica que se va a predecir la variable punt_matematicas_11 usando todas las otras variables (.) en los datos de entrenamiento datos_entrenamiento.\nstep_mutate(across(everything(), ~ if_else(.x == \"NA\", NA, .x))) reemplaza todos los valores de “NA” en todas las columnas con el valor NA. Esto se hace para asegurarse de que los datos faltantes estén representados correctamente en el conjunto de datos.\nstep_mutate(estu_cod_mcpio_presentacion_9 = as_factor(estu_cod_mcpio_presentacion_9)) convierte la columna estu_cod_mcpio_presentacion_9 a un factor. Esto es necesario porque esta columna representa códigos de municipios y no debería tratarse como una variable numérica continua.\nstep_mutate(estu_cod_depto_presentacion_9 = as_factor(estu_cod_depto_presentacion_9)) convierte la columna estu_cod_depto_presentacion_9 a un factor. Esto se hace por la misma razón que en el paso anterior.\nstep_mutate(estu_edad_9 = as.numeric(str_extract_all(estu_edad_9, \"\\\\d+\"))) extrae los números de la columna estu_edad_9 y los convierte a valores numéricos. Esto se hace para asegurarse de que la variable se trate como numérica en lugar de como un factor.\nstep_mutate(fami_cuartoshogar_9 = if_else(fami_cuartoshogar_9 == \"NA\", NA, fami_cuartoshogar_9)) reemplaza los valores “NA” en la columna fami_cuartoshogar_9 con el valor NA. Esto es necesario para asegurarse de que los datos faltantes estén representados correctamente.\nstep_mutate(fami_cuartoshogar_9 = as.numeric(fami_cuartoshogar_9)) convierte la columna fami_cuartoshogar_9 a valores numéricos. Esto se hace porque esta variable representa el número de habitaciones en el hogar y se espera que sea una variable numérica.\nstep_impute_mode(all_nominal_predictors()) imputa los valores faltantes en todas las variables nominales (factores) con el modo (valor más común) de cada columna.\nstep_impute_mean(all_double()) imputa los valores faltantes en todas las variables continuas con la media de cada columna.\nstep_zv(all_predictors()) elimina las variables que tienen una varianza cero. Esto se hace para asegurarse de que las variables que no cambian en todo el conjunto de datos no estén incluidas en el modelo.\nstep_normalize(all_double_predictors()) normaliza todas las variables continuas para que tengan media cero y varianza unitaria. Esto se hace para asegurarse de que las variables estén en la misma métrica\n\nset.seed(2231)\n\nmini_datos &lt;- data_icfes |&gt;\n  select(contains(\"fami\"), starts_with(\"estu\"), \"punt_matematicas_11\") |&gt;\n  select(contains(\"9\"), \"punt_matematicas_11\") |&gt; tidyREDCap::drop_labels()\n\ndatos_divididos &lt;- initial_split(mini_datos, prop = 0.8)\n\ndatos_entrenamiento &lt;- training(datos_divididos)\ndatos_prueba &lt;- testing(datos_divididos)\n\nmean(datos_entrenamiento$punt_matematicas_11, na.rm = T)\nmean(datos_prueba$punt_matematicas_11, na.rm = T)\n\n\nreceta_lasso_2 &lt;- \n  recipe(punt_matematicas_11 ~ ., data = datos_entrenamiento) |&gt;\n  step_mutate(across(everything(), ~ if_else(.x == \"NA\", NA, .x))) |&gt;\n  step_mutate(estu_cod_mcpio_presentacion_9 = as_factor(estu_cod_mcpio_presentacion_9)) |&gt;\n  step_mutate(estu_cod_depto_presentacion_9 = as_factor(estu_cod_depto_presentacion_9)) |&gt;\n  step_mutate(estu_edad_9 = as.numeric(str_extract_all(estu_edad_9, \"\\\\d+\"))) |&gt;\n  step_mutate(fami_cuartoshogar_9 = if_else(fami_cuartoshogar_9 == \"NA\", NA, \n                                            fami_cuartoshogar_9)) |&gt;\n  step_mutate(fami_cuartoshogar_9 = as.numeric(fami_cuartoshogar_9)) |&gt;\n  step_impute_mode(all_nominal_predictors()) |&gt;\n  step_impute_mean(all_double()) |&gt;\n  step_zv(all_predictors()) |&gt;\n  step_normalize(all_double_predictors()) |&gt;\n  step_dummy(all_factor_predictors())\n\nAplicar la receta y obtener los datos transformados.\n\ndespues_receta &lt;- prep(receta_lasso) |&gt; bake(new_data = datos_entrenamiento)\n\n\nspec_lasso &lt;-\n  linear_reg(penalty = 0.5, mixture = 1) |&gt;\n  # En glmnet, mixture = 1 es un modelo lasso. Mixture = 0 es ridge regression.\n  set_engine(\"glmnet\") |&gt;\n  set_mode(\"regression\")\n\nEl segundo paso es crear un workflow. A ese workflow le vamos añadir diferentes pasos. Agregamos el modelo.\n\nwf2 &lt;-\n  workflow() |&gt;\n  add_model(spec_lasso)\n\nDespués agregarmos las transformaciones que debemos realizar a las variables.\n\nDummy\nCentrar\nEscalar\n\nCentrar los datos significa restar la media de una variable de los datos. Escalar los datos significa dividir sobre la desviación estándar.\nAhora podemos agregar la receta al workflow, para que se aplique a los datos antes de estimar el modelo\n\nwf2 &lt;- wf2 |&gt;\n  add_recipe(receta_lasso_2)\n\nEstimar el error en el training\n\nlasso_fit &lt;- wf2 |&gt; \n  last_fit(datos_divididos)\n\ncollect_metrics(lasso_fit)\n\n\nwf2 %&gt;%\n  fit(datos_entrenamiento) %&gt;%\n  extract_fit_parsnip() %&gt;%\n  vip::vi() %&gt;%\n  mutate(\n    Importance = abs(Importance),\n    Variable = fct_reorder(Variable, Importance)\n  ) %&gt;%\n  head(20) |&gt;\n  ggplot(aes(x = Importance, y = Variable, fill = Sign)) +\n  geom_col() +\n  scale_x_continuous(expand = c(0, 0)) +\n  labs(y = NULL) +\n  facet_wrap(~Sign, scales = \"free_y\") +\n  theme(legend.position = \"none\")\n\nEl paquete usemodels propone una manera de hacer el recipe, el engine y el workflow\n\nusemodels::use_ranger(punt_matematicas_11 ~ ., data = datos_entrenamiento)\n\n\n\n\nMachine Learning"
  },
  {
    "objectID": "archive/2023-10-Unal/crear-tablas.html#documentar-el-análisis-de-datos",
    "href": "archive/2023-10-Unal/crear-tablas.html#documentar-el-análisis-de-datos",
    "title": "Crear tablas en R",
    "section": "1.1 Documentar el análisis de datos",
    "text": "1.1 Documentar el análisis de datos\n\n\nReplicabilidad: Permite a otros investigadores o evaluadores replicar tus hallazgos.\nTransparencia: La documentación completa demuestra la integridad del proceso de investigación, lo que aumenta la confianza en los resultados.\nClaridad: Ayuda a clarificar los métodos y resultados.\nComunicación efectiva: Facilita la transferencia de conocimientos.\nRevisión por pares: Hace que el proceso de revisión por pares sea más eficiente.\n\nMejora continua: Te permite volver a visitar y refinar tu análisis en el futuro, o adaptarlo para abordar preguntas de investigación relacionadas.\nFormación y educación: Sirve como un recurso educativo para estudiantes o profesionales que estén aprendiendo cómo llevar a cabo análisis similares.\nResolución de problemas: Facilita la identificación y corrección de errores o inconsistencias en el análisis.\nEconomía de tiempo: Reduce el tiempo necesario para retomar o modificar el proyecto en fases posteriores de la investigación."
  },
  {
    "objectID": "archive/2023-10-Unal/crear-tablas.html#herramientas-para-documentar",
    "href": "archive/2023-10-Unal/crear-tablas.html#herramientas-para-documentar",
    "title": "Crear tablas en R",
    "section": "1.2. Herramientas para documentar",
    "text": "1.2. Herramientas para documentar\n\nCódigo (Programas estadísticos)\nQuarto (Rmarkdown)\nGit (Github)\nR (También sintaxis en spss, stata, etc)"
  },
  {
    "objectID": "archive/2023-10-Unal/crear-tablas.html#quarto",
    "href": "archive/2023-10-Unal/crear-tablas.html#quarto",
    "title": "Crear tablas en R",
    "section": "1.2.1 Quarto",
    "text": "1.2.1 Quarto\n\nQuarto permite crear documentos en varios formatos (PDF, HTML, Word).\nPermite integrar código de R, Python, etc.\nIntegrar tablas y gráficos.\nUnir código y texto."
  },
  {
    "objectID": "archive/2023-10-Unal/crear-tablas.html#descripción-de-la-base-de-datos",
    "href": "archive/2023-10-Unal/crear-tablas.html#descripción-de-la-base-de-datos",
    "title": "Crear tablas en R",
    "section": "2.1 Descripción de la base de datos",
    "text": "2.1 Descripción de la base de datos\nDatos de 71 participantes sobre sus evaluaciones sociomorales en cuatro situaciones de transgresión legal: 1) daño ambiental por minería ilegal, 2) linchamiento en caso de robo, 3) tráfico de químicos para cocaína y 4) porte de armas en público. El estudio examina juicios y justificaciones sobre si hay transgresión, la gravedad de dichas transgresiones y el castigo merecido. También se evalúan las creencias sobre si las transgresiones se deben a características disposicionales de los involucrados."
  },
  {
    "objectID": "archive/2023-10-Unal/crear-tablas.html#variables",
    "href": "archive/2023-10-Unal/crear-tablas.html#variables",
    "title": "Crear tablas en R",
    "section": "Variables",
    "text": "Variables\n\nlibrary(dataWorkshopUN)\nlibrary(gtsummary)\nlibrary(tidyverse)\nlibrary(gt)\n\ndata(datos_ley_moral)\n\n\n\nRows: 6,837\nColumns: 7\n$ ID          &lt;dbl&gt; 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2…\n$ SITUACIONES &lt;chr&gt; \"Daño ambiental\", \"Daño ambiental\", \"Daño ambiental\", \"Dañ…\n$ EDAD        &lt;dbl&gt; 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17…\n$ SEXO        &lt;chr&gt; \"H\", \"H\", \"H\", \"H\", \"H\", \"H\", \"H\", \"H\", \"H\", \"H\", \"H\", \"H\"…\n$ CATEGORIAS  &lt;chr&gt; \"Expectativa de transgresón\", \"Justificación de los desenl…\n$ CODIGOS     &lt;chr&gt; \"Transgresión\", \"Desconfianza institucional\", \"Recursos bá…\n$ RESPUESTA   &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1…"
  },
  {
    "objectID": "archive/2023-10-Unal/crear-tablas.html#información-en-la-base-de-datos",
    "href": "archive/2023-10-Unal/crear-tablas.html#información-en-la-base-de-datos",
    "title": "Crear tablas en R",
    "section": "Información en la base de datos",
    "text": "Información en la base de datos"
  },
  {
    "objectID": "archive/2023-10-Unal/crear-tablas.html#select",
    "href": "archive/2023-10-Unal/crear-tablas.html#select",
    "title": "Crear tablas en R",
    "section": "select()",
    "text": "select()\nEsta función permite seleccionar columnas.\n\ndatos_ley_moral  |&gt; \nselect(SITUACIONES, CODIGOS, RESPUESTA)  |&gt; \nhead(10)  |&gt; \ngt()\n\n\n\n\n\n\n\nSITUACIONES\nCODIGOS\nRESPUESTA\n\n\n\n\nDaño ambiental\nTransgresión\n0\n\n\nDaño ambiental\nDesconfianza institucional\n0\n\n\nDaño ambiental\nRecursos básicos, necesidades y oportunidades\n0\n\n\nDaño ambiental\nObjetivos personales y conveniencia\n0\n\n\nDaño ambiental\nCreencias y prácticas culturales\n0\n\n\nDaño ambiental\nJustificaciones morales\n0\n\n\nDaño ambiental\nReferencia a la experiencia\n0\n\n\nDaño ambiental\nAutoridad, reglas y consecuencias\n0\n\n\nDaño ambiental\nPrudencial\n0\n\n\nDaño ambiental\nOtros\n1"
  },
  {
    "objectID": "archive/2023-10-Unal/crear-tablas.html#filter",
    "href": "archive/2023-10-Unal/crear-tablas.html#filter",
    "title": "Crear tablas en R",
    "section": "filter()",
    "text": "filter()\nEsta función permite filtrar columnas.\n\ndatos_ley_moral  |&gt; \nselect(SITUACIONES, CODIGOS, RESPUESTA)  |&gt; \nfilter(SITUACIONES == \"Linchamiento\")  |&gt; \nhead(10)  |&gt; \ngt()\n\n\n\n\n\n\n\nSITUACIONES\nCODIGOS\nRESPUESTA\n\n\n\n\nLinchamiento\nTransgresión\n1\n\n\nLinchamiento\nDesconfianza institucional\n0\n\n\nLinchamiento\nRecursos básicos, necesidades y oportunidades\n0\n\n\nLinchamiento\nObjetivos personales y conveniencia\n0\n\n\nLinchamiento\nCreencias y prácticas culturales\n1\n\n\nLinchamiento\nJustificaciones morales\n0\n\n\nLinchamiento\nReferencia a la experiencia\n0\n\n\nLinchamiento\nAutoridad, reglas y consecuencias\n0\n\n\nLinchamiento\nPrudencial\n0\n\n\nLinchamiento\nOtros\n0"
  },
  {
    "objectID": "archive/2023-10-Unal/crear-tablas.html#mutate",
    "href": "archive/2023-10-Unal/crear-tablas.html#mutate",
    "title": "Crear tablas en R",
    "section": "mutate()",
    "text": "mutate()\nEsta función permite crear o modificar columnas\n\ndatos_ley_moral  |&gt; \nmutate(Edad_años = paste0(EDAD, \" años\"))  |&gt; \nselect(ID, Edad_años) |&gt; \nunique()  |&gt; \nhead(10)  |&gt; \ngt()\n\n\n\n\n\n\n\nID\nEdad_años\n\n\n\n\n2\n17 años\n\n\n3\n22 años\n\n\n5\n52 años\n\n\n7\n30 años\n\n\n8\n40 años\n\n\n10\n30 años\n\n\n11\n16 años\n\n\n13\n17 años\n\n\n14\n15 años\n\n\n15\n44 años"
  },
  {
    "objectID": "archive/2023-10-Unal/crear-tablas.html#tbl_summary",
    "href": "archive/2023-10-Unal/crear-tablas.html#tbl_summary",
    "title": "Crear tablas en R",
    "section": "tbl_summary()",
    "text": "tbl_summary()\ngtsummary es un paquete que permite crear tablas de resumen de datos. Algunas de sus ventajas son:\n\nPermite crear tablas de resumen de datos con una sintaxis sencilla.\nTablas de resumen para regresiones.\nExportar tablas a varios formatos (Word, PDF, HTML).\nPermite crear tablas con diferentes estilos.\nCalcula estadísticos y p-valores."
  },
  {
    "objectID": "archive/2023-10-Unal/crear-tablas.html#tbl_summary-1",
    "href": "archive/2023-10-Unal/crear-tablas.html#tbl_summary-1",
    "title": "Crear tablas en R",
    "section": "tbl_summary()",
    "text": "tbl_summary()\n\nCalcular la frecuencia y el porcentajes de participantes hombres y mujeres.\n\ndatos_ley_moral  |&gt; \nselect(ID, SEXO)  |&gt; \nunique()  |&gt; \ntbl_summary(include=-ID)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nN = 531\n\n\n\n\nSEXO\n\n\n\n\n    H\n35 (66%)\n\n\n    M\n18 (34%)\n\n\n\n1 n (%)"
  },
  {
    "objectID": "archive/2023-10-Unal/crear-tablas.html#tbl_summary-2",
    "href": "archive/2023-10-Unal/crear-tablas.html#tbl_summary-2",
    "title": "Crear tablas en R",
    "section": "tbl_summary()",
    "text": "tbl_summary()\nCalcular medidas de tendencia y dispersión\n\n\n\ndatos_ley_moral  |&gt; \nselect(ID, EDAD)  |&gt; \nunique()  |&gt; \ntbl_summary(include=EDAD)\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nN = 231\n\n\n\n\nEDAD\n29 (23, 45)\n\n\n\n1 Median (IQR)"
  },
  {
    "objectID": "archive/2023-10-Unal/crear-tablas.html#tbl_summary-3",
    "href": "archive/2023-10-Unal/crear-tablas.html#tbl_summary-3",
    "title": "Crear tablas en R",
    "section": "tbl_summary()",
    "text": "tbl_summary()\nElegir los estadísticos que se muestran en la tabla o el idioma.\n\n\n\ntheme_gtsummary_language(language = \"es\")\n\ndatos_ley_moral  |&gt; \nselect(EDAD)  |&gt; \nunique()  |&gt; \ntbl_summary(\nstatistic = EDAD ~ \"{mean} ({sd})\")\n\n\n\n\n\n\n\n\n\n\nCaracterística\nN = 231\n\n\n\n\nEDAD\n33 (13)\n\n\n\n1 Media (DE)"
  },
  {
    "objectID": "archive/2023-10-Unal/crear-tablas.html#tbl_summary-4",
    "href": "archive/2023-10-Unal/crear-tablas.html#tbl_summary-4",
    "title": "Crear tablas en R",
    "section": "tbl_summary()",
    "text": "tbl_summary()\n\n\n\ndatos_ley_moral  |&gt;\ndatos_organizados(\"Justificación de los desenlaces\")  |&gt; \ntbl_summary(include=-c(ID, SITUACIONES, SEXO, EDAD))  \n\n\n\n\n\n\n\nCaracterística\nN = 1591\n\n\n\n\nDesconfianza institucional\n17 (11%)\n\n\nRecursos básicos, necesidades y oportunidades\n23 (14%)\n\n\nObjetivos personales y conveniencia\n49 (31%)\n\n\nCreencias y prácticas culturales\n50 (31%)\n\n\nJustificaciones morales\n25 (16%)\n\n\nReferencia a la experiencia\n6 (3.8%)\n\n\nAutoridad, reglas y consecuencias\n13 (8.2%)\n\n\nPrudencial\n2 (1.3%)\n\n\nOtros\n7 (4.4%)\n\n\n\n1 n (%)\n\n\n\n\n\n\n\n\n\n\ndatos_ley_moral  |&gt;\ndatos_organizados(\"Justificación de los desenlaces\")  |&gt; \nselect(-c(ID, SITUACIONES, SEXO, EDAD)) |&gt; \ntbl_summary()   |&gt; \nmodify_table_body(\n    fun = ~ dplyr::arrange(.x, desc(readr::parse_number(stat_0)))\n  )\n\n\n\n\n\n\n\nCaracterística\nN = 1591\n\n\n\n\nCreencias y prácticas culturales\n50 (31%)\n\n\nObjetivos personales y conveniencia\n49 (31%)\n\n\nJustificaciones morales\n25 (16%)\n\n\nRecursos básicos, necesidades y oportunidades\n23 (14%)\n\n\nDesconfianza institucional\n17 (11%)\n\n\nAutoridad, reglas y consecuencias\n13 (8.2%)\n\n\nOtros\n7 (4.4%)\n\n\nReferencia a la experiencia\n6 (3.8%)\n\n\nPrudencial\n2 (1.3%)\n\n\n\n1 n (%)"
  },
  {
    "objectID": "archive/2023-10-Unal/crear-tablas.html#tbl_summary-5",
    "href": "archive/2023-10-Unal/crear-tablas.html#tbl_summary-5",
    "title": "Crear tablas en R",
    "section": "tbl_summary()",
    "text": "tbl_summary()\nLa opción by permite crear tablas por grupos.\n\ndatos_ley_moral  |&gt;\ndatos_organizados(\"Justificación de los desenlaces\")  |&gt; \ntbl_summary(by=SITUACIONES,\ninclude=-c(ID, SEXO, EDAD))  |&gt; \nmodify_table_body(\n    fun = ~ dplyr::arrange(.x, desc(readr::parse_number(stat_1)))\n  )  \n\n\n\n\n\n\n\nCaracterística\nDaño ambiental, N = 531\nLinchamiento, N = 531\nNarcotráfico, N = 531\n\n\n\n\nObjetivos personales y conveniencia\n24 (45%)\n1 (1.9%)\n24 (45%)\n\n\nAutoridad, reglas y consecuencias\n12 (23%)\n0 (0%)\n1 (1.9%)\n\n\nJustificaciones morales\n7 (13%)\n16 (30%)\n2 (3.8%)\n\n\nCreencias y prácticas culturales\n6 (11%)\n30 (57%)\n14 (26%)\n\n\nReferencia a la experiencia\n4 (7.5%)\n1 (1.9%)\n1 (1.9%)\n\n\nOtros\n4 (7.5%)\n2 (3.8%)\n1 (1.9%)\n\n\nDesconfianza institucional\n0 (0%)\n17 (32%)\n0 (0%)\n\n\nRecursos básicos, necesidades y oportunidades\n0 (0%)\n0 (0%)\n23 (43%)\n\n\nPrudencial\n0 (0%)\n0 (0%)\n2 (3.8%)\n\n\n\n1 n (%)"
  },
  {
    "objectID": "archive/2023-10-Unal/crear-tablas.html#añadir-detalles-a-las-tabla",
    "href": "archive/2023-10-Unal/crear-tablas.html#añadir-detalles-a-las-tabla",
    "title": "Crear tablas en R",
    "section": "Añadir detalles a las tabla",
    "text": "Añadir detalles a las tabla\n\ndatos_ley_moral  |&gt;\ndatos_organizados(\"Justificación de los juicios\")  |&gt; \ntbl_summary(\n    by = SITUACIONES,\n    include=-c(ID, SEXO, EDAD))   |&gt; \n     modify_table_body(\n    fun = ~ dplyr::arrange(.x, desc(readr::parse_number(stat_1)))\n  )  |&gt;\n    modify_header(\n        label= \"**Justificación de los juicios**\"\n    )"
  },
  {
    "objectID": "archive/2023-10-Unal/crear-tablas.html#añadir-detalles-a-las-tabla-1",
    "href": "archive/2023-10-Unal/crear-tablas.html#añadir-detalles-a-las-tabla-1",
    "title": "Crear tablas en R",
    "section": "Añadir detalles a las tabla",
    "text": "Añadir detalles a las tabla\n\n\n\n\n\n\n\n\nJustificación de los juicios\nDaño ambiental, N = 531\nLinchamiento, N = 531\nNarcotráfico, N = 531\n\n\n\n\nJustificaciones morales\n51 (96%)\n33 (62%)\n16 (30%)\n\n\nAutoridad, reglas y consecuencias\n2 (3.8%)\n22 (42%)\n23 (43%)\n\n\nPrudencial\n2 (3.8%)\n0 (0%)\n23 (43%)\n\n\nOtros\n2 (3.8%)\n0 (0%)\n4 (7.5%)\n\n\nRecursos básicos, necesidades y oportunidades\n0 (0%)\n2 (3.8%)\n9 (17%)\n\n\nObjetivos personales y conveniencia\n0 (0%)\n0 (0%)\n0 (0%)\n\n\nCreencias y prácticas culturales\n0 (0%)\n0 (0%)\n0 (0%)\n\n\nDesconfianza institucional\n0 (0%)\n12 (23%)\n0 (0%)\n\n\n\n1 n (%)"
  },
  {
    "objectID": "archive/2023-10-Unal/crear-tablas.html#añadir-detalles-a-las-tabla-2",
    "href": "archive/2023-10-Unal/crear-tablas.html#añadir-detalles-a-las-tabla-2",
    "title": "Crear tablas en R",
    "section": "Añadir detalles a las tabla",
    "text": "Añadir detalles a las tabla\n\ndatos_ley_moral  |&gt;\ndatos_organizados(\"Justificación de los juicios\")  |&gt; \ntbl_summary(\n    by = SITUACIONES,\n    include=-c(ID, SEXO, EDAD))   |&gt; \n     add_overall()  |&gt; \n     modify_table_body(\n    fun = ~ dplyr::arrange(.x, desc(readr::parse_number(stat_0)))\n  )  |&gt;\n    modify_header(\n        label= \"**Justificación de los juicios**\"\n    )  \n\n\n\n\n\n\n\nJustificación de los juicios\nGlobal, N = 1591\nDaño ambiental, N = 531\nLinchamiento, N = 531\nNarcotráfico, N = 531\n\n\n\n\nJustificaciones morales\n100 (63%)\n51 (96%)\n33 (62%)\n16 (30%)\n\n\nAutoridad, reglas y consecuencias\n47 (30%)\n2 (3.8%)\n22 (42%)\n23 (43%)\n\n\nPrudencial\n25 (16%)\n2 (3.8%)\n0 (0%)\n23 (43%)\n\n\nDesconfianza institucional\n12 (7.5%)\n0 (0%)\n12 (23%)\n0 (0%)\n\n\nRecursos básicos, necesidades y oportunidades\n11 (6.9%)\n0 (0%)\n2 (3.8%)\n9 (17%)\n\n\nOtros\n6 (3.8%)\n2 (3.8%)\n0 (0%)\n4 (7.5%)\n\n\nObjetivos personales y conveniencia\n0 (0%)\n0 (0%)\n0 (0%)\n0 (0%)\n\n\nCreencias y prácticas culturales\n0 (0%)\n0 (0%)\n0 (0%)\n0 (0%)\n\n\n\n1 n (%)"
  },
  {
    "objectID": "archive/2023-10-Unal/crear-tablas.html#add_p-value",
    "href": "archive/2023-10-Unal/crear-tablas.html#add_p-value",
    "title": "Crear tablas en R",
    "section": "Add_p value",
    "text": "Add_p value\n\ndatos_ley_moral  |&gt;\ndatos_organizados(\"Justificación de los juicios\")  |&gt; \ntbl_summary(\n    by = SITUACIONES,\n    include=-c(ID, SEXO, EDAD))   |&gt; \n     add_overall()  |&gt; \n     modify_table_body(\n    fun = ~ dplyr::arrange(.x, desc(readr::parse_number(stat_0)))\n  )  |&gt;\n    modify_header(\n        label= \"**Justificación de los juicios**\"\n    )   |&gt; \n    add_p()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nJustificación de los juicios\nGlobal, N = 1591\nDaño ambiental, N = 531\nLinchamiento, N = 531\nNarcotráfico, N = 531\np-valor2\n\n\n\n\nJustificaciones morales\n100 (63%)\n51 (96%)\n33 (62%)\n16 (30%)\n&lt;0.001\n\n\nAutoridad, reglas y consecuencias\n47 (30%)\n2 (3.8%)\n22 (42%)\n23 (43%)\n&lt;0.001\n\n\nPrudencial\n25 (16%)\n2 (3.8%)\n0 (0%)\n23 (43%)\n&lt;0.001\n\n\nDesconfianza institucional\n12 (7.5%)\n0 (0%)\n12 (23%)\n0 (0%)\n&lt;0.001\n\n\nRecursos básicos, necesidades y oportunidades\n11 (6.9%)\n0 (0%)\n2 (3.8%)\n9 (17%)\n0.001\n\n\nOtros\n6 (3.8%)\n2 (3.8%)\n0 (0%)\n4 (7.5%)\n0.2\n\n\nObjetivos personales y conveniencia\n0 (0%)\n0 (0%)\n0 (0%)\n0 (0%)\n\n\n\n\nCreencias y prácticas culturales\n0 (0%)\n0 (0%)\n0 (0%)\n0 (0%)\n\n\n\n\n\n1 n (%)\n\n\n2 prueba chi cuadrado de independencia; test exacto de Fisher"
  },
  {
    "objectID": "archive/2023-10-Unal/crear-tablas.html#escalas-gravedad-y-castigo",
    "href": "archive/2023-10-Unal/crear-tablas.html#escalas-gravedad-y-castigo",
    "title": "Crear tablas en R",
    "section": "Escalas gravedad y castigo",
    "text": "Escalas gravedad y castigo\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCaracterística\nGlobal, N = 1591\nDaño ambiental, N = 531\nLinchamiento, N = 531\nNarcotráfico, N = 531\n\n\n\n\nEscala de gravedad\n\n\n\n\n\n\n\n\n\n\n    1\n5 (3.1%)\n0 (0%)\n4 (7.5%)\n1 (1.9%)\n\n\n    2\n6 (3.8%)\n0 (0%)\n4 (7.5%)\n2 (3.8%)\n\n\n    3\n20 (13%)\n1 (1.9%)\n9 (17%)\n10 (19%)\n\n\n    4\n29 (18%)\n5 (9.4%)\n11 (21%)\n13 (25%)\n\n\n    5\n99 (62%)\n47 (89%)\n25 (47%)\n27 (51%)\n\n\nEscala de castigo\n\n\n\n\n\n\n\n\n\n\n    1\n11 (6.9%)\n0 (0%)\n7 (13%)\n4 (7.5%)\n\n\n    2\n10 (6.3%)\n0 (0%)\n7 (13%)\n3 (5.7%)\n\n\n    3\n46 (29%)\n3 (5.7%)\n15 (28%)\n28 (53%)\n\n\n    4\n38 (24%)\n16 (30%)\n14 (26%)\n8 (15%)\n\n\n    5\n54 (34%)\n34 (64%)\n10 (19%)\n10 (19%)\n\n\n\n1 n (%)"
  },
  {
    "objectID": "archive/2023-10-Unal/crear-tablas.html#escalas-gravedad-y-castigo-1",
    "href": "archive/2023-10-Unal/crear-tablas.html#escalas-gravedad-y-castigo-1",
    "title": "Crear tablas en R",
    "section": "Escalas gravedad y castigo",
    "text": "Escalas gravedad y castigo\n\ndatos_ley_moral  |&gt; \ndatos_organizados(\"Escalas gravedad y castigo\")   |&gt; \nfilter(SITUACIONES %in% c(\"Linchamiento\", \"Narcotráfico\"))  |&gt; \ntbl_summary(\n    by = SITUACIONES,\n    include=-c(ID, SEXO, EDAD),\n    type= list(`Escala de gravedad` ~ \"continuous\", \n    `Escala de castigo` ~ \"continuous\"), \n    statistic = all_continuous() ~ \"{mean}, ({sd})\")   |&gt; \n    add_p(test = list(\n          all_continuous() ~ \"paired.wilcox.test\"),\n        group = ID)  \n\n\n\n\n\n\n\nCaracterística\nLinchamiento, N = 531\nNarcotráfico, N = 531\np-valor2\n\n\n\n\nEscala de gravedad\n3.92, (1.28)\n4.19, (1.00)\n0.2\n\n\nEscala de castigo\n3.25, (1.28)\n3.32, (1.09)\n0.7\n\n\n\n1 Media, (DE)\n\n\n2 Wilcoxon signed rank test with continuity correction"
  },
  {
    "objectID": "archive/2023-10-Unal/crear-tablas.html#tablas-para-regresiones",
    "href": "archive/2023-10-Unal/crear-tablas.html#tablas-para-regresiones",
    "title": "Crear tablas en R",
    "section": "Tablas para regresiones",
    "text": "Tablas para regresiones\n\ndatos_ley_moral  |&gt; \n    datos_organizados(\"Escalas gravedad y castigo\")   |&gt; \n    filter(SITUACIONES %in% c(\"Linchamiento\", \"Narcotráfico\"))  %&gt;% \n    lm(`Escala de gravedad` ~ EDAD + SEXO + SITUACIONES, data = .)  \n\n\nCall:\nlm(formula = `Escala de gravedad` ~ EDAD + SEXO + SITUACIONES, \n    data = .)\n\nCoefficients:\n            (Intercept)                     EDAD                    SEXOM  \n               3.835985                 0.001162                 0.163164  \nSITUACIONESNarcotráfico  \n               0.264151  \n\n\nLa función lm() genera un resultado como este:\n\n\n\nCall:\nlm(formula = `Escala de gravedad` ~ EDAD + SEXO + SITUACIONES, \n    data = .)\n\nCoefficients:\n            (Intercept)                     EDAD                    SEXOM  \n               3.835985                 0.001162                 0.163164  \nSITUACIONESNarcotráfico  \n               0.264151"
  },
  {
    "objectID": "archive/2023-10-Unal/crear-tablas.html#tablas-para-regresiones-1",
    "href": "archive/2023-10-Unal/crear-tablas.html#tablas-para-regresiones-1",
    "title": "Crear tablas en R",
    "section": "Tablas para regresiones",
    "text": "Tablas para regresiones\n\ndatos_ley_moral  |&gt; \n    datos_organizados(\"Escalas gravedad y castigo\")   |&gt; \n    filter(SITUACIONES %in% c(\"Linchamiento\", \"Narcotráfico\"))  %&gt;% \n    lm(`Escala de gravedad` ~ EDAD + SEXO + SITUACIONES, data = .)  |&gt; \n    tbl_regression()\n\n\n\n\n\n\n\n\n\n\n\n\n\nCaracterística\nBeta\n95% CI1\np-valor\n\n\n\n\nEDAD\n0.00\n-0.02, 0.02\n0.9\n\n\nSEXO\n\n\n\n\n\n\n\n\n    H\n—\n—\n\n\n\n\n    M\n0.16\n-0.31, 0.64\n0.5\n\n\nSITUACIONES\n\n\n\n\n\n\n\n\n    Linchamiento\n—\n—\n\n\n\n\n    Narcotráfico\n0.26\n-0.18, 0.71\n0.2\n\n\n\n1 CI = Intervalo de confianza"
  },
  {
    "objectID": "archive/2023-10-Unal/crear-tablas.html#exportar-a-tablas-a-word",
    "href": "archive/2023-10-Unal/crear-tablas.html#exportar-a-tablas-a-word",
    "title": "Crear tablas en R",
    "section": "Exportar a tablas a word",
    "text": "Exportar a tablas a word\n\ntabla_gravedad_y_castigo &lt;- datos_ley_moral  |&gt; \ndatos_organizados(\"Escalas gravedad y castigo\")   |&gt; \nfilter(SITUACIONES %in% c(\"Linchamiento\", \"Narcotráfico\"))  |&gt; \ntbl_summary(\n    by = SITUACIONES,\n    include=-c(ID, SEXO, EDAD),\n    type= list(`Escala de gravedad` ~ \"continuous\", \n    `Escala de castigo` ~ \"continuous\"), \n    statistic = all_continuous() ~ \"{mean}, ({sd})\")   |&gt; \n    add_p(test = list(\n          all_continuous() ~ \"paired.wilcox.test\"),\n        group = ID)    |&gt; \n        as_gt()\n\ngt::gtsave(tabla_gravedad_y_castigo, \"tabla_gravedad_y_castigo.docx\")"
  },
  {
    "objectID": "archive/2023-11-icfes/1-introduccion.html#temas",
    "href": "archive/2023-11-icfes/1-introduccion.html#temas",
    "title": "1 - Introducción a Machine Learning",
    "section": "Temas",
    "text": "Temas\n\n\n\nTipos de modelos\n\nDescriptivo\nInferencial\nPredictivo\n\nMachine Learning - Supervised\n\nClasificación\nRegresión - Unsupervised\nClustering\n\nEquilibrio entre la varianza y el sesgo\nValidación Cruzada\n\n\n\nEvaluación de los Modelos - Separación entrenamiento y prueba - Remuestreo\n\nLeave One Out\nK-Fold\nBoostraping"
  },
  {
    "objectID": "archive/2023-11-icfes/1-introduccion.html#tipos-de-modelos",
    "href": "archive/2023-11-icfes/1-introduccion.html#tipos-de-modelos",
    "title": "1 - Introducción a Machine Learning",
    "section": "Tipos de modelos",
    "text": "Tipos de modelos\n\nDescriptivosInferencialPredictivo\n\n\n\nDescribir las características de unos datos\nVisualizar los datos\nResumir los datos\nGenerar hipótesis\n\n\n\n\nEstimar la probabilidad de que ocurra un evento\nProducir una estimación de un parámetro poblacional\nProbar una hipótesis\nIdea predeterminada y se prueba\nValor p, intervalo de confianza\n\n\n\n\nAnticipar el valor de una variable\nAplicar una regla a un evento que no ha ocurrido\nMayor interés en la predicción que en la inferencia\nPuede ser que no importe el mecanismo"
  },
  {
    "objectID": "archive/2023-11-icfes/1-introduccion.html#machine-learning",
    "href": "archive/2023-11-icfes/1-introduccion.html#machine-learning",
    "title": "1 - Introducción a Machine Learning",
    "section": "Machine Learning",
    "text": "Machine Learning\nAlgunos de los modelos que se pueden construir con Machine Learning, van a ser fundamentalmente modelos para predecir. Por ejemplo:\n\nk-Nearest Neighbors\nRandom Forests\nSupport Vector Machines"
  },
  {
    "objectID": "archive/2023-11-icfes/1-introduccion.html#machine-learning-1",
    "href": "archive/2023-11-icfes/1-introduccion.html#machine-learning-1",
    "title": "1 - Introducción a Machine Learning",
    "section": "Machine Learning",
    "text": "Machine Learning\n\nMachine LearningUnsupervisedSupervised\n\n\n\n\n\nNo hay una variable de resultado\n\nComponentes principales\n\n\n\n\nHay una variable de resultado\n\nRegresión: variable de resultado continua\nClasificación: variable de resultado categórica"
  },
  {
    "objectID": "archive/2023-11-icfes/1-introduccion.html#el-proceso-del-análisis-de-datos-en-machine-learning",
    "href": "archive/2023-11-icfes/1-introduccion.html#el-proceso-del-análisis-de-datos-en-machine-learning",
    "title": "1 - Introducción a Machine Learning",
    "section": "El proceso del análisis de datos en Machine Learning",
    "text": "El proceso del análisis de datos en Machine Learning"
  },
  {
    "objectID": "archive/2023-11-icfes/1-introduccion.html#proceso-de-análisis-de-datos",
    "href": "archive/2023-11-icfes/1-introduccion.html#proceso-de-análisis-de-datos",
    "title": "1 - Introducción a Machine Learning",
    "section": "Proceso de análisis de datos",
    "text": "Proceso de análisis de datos\n\n\n\nExplorar los datos (EDA)\n“Ingeniería de variables”- crear nuevas variables\nAjustar-sintonizar los modelos\nEvaluar los modelos"
  },
  {
    "objectID": "archive/2023-11-icfes/1-introduccion.html#tres-ideas-importantes-de-machine-learning",
    "href": "archive/2023-11-icfes/1-introduccion.html#tres-ideas-importantes-de-machine-learning",
    "title": "1 - Introducción a Machine Learning",
    "section": "Tres ideas importantes de Machine Learning",
    "text": "Tres ideas importantes de Machine Learning\n\n\nUtilizar la muestra para estimar el error de generalización\nDescomponer el error en tres fuentes: varianza, sesgo y ruido.\nRegularización para controlar la varianza y el sesgo"
  },
  {
    "objectID": "archive/2023-11-icfes/1-introduccion.html#cuál-es-el-mejor-sofware-para-hacer-esto",
    "href": "archive/2023-11-icfes/1-introduccion.html#cuál-es-el-mejor-sofware-para-hacer-esto",
    "title": "1 - Introducción a Machine Learning",
    "section": "¿Cuál es el mejor sofware para hacer esto?",
    "text": "¿Cuál es el mejor sofware para hacer esto?\n\n\n\nPython\nR\nJulia\nMatlab\nProgramas\n\nMplus\nStata\nSAS\nSPSS"
  },
  {
    "objectID": "archive/2023-11-icfes/1-introduccion.html#tidyverse",
    "href": "archive/2023-11-icfes/1-introduccion.html#tidyverse",
    "title": "1 - Introducción a Machine Learning",
    "section": "Tidyverse",
    "text": "Tidyverse\n\n\nggplot2 - para visualización de gráficos\ndplyr - para el procesamiento de datos\ntidyr - para la transformación de datos en formato “tidy” (ordenado)\nreadr - para la lectura de datos en diferentes formatos (CSV, TSV, etc.)\npurrr - para la programación funcional\ntibble - para la creación de data frames en formato “tidy”\nstringr - para la manipulación de cadenas de texto\nforcats- para la manipulación de factores"
  },
  {
    "objectID": "archive/2023-11-icfes/1-introduccion.html#tidyverse-1",
    "href": "archive/2023-11-icfes/1-introduccion.html#tidyverse-1",
    "title": "1 - Introducción a Machine Learning",
    "section": "Tidyverse",
    "text": "Tidyverse\n\nEstilo\n\nPipe\nnombre_de_los_objetos\nUso de las comillas\nRetorna un objeto de la misma clase\nProgramación funcional\n\n\n\n\n\nMachine Learning"
  },
  {
    "objectID": "archive/2023-11-icfes/index.html",
    "href": "archive/2023-11-icfes/index.html",
    "title": "Taller Introducción a Machine Learning en el 14° Seminario Internacional de Investigación sobre la Calidad de la Educación - SiiCE",
    "section": "",
    "text": "Este taller se llevará a cabo durante el 14° Seminario Internacional de Investigación sobre la Calidad de la Educación - SiiCE. En este taller se presentarán los conceptos básicos de Machine Learning y se realizarán ejercicios prácticos en R. El taller está dirigido a investigadores y estudiantes interesados en aprender sobre Machine Learning y su aplicación en la investigación educativa."
  },
  {
    "objectID": "archive/2023-11-icfes/index.html#organizadores",
    "href": "archive/2023-11-icfes/index.html#organizadores",
    "title": "Taller Introducción a Machine Learning en el 14° Seminario Internacional de Investigación sobre la Calidad de la Educación - SiiCE",
    "section": "Organizadores",
    "text": "Organizadores\nFrancisco Cardozo. Universidad de Miami. Eric C. Brown. Universidad de Miami."
  }
]