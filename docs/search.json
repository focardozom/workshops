[
  {
    "objectID": "COC/coc.html",
    "href": "COC/coc.html",
    "title": "Código de Conducta",
    "section": "",
    "text": "Los asistentes a este taller estamos comprometidos con la creación de un entorno inclusivo, respetuoso y seguro para todas las personas involucradas. Este Código de Conducta establece nuestras expectativas sobre el comportamiento de todos los participantes.\n\n\n\n\nRespeto Mutuo: Trata a todos con respeto y cortesía.\nInclusividad: Promueve un ambiente inclusivo y acogedor para todos los participantes.\nColaboración: Fomenta la colaboración y el trabajo en equipo.\nEscucha Activa: Presta atención a las opiniones y preguntas de otros, y da retroalimentación constructiva.\n\n\n\n\n\nDiscriminación o Acoso: Cualquier forma de discriminación o acoso.\nLenguaje Ofensivo: El uso de lenguaje inapropiado, obsceno o insultante.\nIntimidación: Amenazas, acoso, o cualquier otra forma de intimidación.\n\n\n\n\nCualquier participante que viole este Código de Conducta podría enfrentar medidas que van desde advertencias hasta la expulsión del evento, a discreción de los organizadores.\n\n\n\nSi eres víctima o testigo de un comportamiento inaceptable, informa a los organizadores lo más pronto posible."
  },
  {
    "objectID": "COC/coc.html#introducción",
    "href": "COC/coc.html#introducción",
    "title": "Código de Conducta",
    "section": "",
    "text": "Los asistentes a este taller estamos comprometidos con la creación de un entorno inclusivo, respetuoso y seguro para todas las personas involucradas. Este Código de Conducta establece nuestras expectativas sobre el comportamiento de todos los participantes."
  },
  {
    "objectID": "COC/coc.html#comportamiento-esperado",
    "href": "COC/coc.html#comportamiento-esperado",
    "title": "Código de Conducta",
    "section": "",
    "text": "Respeto Mutuo: Trata a todos con respeto y cortesía.\nInclusividad: Promueve un ambiente inclusivo y acogedor para todos los participantes.\nColaboración: Fomenta la colaboración y el trabajo en equipo.\nEscucha Activa: Presta atención a las opiniones y preguntas de otros, y da retroalimentación constructiva."
  },
  {
    "objectID": "COC/coc.html#comportamientos-inaceptables",
    "href": "COC/coc.html#comportamientos-inaceptables",
    "title": "Código de Conducta",
    "section": "",
    "text": "Discriminación o Acoso: Cualquier forma de discriminación o acoso.\nLenguaje Ofensivo: El uso de lenguaje inapropiado, obsceno o insultante.\nIntimidación: Amenazas, acoso, o cualquier otra forma de intimidación."
  },
  {
    "objectID": "COC/coc.html#medidas-disciplinarias",
    "href": "COC/coc.html#medidas-disciplinarias",
    "title": "Código de Conducta",
    "section": "",
    "text": "Cualquier participante que viole este Código de Conducta podría enfrentar medidas que van desde advertencias hasta la expulsión del evento, a discreción de los organizadores."
  },
  {
    "objectID": "COC/coc.html#informes",
    "href": "COC/coc.html#informes",
    "title": "Código de Conducta",
    "section": "",
    "text": "Si eres víctima o testigo de un comportamiento inaceptable, informa a los organizadores lo más pronto posible."
  },
  {
    "objectID": "archive/2024-02-konrad/5-forest.html#re-muestreo-y-validación-cruzada",
    "href": "archive/2024-02-konrad/5-forest.html#re-muestreo-y-validación-cruzada",
    "title": "5. Re-muestreo y Validación Cruzada",
    "section": "Re-muestreo y Validación Cruzada",
    "text": "Re-muestreo y Validación Cruzada\nPaso a paso del proceso de k-fold cross-validation:\nPrimero: duplicar el conjunto de datos en subconjuntos de igual tamaño. Por ejemplo, si k=10, dividimos el conjunto de datos en 10 subconjuntos.\nSegundo: tomar cada subconjunto y dividirlo en dos, unos datos para entrenamiento y otros para validación. Tomar el segundo subconjunto y hacer lo mismo, pero ahora, todos los datos que se utilizaron como validación en el cojunto previo deben ser para entrenamiento, y los de validación, deben ser para entrenamiento. Este proceso se repite hasta que todos los subconjuntos hayan sido divididos en entrenamiento y validación, y los datos de validación, nunca se repiten entre los diferentes subconjuntos.\nTercero: estimamos el modelo en los datos de entrenamiento y lo evaluamos utilizando los datos de validación."
  },
  {
    "objectID": "archive/2024-02-konrad/5-forest.html#re-muestreo-y-validación-cruzada-1",
    "href": "archive/2024-02-konrad/5-forest.html#re-muestreo-y-validación-cruzada-1",
    "title": "5. Re-muestreo y Validación Cruzada",
    "section": "Re-muestreo y Validación Cruzada",
    "text": "Re-muestreo y Validación Cruzada\nFialmente: se obtiene un valor promedio del desempeño del modelo en los datos de validación. Esta media nos proporciona una mejor aproximación del rendimiento del modelo, ya que el modelo ha sido evaluado en diferentes subconjuntos del conjunto de datos, en datos que no fueron utilizados para entrenamiento.\nhttps://scikit-learn.org/stable/modules/cross_validation.html\nhttps://www.tmwr.org/resampling.html"
  },
  {
    "objectID": "archive/2024-02-konrad/5-forest.html#validación-cruzada",
    "href": "archive/2024-02-konrad/5-forest.html#validación-cruzada",
    "title": "5. Re-muestreo y Validación Cruzada",
    "section": "Validación Cruzada",
    "text": "Validación Cruzada\nPara hacer validación cruzada necesitamos utilizar un objeto que contenga la información separada en diferentes cajas.\n\ncrossvalidation &lt;-\n  vfold_cv(datos_entrenamiento, \n           v = 5,  # número de cajas\n           strata = \"PYALC\")"
  },
  {
    "objectID": "archive/2024-02-konrad/5-forest.html#cart-con-hiperparámetros",
    "href": "archive/2024-02-konrad/5-forest.html#cart-con-hiperparámetros",
    "title": "5. Re-muestreo y Validación Cruzada",
    "section": "CART con hiperparámetros",
    "text": "CART con hiperparámetros\n\ntree_spec &lt;- \n  decision_tree(\n    cost_complexity = tune(), \n    tree_depth = tune()\n  ) |&gt; \n  set_mode(\"classification\") |&gt; \n  set_engine(\"rpart\")\n\n\n\n\n\n\n\nTip\n\n\n\nCost_complexity: es una medida de la penalización que se aplica al árbol en función de su complejidad. Un valor más alto de cost_complexity implica una penalización más fuerte, lo que lleva a un árbol más pequeño y menos profundo.\nTree_depth (profundidad del árbol): se refiere a la longitud máxima del camino más largo desde la raíz hasta una hoja en un árbol de decisión.\nMin_n (mínimo número de muestras para dividir un nodo): Min_n es un parámetro que controla el número mínimo de datos requeridas para dividir un nodo en un árbol de decisión."
  },
  {
    "objectID": "archive/2024-02-konrad/5-forest.html#cart-con-hiperparámetros-1",
    "href": "archive/2024-02-konrad/5-forest.html#cart-con-hiperparámetros-1",
    "title": "5. Re-muestreo y Validación Cruzada",
    "section": "CART con hiperparámetros",
    "text": "CART con hiperparámetros\nDebemos especificar valors para los hiperparámetros que queremos ajustar.\n\ntree_grid &lt;- grid_regular(\n  cost_complexity(range = c(-5L, -1L)),\n  tree_depth (range = c(5L, 10L)))"
  },
  {
    "objectID": "archive/2024-02-konrad/5-forest.html#cart-con-hiperparámetros-2",
    "href": "archive/2024-02-konrad/5-forest.html#cart-con-hiperparámetros-2",
    "title": "5. Re-muestreo y Validación Cruzada",
    "section": "CART con hiperparámetros",
    "text": "CART con hiperparámetros\nUna vez se ha definido cuáles son los valores que queremos probar, se estima el modelo en los diferetes conjuntos de datos.\n\ndoParallel::registerDoParallel()\n\nset.seed(345)\ntree_rs &lt;-\n  tune_grid(\n    tree_spec,\n    PYALC ~ .,\n    resamples = crossvalidation,\n    grid = tree_grid,\n    metrics = metric_set(accuracy)\n  )\n\ndoParallel::stopImplicitCluster()"
  },
  {
    "objectID": "archive/2024-02-konrad/5-forest.html#desempeño-hiperparámetros",
    "href": "archive/2024-02-konrad/5-forest.html#desempeño-hiperparámetros",
    "title": "5. Re-muestreo y Validación Cruzada",
    "section": "Desempeño hiperparámetros",
    "text": "Desempeño hiperparámetros\nFiltrar los rultados para utilizar la combinación de hiperparámetros que mejor desempeño tuvo, y estimar el modelo.\n\nshow_best(tree_rs, metric = \"accuracy\")\n\nautoplot(tree_rs)\n\nsimpler_tree &lt;- select_best(tree_rs,metric = \"accuracy\")\n\nfinal_tree &lt;- finalize_model(tree_spec, simpler_tree)\n\nfinal_fit &lt;- fit(final_tree, PYALC ~ ., datos_entrenamiento)"
  },
  {
    "objectID": "archive/2024-02-konrad/5-forest.html#visualización-del-árbol",
    "href": "archive/2024-02-konrad/5-forest.html#visualización-del-árbol",
    "title": "5. Re-muestreo y Validación Cruzada",
    "section": "Visualización del árbol",
    "text": "Visualización del árbol\n\ncart_trained &lt;- \n  final_fit  |&gt; extract_fit_parsnip()\n\ncart_tree_fit &lt;- final_fit$fit\n\ntreemisc::tree_diagram(cart_tree_fit, roundint=FALSE)"
  },
  {
    "objectID": "archive/2024-02-konrad/5-forest.html#obtener-el-desempeño-del-modelo-en-datos-de-validación",
    "href": "archive/2024-02-konrad/5-forest.html#obtener-el-desempeño-del-modelo-en-datos-de-validación",
    "title": "5. Re-muestreo y Validación Cruzada",
    "section": "Obtener el desempeño del modelo en datos de validación",
    "text": "Obtener el desempeño del modelo en datos de validación\n\ntree_val &lt;- fit_resamples(\n  final_tree, PYALC ~ ., \n  crossvalidation, \n  metrics= metric_set(accuracy))\n\ntree_results_h  &lt;- tree_val  |&gt; \n  collect_metrics()  |&gt; \n  mutate(model=\"Árbol Sintonizado\")\n\nlm_model_val &lt;- fit_resamples(\n  lm_model, PYALC ~ ., \n  crossvalidation, \n  metrics= metric_set(accuracy))\n\nlm_results  &lt;- lm_model_val  |&gt; \n  collect_metrics()  |&gt; \n  mutate(model=\"Regresión lineal\")\n\ntree_spec_val  &lt;- fit_resamples(\n  tree_spec, PYALC ~ ., \n  crossvalidation, \n  metrics= metric_set(accuracy))\n\ntree_results  &lt;- tree_spec_val|&gt; \n  collect_metrics()   |&gt; \n  mutate(model=\"Árbol\")\n  \n\nrbind(lm_results, tree_results, tree_results_h) |&gt; \nselect(model, mean)"
  },
  {
    "objectID": "archive/2024-02-konrad/5-forest.html#random-forest-1",
    "href": "archive/2024-02-konrad/5-forest.html#random-forest-1",
    "title": "5. Re-muestreo y Validación Cruzada",
    "section": "Random Forest",
    "text": "Random Forest\nLos árboles de decisión sufren de muchos problemas, en especial de sobreajuste. Esto se puede entender como un problema de varianza, y por lo tanto se pueden hacer cosas para minimizarlo. Por ejemplo, podríamos construir muchos árboles de decisión y promediar sus predicciones. Este es el concepto detrás de los Random Forests."
  },
  {
    "objectID": "archive/2024-02-konrad/5-forest.html#random-forest-2",
    "href": "archive/2024-02-konrad/5-forest.html#random-forest-2",
    "title": "5. Re-muestreo y Validación Cruzada",
    "section": "Random Forest",
    "text": "Random Forest\nEspecificar un modelo\n\nrf_spec &lt;- \n  rand_forest()  |&gt; \n  set_mode(\"classification\") |&gt; \n  set_engine(\"ranger\", importance = \"permutation\")\n\nEstimar un modelo\n\nrf_results &lt;- rf_spec |&gt; \nfit_resamples(PYALC ~ ., \ncrossvalidation, metrics = metric_set(accuracy))\n\nObtener sus predicciones\n\nrf_results_val  &lt;- rf_results  |&gt; \ncollect_metrics()  |&gt; \n  mutate(model=\"RF\")\n  \n\nrbind(lm_results, tree_results, tree_results_h, rf_results_val) |&gt; \nselect(model, mean) \n\n\nlibrary(vip)\nrf_spec |&gt; \n  fit(PYALC ~ ., datos_entrenamiento) |&gt; \n  vip() +\n  ggtitle(\"Random Forest\")"
  },
  {
    "objectID": "archive/2024-02-konrad/5-forest.html#sesgo-y-varianza",
    "href": "archive/2024-02-konrad/5-forest.html#sesgo-y-varianza",
    "title": "5. Re-muestreo y Validación Cruzada",
    "section": "Sesgo y varianza",
    "text": "Sesgo y varianza\nEstos dos conceptos son cruciales para entender el equilibrio entre la complejidad del modelo y su capacidad para generalizar a nuevos datos.\nSesgo (Bias): a. Definición: El sesgo es la diferencia entre la predicción promedio de nuestro modelo y el valor verdadero que intentamos predecir.El sesgo, en términos estadísticos, se refiere a la diferencia sistemática entre la esperanza (o promedio) de las estimaciones que produce un estimador y el valor real del parámetro que se desea estimar. Un modelo con alta varianza es muy sensible a pequeñas variaciones en los datos de entrenamiento, lo que puede resultar en un sobreajuste. Es decir, el modelo se ajusta muy bien a los datos de entrenamiento, pero tiene un rendimiento deficiente en datos no vistos o de prueba.\n\nEjemplo: Un modelo de regresión lineal simple podría tener un alto sesgo si los datos reales tienen una relación no lineal.\nImplicaciones: Un modelo con alto sesgo es demasiado simple y no captura la estructura subyacente de los datos. Esto conduce a un bajo rendimiento en el conjunto de entrenamiento y prueba.\n\nVarianza (Variance): a. Definición: La varianza es la cantidad de variabilidad en las predicciones del modelo para un punto de datos dado. b. Ejemplo: Un modelo de árbol de decisión muy profundo podría tener alta varianza, ya que es muy sensible a pequeñas variaciones en los datos de entrenamiento. c. Implicaciones: Un modelo con alta varianza tiende a sobreajustarse a los datos de entrenamiento, lo que resulta en un buen rendimiento en el conjunto de entrenamiento pero un bajo rendimiento en el conjunto de prueba.\nEl objetivo en Machine Learning es equilibrar el sesgo y la varianza para minimizar el error de predicción general en el modelo a. Objetivo: Encontrar un equilibrio entre sesgo y varianza que minimice el error total de predicción. b. Estrategias: Seleccionar un modelo con la complejidad adecuada, usar técnicas de regularización, y validar el modelo con conjuntos de datos de entrenamiento y prueba separados.\nFormas de disminur el sesgo\nAumentar la complejidad del modelo: Un modelo más complejo puede capturar mejor la estructura subyacente de los datos. Por ejemplo, en lugar de utilizar una regresión lineal simple, podrías probar una regresión polinomial o un modelo de árbol de decisión.\nAñadir más variables: A veces, el sesgo puede ser el resultado de no tener en cuenta variables importantes que influyen en la variable objetivo. Añadir más variables relevantes puede ayudar a reducir el sesgo del modelo.\nUtilizar técnicas de “ingeniería de predictores”: Transformar o combinar las variables existentes para crear nuevas características puede ayudar a capturar mejor la relación entre las variables de entrada y salida. Por ejemplo, si estás trabajando en un problema de predicción de precios de viviendas, podrías crear una nueva característica que represente la relación entre el tamaño de la casa y el número de habitaciones.\nAumentar el tamaño del conjunto de datos: Si tu conjunto de datos es pequeño o no es representativo de la población general, es posible que el modelo tenga un sesgo alto. Aumentar el tamaño del conjunto de datos y asegurarte de que es representativo puede ayudar a reducir el sesgo.\nUtilizar ensembles de modelos: Combinar varios modelos en un ensemble puede ayudar a reducir el sesgo, ya que cada modelo puede capturar diferentes aspectos de la relación entre las variables de entrada y salida. Por ejemplo, puedes utilizar métodos de ensemble como Bagging, Boosting o Stacking."
  },
  {
    "objectID": "archive/2024-02-konrad/5-forest.html#técnicas-para-reducir-la-varianza",
    "href": "archive/2024-02-konrad/5-forest.html#técnicas-para-reducir-la-varianza",
    "title": "5. Re-muestreo y Validación Cruzada",
    "section": "Técnicas para reducir la varianza",
    "text": "Técnicas para reducir la varianza\nReducir la complejidad del modelo: Un modelo más simple tiende a tener una menor varianza y es menos propenso al sobreajuste. Por ejemplo, se puede limitar la profundidad de un árbol de decisión.\nUtilizar regularización: La regularización es una técnica que añade una penalización a los coeficientes del modelo para evitar que se ajusten demasiado a los datos de entrenamiento.Por ejemplo, regularización L1 (Lasso) y L2 (Ridge).\nAumentar el tamaño del conjunto de datos: Si dispones de más datos, el modelo será menos sensible a pequeñas variaciones en los datos de entrenamiento y tendrá una menor varianza."
  },
  {
    "objectID": "archive/2024-02-konrad/5-forest.html#técnicas-para-reducir-la-varianza-1",
    "href": "archive/2024-02-konrad/5-forest.html#técnicas-para-reducir-la-varianza-1",
    "title": "5. Re-muestreo y Validación Cruzada",
    "section": "Técnicas para reducir la varianza",
    "text": "Técnicas para reducir la varianza\nEliminar características ruidosas: Si el modelo incluye características que no están relacionadas con la variable objetivo o que contienen mucho ruido, estas pueden aumentar la varianza del modelo. Realizar un análisis de importancia de características y eliminar las características poco importantes puede ayudar a reducir la varianza.\nValidación cruzada (cross-validation): Utilizar la validación cruzada, como k-fold cross-validation, te permite evaluar el rendimiento del modelo en diferentes subconjuntos del conjunto de datos de entrenamiento. Esto puede ayudarte a identificar si el modelo está sobreajustando los datos y ajustar la complejidad del modelo en consecuencia."
  },
  {
    "objectID": "archive/2024-02-konrad/5-forest.html#técnicas-para-reducir-la-varianza-2",
    "href": "archive/2024-02-konrad/5-forest.html#técnicas-para-reducir-la-varianza-2",
    "title": "5. Re-muestreo y Validación Cruzada",
    "section": "Técnicas para reducir la varianza",
    "text": "Técnicas para reducir la varianza\nUtilizar diferentes modelos: Combinar varios modelos en un ensemble puede ayudar a reducir la varianza, ya que la variabilidad de cada modelo individual se promedia. Por ejemplo, puedes utilizar métodos de ensemble como Bagging (Bootstrap Aggregating) o Random Forest, que promedian las predicciones de múltiples árboles de decisión entrenados en subconjuntos aleatorios de los datos."
  },
  {
    "objectID": "archive/2024-02-konrad/3-modelos.html#agenda",
    "href": "archive/2024-02-konrad/3-modelos.html#agenda",
    "title": "3. Estimar un modelo",
    "section": "Agenda",
    "text": "Agenda\n\n\nParte I\n\nEspecificar un modelo\nEstimar un modelo\nVer los resultados del modelo\n\n\nParte II\n\nDividir los datos\nEspecificar un modelo\nEstimar un modelo\nEvaluar el modelo\nEstimar un modelo mejor"
  },
  {
    "objectID": "archive/2024-02-konrad/3-modelos.html#estimar-un-modelo",
    "href": "archive/2024-02-konrad/3-modelos.html#estimar-un-modelo",
    "title": "3. Estimar un modelo",
    "section": "Estimar un modelo",
    "text": "Estimar un modelo\n\nHay muchas formas de estimar modelos en R\n\nlm(formula, data, ...)\nstan_glm(formula, data, family= \"gaussian\",...)\nglmnet(x=matrix, y=vector, family=\"gaussian\",...)\n\n\n\n\n\n\n\nTip\n\n\nlm(): Estimar un modelo de regresión lineal.\nstan_glm(): Estimar un modelo de regresión utilizando el paquete Stan.\nglmnet(): Estimar un modelo de regresión utilizando la regularización Lasso o Ridge."
  },
  {
    "objectID": "archive/2024-02-konrad/3-modelos.html#especificar-el-modelo-en-tidymodels",
    "href": "archive/2024-02-konrad/3-modelos.html#especificar-el-modelo-en-tidymodels",
    "title": "3. Estimar un modelo",
    "section": "Especificar el modelo en tidymodels",
    "text": "Especificar el modelo en tidymodels\nTidymodels ofrece una sintaxis general para estimar los modelos\nhttps://www.tidymodels.org/\n\nEspecificar el tipo de modelo\n\nlinear_reg(), logistic_reg(), decision_tree()\n\nEspecificar el tipo de outcome\n\nRegresión: variables continuas\nClasificación: categórica,multinomial, ordinal"
  },
  {
    "objectID": "archive/2024-02-konrad/3-modelos.html#especificar-el-modelo-en-tidymodels-1",
    "href": "archive/2024-02-konrad/3-modelos.html#especificar-el-modelo-en-tidymodels-1",
    "title": "3. Estimar un modelo",
    "section": "Especificar el modelo en tidymodels",
    "text": "Especificar el modelo en tidymodels\n\nlibrary(tidymodels)\n\n── Attaching packages ────────────────────────────────────── tidymodels 1.1.1 ──\n\n\n✔ broom        1.0.5     ✔ recipes      1.0.9\n✔ dials        1.2.0     ✔ rsample      1.2.0\n✔ dplyr        1.1.4     ✔ tibble       3.2.1\n✔ ggplot2      3.4.4     ✔ tidyr        1.3.1\n✔ infer        1.0.5     ✔ tune         1.1.2\n✔ modeldata    1.2.0     ✔ workflows    1.1.3\n✔ parsnip      1.1.1     ✔ workflowsets 1.0.1\n✔ purrr        1.0.2     ✔ yardstick    1.2.0\n\n\n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ purrr::discard() masks scales::discard()\n✖ dplyr::filter()  masks stats::filter()\n✖ dplyr::lag()     masks stats::lag()\n✖ recipes::step()  masks stats::step()\n• Use suppressPackageStartupMessages() to eliminate package startup messages\n\ntidymodels_prefer()\n\nlinear_reg() |&gt; \n  set_engine(\"lm\") |&gt; \n  set_mode(\"regression\")\n\nLinear Regression Model Specification (regression)\n\nComputational engine: lm \n\nlogistic_reg() |&gt; \n    set_engine(\"glmnet\") |&gt; \n    set_mode(\"classification\")\n\nLogistic Regression Model Specification (classification)\n\nComputational engine: glmnet \n\nlinear_reg() |&gt;\n    set_engine(\"stan\")  |&gt; \n    set_mode(\"regression\")\n\nLinear Regression Model Specification (regression)\n\nComputational engine: stan"
  },
  {
    "objectID": "archive/2024-02-konrad/3-modelos.html#especificar-el-modelo-en-tidymodels-2",
    "href": "archive/2024-02-konrad/3-modelos.html#especificar-el-modelo-en-tidymodels-2",
    "title": "3. Estimar un modelo",
    "section": "Especificar el modelo en tidymodels",
    "text": "Especificar el modelo en tidymodels\n\n\n\n\n\n\nTip\n\n\nlibrary(): cargar el paquete tidymodels.\ntidymodels_prefer(): establecer el paquete tidymodels como el preferido.\nlinear_reg(): Crear una especificación de modelo de regresión lineal en el marco de tidymodels.\nlogistic_reg() : Crear una especificación de modelo de regresión logística en el marco de tidymodels.\nset_engine(): establecer el motor (paquete) de cálculo del modelo. Se utilizará “lm” para el primer modelo, “glmnet” para el segundo y “stan” para el tercero."
  },
  {
    "objectID": "archive/2024-02-konrad/3-modelos.html#estimar-un-modelo-1",
    "href": "archive/2024-02-konrad/3-modelos.html#estimar-un-modelo-1",
    "title": "3. Estimar un modelo",
    "section": "Estimar un modelo",
    "text": "Estimar un modelo\n\nEstimar un modelo de regresión logística para evaluar la asociación entre el consumo de alcohol y los factores de riesgo"
  },
  {
    "objectID": "archive/2024-02-konrad/3-modelos.html#descriptivos",
    "href": "archive/2024-02-konrad/3-modelos.html#descriptivos",
    "title": "3. Estimar un modelo",
    "section": "Descriptivos",
    "text": "Descriptivos\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ forcats   1.0.0     ✔ readr     2.1.4\n✔ lubridate 1.9.3     ✔ stringr   1.5.1\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ readr::col_factor() masks scales::col_factor()\n✖ purrr::discard()    masks scales::discard()\n✖ dplyr::filter()     masks stats::filter()\n✖ stringr::fixed()    masks recipes::fixed()\n✖ dplyr::lag()        masks stats::lag()\n✖ readr::spec()       masks yardstick::spec()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\n Calcular la tabla de descriptivos\n\nmini_datos |&gt;\n    select(PYALC,factores_de_riesgo) |&gt;\n    table1::table1( ~ ., data=_)\n\nWarning: Using an external vector in selections was deprecated in tidyselect 1.1.0.\nℹ Please use `all_of()` or `any_of()` instead.\n  # Was:\n  data %&gt;% select(factores_de_riesgo)\n\n  # Now:\n  data %&gt;% select(all_of(factores_de_riesgo))\n\nSee &lt;https://tidyselect.r-lib.org/reference/faq-external-vector.html&gt;.\n\n\n\n\n\n\n\n\n\n\n\n\nOverall\n(N=12507)\n\n\n\n\nPYALC\n\n\n\nNo ha consumido\n3647 (29.2%)\n\n\nSí ha consumido\n8860 (70.8%)\n\n\nCRPAD\n\n\n\nMean (SD)\n2.13 (0.855)\n\n\nMedian [Min, Max]\n2.00 [1.00, 4.00]\n\n\nCRLNFD\n\n\n\nMean (SD)\n2.18 (0.536)\n\n\nMedian [Min, Max]\n2.17 [1.00, 4.00]\n\n\nFRPFD\n\n\n\nMean (SD)\n1.37 (0.484)\n\n\nMedian [Min, Max]\n1.33 [1.00, 4.00]\n\n\nFRPFM\n\n\n\nMean (SD)\n1.73 (0.534)\n\n\nMedian [Min, Max]\n1.75 [0.875, 4.00]\n\n\nSRLCS\n\n\n\nMean (SD)\n2.19 (0.446)\n\n\nMedian [Min, Max]\n2.14 [1.00, 4.86]\n\n\nPRFAD\n\n\n\nMean (SD)\n1.72 (0.677)\n\n\nMedian [Min, Max]\n1.50 [1.00, 4.00]\n\n\nPRATA\n\n\n\nMean (SD)\n1.53 (0.583)\n\n\nMedian [Min, Max]\n1.40 [1.00, 4.00]\n\n\n\n\n\n\n\nCalcular la tabla de descriptivos por grupo (Sí y No ha consumido)\n\nmini_datos |&gt;\n    select(PYALC,factores_de_riesgo) |&gt;\n    filter(!is.na(PYALC)) |&gt; \n    table1::table1( ~ . | PYALC, data=_)\n\n\n\n\n\n\n\n\n\n\n\n\n\nNo ha consumido\n(N=3647)\nSí ha consumido\n(N=8860)\nOverall\n(N=12507)\n\n\n\n\nCRPAD\n\n\n\n\n\nMean (SD)\n1.79 (0.810)\n2.27 (0.833)\n2.13 (0.855)\n\n\nMedian [Min, Max]\n1.50 [1.00, 4.00]\n2.25 [1.00, 4.00]\n2.00 [1.00, 4.00]\n\n\nCRLNFD\n\n\n\n\n\nMean (SD)\n2.00 (0.569)\n2.26 (0.503)\n2.18 (0.536)\n\n\nMedian [Min, Max]\n2.00 [1.00, 4.00]\n2.20 [1.00, 4.00]\n2.17 [1.00, 4.00]\n\n\nFRPFD\n\n\n\n\n\nMean (SD)\n1.16 (0.394)\n1.46 (0.491)\n1.37 (0.484)\n\n\nMedian [Min, Max]\n1.00 [1.00, 4.00]\n1.33 [1.00, 4.00]\n1.33 [1.00, 4.00]\n\n\nFRPFM\n\n\n\n\n\nMean (SD)\n1.58 (0.554)\n1.79 (0.513)\n1.73 (0.534)\n\n\nMedian [Min, Max]\n1.50 [1.00, 4.00]\n1.75 [0.875, 4.00]\n1.75 [0.875, 4.00]\n\n\nSRLCS\n\n\n\n\n\nMean (SD)\n2.08 (0.431)\n2.24 (0.443)\n2.19 (0.446)\n\n\nMedian [Min, Max]\n2.00 [1.00, 4.86]\n2.17 [1.00, 4.57]\n2.14 [1.00, 4.86]\n\n\nPRFAD\n\n\n\n\n\nMean (SD)\n1.37 (0.551)\n1.87 (0.672)\n1.72 (0.677)\n\n\nMedian [Min, Max]\n1.00 [1.00, 4.00]\n1.75 [1.00, 4.00]\n1.50 [1.00, 4.00]\n\n\nPRATA\n\n\n\n\n\nMean (SD)\n1.37 (0.515)\n1.60 (0.596)\n1.53 (0.583)\n\n\nMedian [Min, Max]\n1.20 [1.00, 4.00]\n1.40 [1.00, 4.00]\n1.40 [1.00, 4.00]"
  },
  {
    "objectID": "archive/2024-02-konrad/3-modelos.html#explorar-los-datos-visualmente",
    "href": "archive/2024-02-konrad/3-modelos.html#explorar-los-datos-visualmente",
    "title": "3. Estimar un modelo",
    "section": "Explorar los datos visualmente",
    "text": "Explorar los datos visualmente\nHacer un gráfico para ver tendencias en los factores de riesgo\n\nmini_datos |&gt; \n select(PYALC,factores_de_riesgo) |&gt;\n  pivot_longer(-PYALC) |&gt; \n  ggplot(aes(value, fct_reorder(name, value), fill = PYALC)) +\n  geom_boxplot()"
  },
  {
    "objectID": "archive/2024-02-konrad/3-modelos.html#especificar-el-modelo-1",
    "href": "archive/2024-02-konrad/3-modelos.html#especificar-el-modelo-1",
    "title": "3. Estimar un modelo",
    "section": "1. Especificar el modelo",
    "text": "1. Especificar el modelo\nEspecificar un modelo de regresión logística. Se establece el “paquete”, en este caso “glm” y opciones del paquete (la distribución de la variable de respuesta). Además, se especifica que es un problema de “classification”, debido a que la variable dependiente es categórica. Todo esto se almacena en el objeto lm_model.\n\n\nlm_model &lt;-\n    logistic_reg() %&gt;% \n    set_engine(\"glm\", family=\"binomial\") |&gt;\n    set_mode(\"classification\")"
  },
  {
    "objectID": "archive/2024-02-konrad/3-modelos.html#estimar-el-modelo",
    "href": "archive/2024-02-konrad/3-modelos.html#estimar-el-modelo",
    "title": "3. Estimar un modelo",
    "section": "2. Estimar el modelo",
    "text": "2. Estimar el modelo\nAquí se estima el modelo con la función fit(). Se especifica la variable de resultado (PYALC) y los predictores (.). Se utiliza el objeto mini_datos como base de datos.\n\n\nlm_results &lt;- lm_model |&gt;\n    fit(PYALC ~ ., data = mini_datos)"
  },
  {
    "objectID": "archive/2024-02-konrad/3-modelos.html#obtener-los-resultados-del-modelo",
    "href": "archive/2024-02-konrad/3-modelos.html#obtener-los-resultados-del-modelo",
    "title": "3. Estimar un modelo",
    "section": "3. Obtener los resultados del modelo",
    "text": "3. Obtener los resultados del modelo\nObtener los coeficientes (betas) del modelo\n\nlm_results |&gt; tidy() \n\n# A tibble: 15 × 5\n   term           estimate std.error statistic   p.value\n   &lt;chr&gt;             &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n 1 (Intercept)    -5.28      0.177    -29.8    9.45e-196\n 2 CRPAD           0.182     0.0305     5.98   2.24e-  9\n 3 CRLNFD          0.230     0.0463     4.96   6.98e-  7\n 4 FRPFD           1.01      0.0695    14.5    8.78e- 48\n 5 FRPFM           0.132     0.0466     2.83   4.68e-  3\n 6 SRLCS           0.241     0.0553     4.37   1.26e-  5\n 7 PRFAD           0.907     0.0558    16.3    1.88e- 59\n 8 PRATA          -0.288     0.0559    -5.15   2.67e-  7\n 9 YEAR2014       -0.00523   0.0550    -0.0951 9.24e-  1\n10 YEAR2015       -0.354     0.0872    -4.06   4.93e-  5\n11 YEAR2016       -0.154     0.0970    -1.59   1.13e-  1\n12 YEAR2017       -0.341     0.0706    -4.84   1.32e-  6\n13 GRADE           0.299     0.0162    18.4    1.04e- 75\n14 GENDERFemenino -0.0302    0.0448    -0.675  5.00e-  1\n15 AGE            -0.00150   0.00456   -0.329  7.42e-  1\n\n\nObtener los índices de ajuste del modelo\n\nlm_results |&gt; glance()\n\n# A tibble: 1 × 8\n  null.deviance df.null logLik    AIC    BIC deviance df.residual  nobs\n          &lt;dbl&gt;   &lt;int&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;       &lt;int&gt; &lt;int&gt;\n1        15098.   12506 -6141. 12313. 12424.   12283.       12492 12507"
  },
  {
    "objectID": "archive/2024-02-konrad/3-modelos.html#obtener-los-resultados-del-modelo-1",
    "href": "archive/2024-02-konrad/3-modelos.html#obtener-los-resultados-del-modelo-1",
    "title": "3. Estimar un modelo",
    "section": "3. Obtener los resultados del modelo",
    "text": "3. Obtener los resultados del modelo\n\n\n\n\n\n\nTip\n\n\ntidy(): Esta función se utiliza para convertir los resultados de un modelo en un marco de datos “ordenado” que muestra los coeficientes del modelo, los errores estándar, los valores t y los valores p para cada variable independiente.\nglance(): Esta función se utiliza para resumir los resultados de un modelo como estadísticas globales del modelo, por ejemplo, R-cuadrado ajustado, el AIC y el BIC.\ntidy(exp=TRUE, conf.int=TRUE): Esta función se utiliza para convertir los resultados de un modelo en un marco de datos “ordenado” que muestra los coeficientes del modelo, los errores estándar, los valores t y los valores p para cada variable independiente. Los argumentos exp y conf.int se utilizan para incluir los intervalos de confianza y los exponentes en los resultados\n\nlm_results |&gt; tidy(exp=TRUE, conf.int=TRUE)\n\n# A tibble: 15 × 7\n   term           estimate std.error statistic   p.value conf.low conf.high\n   &lt;chr&gt;             &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n 1 (Intercept)     0.00511   0.177    -29.8    9.45e-196  0.00360   0.00721\n 2 CRPAD           1.20      0.0305     5.98   2.24e-  9  1.13      1.27   \n 3 CRLNFD          1.26      0.0463     4.96   6.98e-  7  1.15      1.38   \n 4 FRPFD           2.74      0.0695    14.5    8.78e- 48  2.40      3.15   \n 5 FRPFM           1.14      0.0466     2.83   4.68e-  3  1.04      1.25   \n 6 SRLCS           1.27      0.0553     4.37   1.26e-  5  1.14      1.42   \n 7 PRFAD           2.48      0.0558    16.3    1.88e- 59  2.22      2.77   \n 8 PRATA           0.750     0.0559    -5.15   2.67e-  7  0.672     0.837  \n 9 YEAR2014        0.995     0.0550    -0.0951 9.24e-  1  0.893     1.11   \n10 YEAR2015        0.702     0.0872    -4.06   4.93e-  5  0.592     0.833  \n11 YEAR2016        0.857     0.0970    -1.59   1.13e-  1  0.709     1.04   \n12 YEAR2017        0.711     0.0706    -4.84   1.32e-  6  0.619     0.816  \n13 GRADE           1.35      0.0162    18.4    1.04e- 75  1.31      1.39   \n14 GENDERFemenino  0.970     0.0448    -0.675  5.00e-  1  0.889     1.06   \n15 AGE             0.999     0.00456   -0.329  7.42e-  1  0.990     1.01"
  },
  {
    "objectID": "archive/2024-02-konrad/3-modelos.html#para-qué-necesitamos-los-datos",
    "href": "archive/2024-02-konrad/3-modelos.html#para-qué-necesitamos-los-datos",
    "title": "3. Estimar un modelo",
    "section": "Para qué necesitamos los datos?",
    "text": "Para qué necesitamos los datos?\nNecesitamos:\n- Estimar parametros\n- Seleccionar modelos\n- Sintonizar los modelos (tunning)\n- Evaluar los modelos\n¿Cómo gastarnos los datos de una forma que sea eficiente para todos estos pasos? (validación empírica)"
  },
  {
    "objectID": "archive/2024-02-konrad/3-modelos.html#dividir-los-datos",
    "href": "archive/2024-02-konrad/3-modelos.html#dividir-los-datos",
    "title": "3. Estimar un modelo",
    "section": "Dividir los datos",
    "text": "Dividir los datos\nDividir los datos en dos conjuntos\nEntrenamiento:\n\nLa mayoría de los datos (¿70%, 80%?)\nAquí se ajusta el modelo\n\nPrueba:\n\nUn pequeño conjunto de datos\nAquí se evaluará el modelo final\n\n\nLos datos de prueba se utilizan una sola vez, si se utilizan más de una vez, se convierten en parte del proceso de entrenamiento.\n\n\n\n\n\n\n\nNote\n\n\nLa división de los datos se hace al nivel de unidad independiente de observación."
  },
  {
    "objectID": "archive/2024-02-konrad/3-modelos.html#dividir-los-datos-1",
    "href": "archive/2024-02-konrad/3-modelos.html#dividir-los-datos-1",
    "title": "3. Estimar un modelo",
    "section": "Dividir los datos",
    "text": "Dividir los datos\nCrear dos bases: entrenamiento 80% y prueba 20%\n\nset.seed(1234)\n\ndatos_divididos &lt;- initial_split(mini_datos, prop = 0.8, strata = \"PYALC\")\n\ndatos_entrenamiento &lt;- training(datos_divididos)\ndatos_prueba &lt;- testing(datos_divididos)\n\n\nLa opción strata es para que los datos de entrenamiento y prueba tengan la misma distribución de la variable PYALC\n\nA veces la selección aleatoria de la muestra es problemática, por ejemplo cuando hay una componente de tiempo en los datos. En este caso, se puede usar la función initial_time_split()."
  },
  {
    "objectID": "archive/2024-02-konrad/3-modelos.html#dividir-los-datos-2",
    "href": "archive/2024-02-konrad/3-modelos.html#dividir-los-datos-2",
    "title": "3. Estimar un modelo",
    "section": "Dividir los datos",
    "text": "Dividir los datos\nset.seed(): establecer una semilla para la generación de números aleatorios en R. En este caso, se utiliza para establecer la semilla en 1234, lo que garantiza que los resultados sean reproducibles. Esto es especialmente importante cuando se trabaja con modelos de aprendizaje automático, ya que los resultados pueden variar según la semilla utilizada para la generación de números aleatorios.\ninitial_split(): dividir los datos en conjuntos de entrenamiento y prueba. Divide el objeto “mini_datos” en conjuntos de entrenamiento y prueba en una proporción de 80/20, y estratificando por la columna “PYALC”.\ntraining(): extraer el conjunto de entrenamiento de un objeto creado con la función initial_split(). Se utiliza para extraer el conjunto de entrenamiento del objeto “datos_divididos”.\ntesting(): extraer el conjunto de prueba de un objeto creado con la función initial_split(). Se utiliza para extraer el conjunto de prueba del objeto “datos_divididos”."
  },
  {
    "objectID": "archive/2024-02-konrad/3-modelos.html#dividir-los-datos-3",
    "href": "archive/2024-02-konrad/3-modelos.html#dividir-los-datos-3",
    "title": "3. Estimar un modelo",
    "section": "Dividir los datos",
    "text": "Dividir los datos\nDescripivos de los datos de entrenamiento\n\ndatos_entrenamiento |&gt;\n    select(PYALC,factores_de_riesgo) |&gt;\n    table1::table1( ~ ., data=_)\n\n\n\n\n\n\n\n\n\n\n\nOverall\n(N=10005)\n\n\n\n\nPYALC\n\n\n\nNo ha consumido\n2917 (29.2%)\n\n\nSí ha consumido\n7088 (70.8%)\n\n\nCRPAD\n\n\n\nMean (SD)\n2.13 (0.855)\n\n\nMedian [Min, Max]\n2.00 [1.00, 4.00]\n\n\nCRLNFD\n\n\n\nMean (SD)\n2.18 (0.535)\n\n\nMedian [Min, Max]\n2.17 [1.00, 4.00]\n\n\nFRPFD\n\n\n\nMean (SD)\n1.37 (0.477)\n\n\nMedian [Min, Max]\n1.33 [1.00, 4.00]\n\n\nFRPFM\n\n\n\nMean (SD)\n1.73 (0.533)\n\n\nMedian [Min, Max]\n1.75 [0.875, 4.00]\n\n\nSRLCS\n\n\n\nMean (SD)\n2.19 (0.446)\n\n\nMedian [Min, Max]\n2.14 [1.00, 4.86]\n\n\nPRFAD\n\n\n\nMean (SD)\n1.73 (0.676)\n\n\nMedian [Min, Max]\n1.50 [1.00, 4.00]\n\n\nPRATA\n\n\n\nMean (SD)\n1.53 (0.582)\n\n\nMedian [Min, Max]\n1.40 [1.00, 4.00]\n\n\n\n\n\n\ndatos_prueba |&gt;\n    select(PYALC,factores_de_riesgo) |&gt;\n    table1::table1( ~ ., data=_)\n\n\n\n\n\n\n\n\n\n\n\nOverall\n(N=2502)\n\n\n\n\nPYALC\n\n\n\nNo ha consumido\n730 (29.2%)\n\n\nSí ha consumido\n1772 (70.8%)\n\n\nCRPAD\n\n\n\nMean (SD)\n2.13 (0.857)\n\n\nMedian [Min, Max]\n2.00 [1.00, 4.00]\n\n\nCRLNFD\n\n\n\nMean (SD)\n2.19 (0.542)\n\n\nMedian [Min, Max]\n2.17 [1.00, 4.00]\n\n\nFRPFD\n\n\n\nMean (SD)\n1.38 (0.509)\n\n\nMedian [Min, Max]\n1.33 [1.00, 4.00]\n\n\nFRPFM\n\n\n\nMean (SD)\n1.73 (0.539)\n\n\nMedian [Min, Max]\n1.63 [1.00, 4.00]\n\n\nSRLCS\n\n\n\nMean (SD)\n2.19 (0.445)\n\n\nMedian [Min, Max]\n2.14 [1.00, 4.14]\n\n\nPRFAD\n\n\n\nMean (SD)\n1.71 (0.682)\n\n\nMedian [Min, Max]\n1.50 [1.00, 4.00]\n\n\nPRATA\n\n\n\nMean (SD)\n1.52 (0.586)\n\n\nMedian [Min, Max]\n1.40 [1.00, 4.00]"
  },
  {
    "objectID": "archive/2024-02-konrad/3-modelos.html#especificar-el-modelo-2",
    "href": "archive/2024-02-konrad/3-modelos.html#especificar-el-modelo-2",
    "title": "3. Estimar un modelo",
    "section": "1. Especificar el modelo",
    "text": "1. Especificar el modelo\nNo es necesario volver a especificar el modelo, ya que ya lo hicimos en la parte I. Pero si lo hiciéramos, sería de la siguiente manera:\n\nlm_model &lt;-\n  logistic_reg() %&gt;%\n  set_engine(\"glm\", family = \"binomial\") |&gt;\n  set_mode(\"classification\")"
  },
  {
    "objectID": "archive/2024-02-konrad/3-modelos.html#estimar-el-modelo-1",
    "href": "archive/2024-02-konrad/3-modelos.html#estimar-el-modelo-1",
    "title": "3. Estimar un modelo",
    "section": "2. Estimar el modelo",
    "text": "2. Estimar el modelo\nEstimar el modelo con la función fit(). Se especifica la variable de resultado (PYALC) y los predictores (.). Se utiliza el objeto datos_entrenamiento como base de datos.\n\nlm_results &lt;- lm_model |&gt;\n    fit(PYALC ~ ., data = datos_entrenamiento)"
  },
  {
    "objectID": "archive/2024-02-konrad/3-modelos.html#obtener-los-resultados-del-modelo-2",
    "href": "archive/2024-02-konrad/3-modelos.html#obtener-los-resultados-del-modelo-2",
    "title": "3. Estimar un modelo",
    "section": "3. Obtener los resultados del modelo",
    "text": "3. Obtener los resultados del modelo\nObtener los coeficientes (betas) del modelo en OR con sus intervalos de confianza.\n\nlm_results |&gt; tidy(exp=TRUE, conf.int=TRUE)\n\n# A tibble: 15 × 7\n   term           estimate std.error statistic   p.value conf.low conf.high\n   &lt;chr&gt;             &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n 1 (Intercept)     0.00472   0.198     -27.0   4.20e-161  0.00319   0.00694\n 2 CRPAD           1.20      0.0340      5.43  5.71e-  8  1.13      1.29   \n 3 CRLNFD          1.25      0.0519      4.34  1.43e-  5  1.13      1.39   \n 4 FRPFD           2.82      0.0785     13.2   6.81e- 40  2.42      3.30   \n 5 FRPFM           1.14      0.0523      2.44  1.46e-  2  1.03      1.26   \n 6 SRLCS           1.28      0.0617      3.94  8.09e-  5  1.13      1.44   \n 7 PRFAD           2.52      0.0625     14.8   1.87e- 49  2.23      2.85   \n 8 PRATA           0.746     0.0623     -4.71  2.47e-  6  0.660     0.843  \n 9 YEAR2014        0.983     0.0616     -0.270 7.87e-  1  0.871     1.11   \n10 YEAR2015        0.685     0.0973     -3.89  9.97e-  5  0.566     0.829  \n11 YEAR2016        0.844     0.110      -1.53  1.25e-  1  0.681     1.05   \n12 YEAR2017        0.717     0.0791     -4.21  2.53e-  5  0.614     0.837  \n13 GRADE           1.35      0.0182     16.4   9.64e- 61  1.30      1.40   \n14 GENDERFemenino  0.971     0.0503     -0.579 5.63e-  1  0.880     1.07   \n15 AGE             1.00      0.00558     0.172 8.64e-  1  0.991     1.01"
  },
  {
    "objectID": "archive/2024-02-konrad/3-modelos.html#evaluar-el-modelo-1",
    "href": "archive/2024-02-konrad/3-modelos.html#evaluar-el-modelo-1",
    "title": "3. Estimar un modelo",
    "section": "4. Evaluar el modelo",
    "text": "4. Evaluar el modelo\nHay varias formas de evaluar un modelo. Algunas de las más comunes son: - Métricas de ajuste - Área bajo la curva (AUC) - Sensibilidad y especificidad - Matrices de confusión …\nDado que nuestro objevito es predecir el consumo de alcohol, vamos a utilizar las métricas que evaluen el modelo según su desempeño en la clasificación de observaciones (accuracy o exactitud)."
  },
  {
    "objectID": "archive/2024-02-konrad/3-modelos.html#evaluar-el-modelo-2",
    "href": "archive/2024-02-konrad/3-modelos.html#evaluar-el-modelo-2",
    "title": "3. Estimar un modelo",
    "section": "4. Evaluar el modelo",
    "text": "4. Evaluar el modelo\nUtilizar el modelo para predecir los valores de la variable dependiente en los datos de entrenamiento.\n\npredecir_estos_valores &lt;- datos_entrenamiento  |&gt;  \n    select(-PYALC)  |&gt; \n    slice(1:10)\n\npredict(lm_results, predecir_estos_valores)\n\n# A tibble: 10 × 1\n   .pred_class    \n   &lt;fct&gt;          \n 1 Sí ha consumido\n 2 No ha consumido\n 3 No ha consumido\n 4 Sí ha consumido\n 5 Sí ha consumido\n 6 Sí ha consumido\n 7 Sí ha consumido\n 8 No ha consumido\n 9 Sí ha consumido\n10 Sí ha consumido\n\n\nObtener las predicciones en forma de probabilidades\n\npredict(lm_results, predecir_estos_valores, type=\"prob\")\n\n# A tibble: 10 × 2\n   `.pred_No ha consumido` `.pred_Sí ha consumido`\n                     &lt;dbl&gt;                   &lt;dbl&gt;\n 1                  0.437                    0.563\n 2                  0.635                    0.365\n 3                  0.745                    0.255\n 4                  0.328                    0.672\n 5                  0.275                    0.725\n 6                  0.313                    0.687\n 7                  0.0875                   0.912\n 8                  0.583                    0.417\n 9                  0.493                    0.507\n10                  0.325                    0.675"
  },
  {
    "objectID": "archive/2024-02-konrad/3-modelos.html#evaluar-el-modelo-3",
    "href": "archive/2024-02-konrad/3-modelos.html#evaluar-el-modelo-3",
    "title": "3. Estimar un modelo",
    "section": "4. Evaluar el modelo",
    "text": "4. Evaluar el modelo\nObtener las predicciones y los valores observadods para calcular algunas métricas.\n\nentrenamiento &lt;- datos_entrenamiento %&gt;% \n    select(-PYALC)\n\nprediccion &lt;- predict(lm_results, entrenamiento)\n\nresultados_prueba &lt;- cbind(prediccion, datos_entrenamiento) |&gt; \n  select(.pred_class, PYALC, everything()) |&gt; \n  tibble()\n\nresultados_prueba\n\n# A tibble: 10,005 × 13\n   .pred_class     PYALC  CRPAD CRLNFD FRPFD FRPFM SRLCS PRFAD PRATA YEAR  GRADE\n   &lt;fct&gt;           &lt;fct&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt; &lt;dbl&gt;\n 1 Sí ha consumido No ha…  4      2     1     1.62  1.86  1      1   2014      7\n 2 No ha consumido No ha…  1      2     1     2     2.17  1      1.2 2017      7\n 3 No ha consumido No ha…  1      2.2   1     1.25  1.6   1      1.2 2017      6\n 4 Sí ha consumido No ha…  1      1.67  1     1.12  2.43  1.5    1.2 2012…     9\n 5 Sí ha consumido No ha…  3.75   2.33  1     2     2.43  1.25   1   2014      8\n 6 Sí ha consumido No ha…  3.25   1.67  1.33  1.62  1.86  1.5    1.2 2014      7\n 7 Sí ha consumido No ha…  1.75   1.8   2     2     1.67  2      2   2017     11\n 8 No ha consumido No ha…  1      3.4   1     4     1.83  1      1   2017      6\n 9 Sí ha consumido No ha…  2.75   2.17  1     1.5   3.29  1      1.2 2014      6\n10 Sí ha consumido No ha…  1      1.8   1     2.29  1.86  1.75   1   2014      8\n# ℹ 9,995 more rows\n# ℹ 2 more variables: GENDER &lt;fct&gt;, AGE &lt;dbl&gt;"
  },
  {
    "objectID": "archive/2024-02-konrad/3-modelos.html#métricas-1",
    "href": "archive/2024-02-konrad/3-modelos.html#métricas-1",
    "title": "3. Estimar un modelo",
    "section": "Métricas",
    "text": "Métricas\nExactitud (accuracy): Es una métrica que mide la proporción de predicciones correctas realizadas por un modelo en comparación con el total de predicciones realizadas. Es decir, la cantidad de veces que el modelo acertó sobre el total de datos que se le presentaron.\nSensibilidad (sensitivity/recall): Es la proporción de verdaderos positivos (TP) que son identificados correctamente por el modelo en relación con el total de verdaderos positivos y falsos negativos (FN). La sensibilidad mide la capacidad del modelo para detectar correctamente los casos positivos.\nEspecificidad (Specificity): Es la proporción de verdaderos negativos (TN) que son identificados correctamente por el modelo en relación con el total de verdaderos negativos y falsos positivos (FP). La especificidad mide la capacidad del modelo para detectar correctamente los casos negativos."
  },
  {
    "objectID": "archive/2024-02-konrad/3-modelos.html#métricas-2",
    "href": "archive/2024-02-konrad/3-modelos.html#métricas-2",
    "title": "3. Estimar un modelo",
    "section": "Métricas",
    "text": "Métricas\nPrecision (Precisión): Es la proporción de verdaderos positivos (TP) que son identificados correctamente por el modelo en relación con el total de verdaderos positivos y falsos positivos (FP). La precisión mide la capacidad del modelo para no identificar falsamente un caso como positivo.\nF-measure (Puntuación F): Es una métrica que combina la precisión y el recall en una sola puntuación. El valor de la F-measure oscila entre 0 y 1, siendo 1 el valor óptimo.\nKappa (Coeficiente Kappa): Es una medida de concordancia que compara la cantidad de acuerdos observados entre el modelo y las observaciones reales con la cantidad de acuerdos que se esperarían por casualidad. Un valor de kappa cercano a 1 indica una concordancia casi perfecta entre el modelo y las observaciones reales."
  },
  {
    "objectID": "archive/2024-02-konrad/3-modelos.html#métricas-3",
    "href": "archive/2024-02-konrad/3-modelos.html#métricas-3",
    "title": "3. Estimar un modelo",
    "section": "Métricas",
    "text": "Métricas"
  },
  {
    "objectID": "archive/2024-02-konrad/3-modelos.html#calcular-las-métricas",
    "href": "archive/2024-02-konrad/3-modelos.html#calcular-las-métricas",
    "title": "3. Estimar un modelo",
    "section": "Calcular las métricas",
    "text": "Calcular las métricas\nCon los datos observados y los predichos, se pueden calcular las métricas del modelo.\n\nconf_mat(resultados_prueba, truth = PYALC,\n         estimate = .pred_class)\n\n                 Truth\nPrediction        No ha consumido Sí ha consumido\n  No ha consumido            1394             730\n  Sí ha consumido            1523            6358\n\naccuracy(resultados_prueba, truth = PYALC,\n         estimate = .pred_class)\n\n# A tibble: 1 × 3\n  .metric  .estimator .estimate\n  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;\n1 accuracy binary         0.775\n\nsens(resultados_prueba, truth = PYALC,\n    estimate = .pred_class, event_level = \"second\")\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 sens    binary         0.897"
  },
  {
    "objectID": "archive/2024-02-konrad/3-modelos.html#calcular-las-métricas-1",
    "href": "archive/2024-02-konrad/3-modelos.html#calcular-las-métricas-1",
    "title": "3. Estimar un modelo",
    "section": "Calcular las métricas",
    "text": "Calcular las métricas\nMás métricas\n\nspec(resultados_prueba, truth = PYALC,\n    estimate = .pred_class, event_level = \"second\")\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 spec    binary         0.478\n\nprecision(resultados_prueba, truth = PYALC,\n    estimate = .pred_class)\n\n# A tibble: 1 × 3\n  .metric   .estimator .estimate\n  &lt;chr&gt;     &lt;chr&gt;          &lt;dbl&gt;\n1 precision binary         0.656\n\nrecall(resultados_prueba, truth = PYALC,\n    estimate = .pred_class, event_level=\"second\")\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 recall  binary         0.897\n\nkap(resultados_prueba, truth = PYALC,\n    estimate = .pred_class)\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 kap     binary         0.407"
  },
  {
    "objectID": "archive/2024-02-konrad/3-modelos.html#calcular-las-métricas-2",
    "href": "archive/2024-02-konrad/3-modelos.html#calcular-las-métricas-2",
    "title": "3. Estimar un modelo",
    "section": "Calcular las métricas",
    "text": "Calcular las métricas\nCalcular todas las métricas y guardarlas en una base de datos\n\ncustom_metrics &lt;- metric_set(accuracy, sens, spec, precision, recall, f_meas, kap, mcc)\n\nlm_metrics  &lt;- custom_metrics(resultados_prueba,\n  truth = PYALC,\n  estimate = .pred_class, \n  event_level = \"second\"\n)  |&gt; \nmutate(model= \"Regresión Logística\")"
  },
  {
    "objectID": "archive/2024-02-konrad/3-modelos.html#tabla-de-métricas",
    "href": "archive/2024-02-konrad/3-modelos.html#tabla-de-métricas",
    "title": "3. Estimar un modelo",
    "section": "Tabla de Métricas",
    "text": "Tabla de Métricas\n\nlibrary(gt)\n\ncustom_metrics(resultados_prueba,\n  truth = PYALC,\n  estimate = .pred_class\n) |&gt; gt()\n\n\n\n\n\n  \n    \n    \n      .metric\n      .estimator\n      .estimate\n    \n  \n  \n    accuracy\nbinary\n0.7748126\n    sens\nbinary\n0.4778882\n    spec\nbinary\n0.8970090\n    precision\nbinary\n0.6563089\n    recall\nbinary\n0.4778882\n    f_meas\nbinary\n0.5530649\n    kap\nbinary\n0.4074916\n    mcc\nbinary\n0.4166529"
  },
  {
    "objectID": "archive/2024-02-konrad/3-modelos.html#área-bajo-la-curva",
    "href": "archive/2024-02-konrad/3-modelos.html#área-bajo-la-curva",
    "title": "3. Estimar un modelo",
    "section": "Área bajo la curva",
    "text": "Área bajo la curva\nEl área bajo la curva (AUC) es una métrica que mide la capacidad de un modelo para distinguir entre dos clases. En el caso de un modelo de regresión logística, el AUC mide la capacidad del modelo para distinguir entre los que han consumido alcohol y los que no.\n\nprediccion_auc &lt;- predict(lm_results, entrenamiento, type = \"prob\")\n\nresultados_prueba_auc &lt;- cbind(prediccion_auc, datos_entrenamiento) |&gt;\n  tibble()\n\nroc_auc(resultados_prueba_auc,\n  truth = PYALC,\n  `.pred_Sí ha consumido`,\n  event_level = \"second\"\n)\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 roc_auc binary         0.795\n\nroc_curve(resultados_prueba_auc,\n  truth = PYALC,\n   `.pred_Sí ha consumido`,\n  event_level = \"second\"\n) |&gt; autoplot()"
  },
  {
    "objectID": "archive/2024-02-konrad/1-introduccion.html#agradecimientos",
    "href": "archive/2024-02-konrad/1-introduccion.html#agradecimientos",
    "title": "1. Introducción a Machine Learning con tidymodels",
    "section": "Agradecimientos",
    "text": "Agradecimientos\nEste workshop es posible gracias a la colaboración de la Fundación Universitaria Konrad Lorenz, la Universidad de Miami, a través del Frost Institute for Data Science and Computing y el Department of Public Health Sciences, y la Corporación Nuevos Rumbos."
  },
  {
    "objectID": "archive/2024-02-konrad/1-introduccion.html#temas",
    "href": "archive/2024-02-konrad/1-introduccion.html#temas",
    "title": "1. Introducción a Machine Learning con tidymodels",
    "section": "Temas",
    "text": "Temas\n\n\n\nTipos de modelos\n\nDescriptivo\nInferencial\nPredictivo\n\nMachine Learning\n\nSupervised\n\nClasificación\nRegresión\n\nUnsupervised\n\nClustering\n\nReinforcement Learning\n\n\n\n\nIdeas principales\n\nError de generalización\nEquilibrio entre la varianza y el sesgo\nRegularización"
  },
  {
    "objectID": "archive/2024-02-konrad/1-introduccion.html#tipos-de-modelos",
    "href": "archive/2024-02-konrad/1-introduccion.html#tipos-de-modelos",
    "title": "1. Introducción a Machine Learning con tidymodels",
    "section": "Tipos de modelos",
    "text": "Tipos de modelos\n\n\n\nDescriptivos\n\nDescribir las características de una base de datos\nVisualizar los datos\nResumir los datos\nGenerar hipótesis\n\n\n\nInferencial\n\nEstimar la probabilidad de que ocurra un evento\nProducir una estimación de un parámetro poblacional\nProbar una hipótesis\nIdea predeterminada y se prueba\nValor p, intervalo de confianza\n\n\n\nPredictivo\n\nAnticipar el valor de una variable\nAplicar una regla a un evento que no ha ocurrido\nMayor interés en la predicción que en la inferencia\nPuede ser que no importe el mecanismo"
  },
  {
    "objectID": "archive/2024-02-konrad/1-introduccion.html#otra-clasificación-es",
    "href": "archive/2024-02-konrad/1-introduccion.html#otra-clasificación-es",
    "title": "1. Introducción a Machine Learning con tidymodels",
    "section": "Otra clasificación es",
    "text": "Otra clasificación es\n\nModelos explicativos\n\nInferencia Causal\nTeoría\nEfectos\nDAGs\n\nModelos predictivos\n\nMachine Learning\nBlack box\nNo énfasis en el mecanismo\nDesarrollado con métrica de predicción\nSesgo y varianza"
  },
  {
    "objectID": "archive/2024-02-konrad/1-introduccion.html#machine-learning",
    "href": "archive/2024-02-konrad/1-introduccion.html#machine-learning",
    "title": "1. Introducción a Machine Learning con tidymodels",
    "section": "Machine Learning",
    "text": "Machine Learning\n\n\nNo-supervisado\nNo hay una variable de resultado\n\nPor ejemplo\n\nComponentes principales\nReducción de dimensionalidad\n\n\n\n\nSupervisado\nHay una variable de resultado\n\nRegresión: variable de resultado continua\n\nClasificación: variable de resultado categórica"
  },
  {
    "objectID": "archive/2024-02-konrad/1-introduccion.html#en-qué-consiste-el-análisis-de-datos",
    "href": "archive/2024-02-konrad/1-introduccion.html#en-qué-consiste-el-análisis-de-datos",
    "title": "1. Introducción a Machine Learning con tidymodels",
    "section": "¿En qué consiste el análisis de datos?",
    "text": "¿En qué consiste el análisis de datos?\n¿Cuál es el inicio y el final del análisis de datos?\n\n¿La creación del modelo es el primer paso?\n¿Limpiar los datos?\n¿Explorar los datos?\n¿Cómo se van a evaluar los modelos?"
  },
  {
    "objectID": "archive/2024-02-konrad/1-introduccion.html#gráfico-del-proceso-de-análisis-de-datos",
    "href": "archive/2024-02-konrad/1-introduccion.html#gráfico-del-proceso-de-análisis-de-datos",
    "title": "1. Introducción a Machine Learning con tidymodels",
    "section": "Gráfico del proceso de análisis de datos",
    "text": "Gráfico del proceso de análisis de datos\nSe inicia con importar los datos, seguido por la organización-limpieza de los datos, la exploración, la creación de modelos y finalmente la comunicación de los resultados.\n\nimagen de R4DS"
  },
  {
    "objectID": "archive/2024-02-konrad/1-introduccion.html#proceso-de-análisis-de-datos",
    "href": "archive/2024-02-konrad/1-introduccion.html#proceso-de-análisis-de-datos",
    "title": "1. Introducción a Machine Learning con tidymodels",
    "section": "Proceso de análisis de datos",
    "text": "Proceso de análisis de datos\n\nExplorar los datos (EDA)\nModelos iniciales\nEvaluación de los modelos\n“Ingeniería de variables”- crear nuevas variables\nAjustar-sintonizar los modelos\nEvaluación final de los modelos\nModelo Final\n\n imagen de Tidymodels"
  },
  {
    "objectID": "archive/2024-02-konrad/1-introduccion.html#cuál-es-el-mejor-sofware-para-hacer-esto",
    "href": "archive/2024-02-konrad/1-introduccion.html#cuál-es-el-mejor-sofware-para-hacer-esto",
    "title": "1. Introducción a Machine Learning con tidymodels",
    "section": "¿Cuál es el mejor sofware para hacer esto?",
    "text": "¿Cuál es el mejor sofware para hacer esto?\n\n\n\nPython\nR\nMatlab\nJulia\nStata\nSAS\nSPSS\nMplus"
  },
  {
    "objectID": "archive/2024-02-konrad/1-introduccion.html#en-este-workshop-utilizaremos",
    "href": "archive/2024-02-konrad/1-introduccion.html#en-este-workshop-utilizaremos",
    "title": "1. Introducción a Machine Learning con tidymodels",
    "section": "En este workshop utilizaremos",
    "text": "En este workshop utilizaremos"
  },
  {
    "objectID": "archive/2024-02-konrad/1-introduccion.html#analizar-datos-en-r",
    "href": "archive/2024-02-konrad/1-introduccion.html#analizar-datos-en-r",
    "title": "1. Introducción a Machine Learning con tidymodels",
    "section": "Analizar datos en R",
    "text": "Analizar datos en R\n\n\n\nUsar base R\nUsar tidyverse"
  },
  {
    "objectID": "archive/2024-02-konrad/1-introduccion.html#tidyverse",
    "href": "archive/2024-02-konrad/1-introduccion.html#tidyverse",
    "title": "1. Introducción a Machine Learning con tidymodels",
    "section": "Tidyverse",
    "text": "Tidyverse\n\n\nggplot2 - para visualización de gráficos dplyr - para el procesamiento de datos tidyr - para la transformación de datos en formato “tidy” (ordenado) readr - para la lectura de datos en diferentes formatos (CSV, TSV, etc.) purrr - para la programación funcional tibble - para la creación de data frames en formato “tidy” stringr - para la manipulación de cadenas de texto forcats- para la manipulación de factores más"
  },
  {
    "objectID": "archive/2024-02-konrad/1-introduccion.html#tidyverse-1",
    "href": "archive/2024-02-konrad/1-introduccion.html#tidyverse-1",
    "title": "1. Introducción a Machine Learning con tidymodels",
    "section": "Tidyverse",
    "text": "Tidyverse\n\nPipe\nnombre_de_los_objetos\nUso de las comillas\nRetorna un objeto de la misma clase\nProgramación funcional"
  },
  {
    "objectID": "archive/2024-02-konrad/1-introduccion.html#tidymodels",
    "href": "archive/2024-02-konrad/1-introduccion.html#tidymodels",
    "title": "1. Introducción a Machine Learning con tidymodels",
    "section": "Tidymodels",
    "text": "Tidymodels\n\n\nparsnip - para la especificación de modelos recipes - para la preparación de datos rsample - para la validación de modelos tune - para la sintonización de hiperparámetros workflows - para la creación de flujos de trabajo dials - para la selección de hiperparámetros yardstick - para la evaluación de modelos más"
  },
  {
    "objectID": "archive/2024-02-konrad/1-introduccion.html#este-workshop",
    "href": "archive/2024-02-konrad/1-introduccion.html#este-workshop",
    "title": "1. Introducción a Machine Learning con tidymodels",
    "section": "Este workshop",
    "text": "Este workshop\nEn este workshop vamos a utilizar tidymodels para desarrollar los models.\nUtilizaremos una base de datos que contiene información sobre factores de riesgo asociados al consumo de drogas en adolescentes. Vamos a desarrollar en primer lugar un modelo descriptivo que nos permita entender la relación entre las variables. Luego vamos a desarrollar un modelo predictivo que nos permita predecir el consumo de drogas en adolescentes basados en los factores de riesgo."
  },
  {
    "objectID": "archive/2024-02-konrad/1-introduccion.html#objetivos",
    "href": "archive/2024-02-konrad/1-introduccion.html#objetivos",
    "title": "1. Introducción a Machine Learning con tidymodels",
    "section": "Objetivos",
    "text": "Objetivos\n\nIdeas principales\n\nCalcular el error de un modelo en nuevos datos.\nBuscar el equilibrio entre la varianza y el sesgo de un modelo.\nAplicar regularización para evitar el sobreajuste."
  },
  {
    "objectID": "archive/2024-02-konrad/1-introduccion.html#resumen",
    "href": "archive/2024-02-konrad/1-introduccion.html#resumen",
    "title": "1. Introducción a Machine Learning con tidymodels",
    "section": "Resumen",
    "text": "Resumen\n\nModelos descriptivos, inferenciales y predictivos\nMachine Learning\nProceso de análisis de datos\nTidyverse\nTidymodels"
  },
  {
    "objectID": "archive/2023-12-um/index.html",
    "href": "archive/2023-12-um/index.html",
    "title": "Imbalanced data in Machine Learning Modeling",
    "section": "",
    "text": "Imbalanced data is a term used to describe datasets where there’s an uneven representation of target outcomes across different categories. In such cases, one category often has a significantly higher frequency compared to others. A classic example can be seen in binary classification problems, where one class may have a disproportionate number of observations relative to its counterpart. This imbalance presents a unique challenge in modeling: standard algorithms, which are usually designed for more evenly distributed data, may inherently favor the more common class. This bias can result in suboptimal performance, particularly in accurately predicting the outcomes for the minority class. Imbalance datasets are a practical concern in various fields, including research on adolescent health issues and drug use, where some outcomes or behaviors might be notably less common but are crucial to identify correctly.\nIn this workshop, we will explore various modeling techniques and resampling methods tailored to this specific challenge. Key topics include cross-validation, estimation of empirical error, and the identification of model hyperparameters. This comprehensive approach will provide participants with a deep understanding of handling imbalanced datasets effectively.\nThis workshop will be held at the University of Miami on Tuesday, December 5, 2023. We will meet in room 1080A at Don Soffer Clinical Research Center.\nWe will utilize the R programming language along with the tidymodel package to implement our models. The workshop will include a range of practical exercises and illustrative examples. Participants are expected to have a basic understanding of R and familiarity with regression analysis."
  },
  {
    "objectID": "archive/2023-12-um/index.html#overview",
    "href": "archive/2023-12-um/index.html#overview",
    "title": "Imbalanced data in Machine Learning Modeling",
    "section": "",
    "text": "Imbalanced data is a term used to describe datasets where there’s an uneven representation of target outcomes across different categories. In such cases, one category often has a significantly higher frequency compared to others. A classic example can be seen in binary classification problems, where one class may have a disproportionate number of observations relative to its counterpart. This imbalance presents a unique challenge in modeling: standard algorithms, which are usually designed for more evenly distributed data, may inherently favor the more common class. This bias can result in suboptimal performance, particularly in accurately predicting the outcomes for the minority class. Imbalance datasets are a practical concern in various fields, including research on adolescent health issues and drug use, where some outcomes or behaviors might be notably less common but are crucial to identify correctly.\nIn this workshop, we will explore various modeling techniques and resampling methods tailored to this specific challenge. Key topics include cross-validation, estimation of empirical error, and the identification of model hyperparameters. This comprehensive approach will provide participants with a deep understanding of handling imbalanced datasets effectively.\nThis workshop will be held at the University of Miami on Tuesday, December 5, 2023. We will meet in room 1080A at Don Soffer Clinical Research Center.\nWe will utilize the R programming language along with the tidymodel package to implement our models. The workshop will include a range of practical exercises and illustrative examples. Participants are expected to have a basic understanding of R and familiarity with regression analysis."
  },
  {
    "objectID": "archive/2023-12-um/index.html#organizers",
    "href": "archive/2023-12-um/index.html#organizers",
    "title": "Imbalanced data in Machine Learning Modeling",
    "section": "Organizers",
    "text": "Organizers\nFrancisco Cardozo. University of Miami.\nEric C. Brown.. University of Miami. María Fernanda Reyes, Universidad de los Andes."
  },
  {
    "objectID": "archive/2023-12-um/index.html#first-ring---the-two-paths-of-destiny",
    "href": "archive/2023-12-um/index.html#first-ring---the-two-paths-of-destiny",
    "title": "Imbalanced data in Machine Learning Modeling",
    "section": "First Ring - The Two Paths of Destiny",
    "text": "First Ring - The Two Paths of Destiny\n\nDivide the data into two groups, some data to train the model and another to test it.\n\nIn an age long past, when the world was still uncharted, the First Ring emerged, gleaming with the promise of unexplored knowledge. It was said to hold the power to split the fabric of reality into two distinct paths: one leading through the verdant forests of Training, lush with learning and growth, and the other winding into the misty valleys of Testing, where truth is revealed in the shadows. Those who embark on this journey, much like the brave heroes of old, are fated to traverse these paths, each step a new chapter in their quest for wisdom."
  },
  {
    "objectID": "archive/2023-12-um/index.html#second-ring---the-mirror-of-fates",
    "href": "archive/2023-12-um/index.html#second-ring---the-mirror-of-fates",
    "title": "Imbalanced data in Machine Learning Modeling",
    "section": "Second Ring - The Mirror of Fates",
    "text": "Second Ring - The Mirror of Fates\n\nValidate the model with the data that was not used to train it.\n\nThe Second Ring was forged in the hidden realms, where magic and mystery intertwine. It was no ordinary artifact, for it held a mirror reflecting not just images but destinies. In the hands of the learned, this ring divided the waters of Training, creating a silent pool of Validation, serene yet profound. Here, seers and sages could gaze into the depths, discerning the hidden strengths and weaknesses of their creations, much like the ancient oracles who, in their sacred groves, saw truths beyond the ken of mortals."
  },
  {
    "objectID": "archive/2023-12-um/index.html#third-ring---the-balance-of-light-and-shadow",
    "href": "archive/2023-12-um/index.html#third-ring---the-balance-of-light-and-shadow",
    "title": "Imbalanced data in Machine Learning Modeling",
    "section": "Third Ring - The Balance of Light and Shadow",
    "text": "Third Ring - The Balance of Light and Shadow\n\nThe balance between bias and variance is the key to the power of the model.\n\nIn the great halls of knowledge, the Third Ring was revered as the most elusive and powerful. It was the embodiment of the eternal struggle between Light and Shadow, an artifact that sought the perfect equilibrium. In the hands of a master, it could weave together the threads of Variance and Bias, creating a tapestry as balanced and harmonious as the cycle of day and night. The quest for this balance was akin to a legendary saga, where heroes journeyed through realms of dazzling brilliance and profound darkness, seeking the ancient wisdom that would bring peace to the land.\n\nSecret ring: trees are very good at learning the distribution of training data, but sometimes, they tend to over-specialize on the data they are trained on. One way to solve this is to make many trees, which we can then average."
  },
  {
    "objectID": "archive/2023-11-icfes/2-taller-icfes.html",
    "href": "archive/2023-11-icfes/2-taller-icfes.html",
    "title": "Taller Introducción a Machine Learning en el 14° Seminario Internacional de Investigación sobre la Calidad de la Educación - SiiCE",
    "section": "",
    "text": "Hay muchas formas de estimar modelos en R\n\nlm(formula, data, ...)\nstan_glm(formula, data, family= \"gaussian\",...)\nglmnet(x=matrix, y=vector, family=\"gaussian\",...)\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nlm(): Ajusta un modelo de regresión lineal a los datos.\nstan_glm(): Ajusta un modelo de regresión utilizando el paquete Stan.\nglmnet(): Ajusta un modelo de regresión utilizando la regularización Lasso o Ridge.\n\n\n\nTidymodels ofrece una sintaxis general para estimar los modelos\n\nEspecificar el tipo de modelo\n\nlinear_reg(), logistic_reg(), decition_tree()\n\nEspecificar el tipo de outcome\n\nRegresión para outcomes continuos\nClasificación: multinomial, ordinal, binaria\n\n\n\nlinear_reg() |&gt; \n  set_engine(\"lm\") \n\nLinear Regression Model Specification (regression)\n\nComputational engine: lm \n\nlinear_reg() |&gt; \n    set_engine(\"glmnet\") \n\nLinear Regression Model Specification (regression)\n\nComputational engine: glmnet \n\nlinear_reg() |&gt;\n    set_engine(\"stan\") \n\nLinear Regression Model Specification (regression)\n\nComputational engine: stan \n\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nlibrary(): Carga el paquete tidymodels en R.\ntidymodels_prefer(): Establece el paquete tidymodels como el preferido para las funciones de modelado en R.\nlinear_reg(): Crea una especificación de modelo de regresión lineal en el marco de trabajo tidymodels.\nset_engine(): Establece el motor de cálculo para un objeto de especificación de modelo. Se establece en “lm” para la primera llamada a linear_reg(), “glmnet” para la segunda llamada y “stan” para la tercera.\n\n\n\nPara estimar un modelo hay que hacer los siguientes pasos:\n\n\n\nlm_model &lt;-\n    logistic_reg() %&gt;% \n    set_engine(\"glm\", family=\"binomial\") |&gt;\n    set_mode(\"classification\")\n\nEspecificar un modelo de regresión logística. Se establece el “paquete”, en este caso “glm” y opciones del paquete (la distribución de la variable de respuesta). Además, se establece el modo de modelado en “classification” para indicar que es una variable categórica. El resultado se almacena en el objeto lm_model.\n\n\n\n\nlm_results &lt;- lm_model |&gt;\n    fit(puntaje ~ ., data = taller_icfes)\n\nAquí se ajusta-estima el modelo utilizando la función fit(). Se especifica la variable de respuesta (puntaje) y los predictores (.) y se utiliza el objeto taller_icfes como base de datos.\n\n\n\n\nlm_results |&gt; tidy() \n\n# A tibble: 49 × 5\n   term                                     estimate std.error statistic p.value\n   &lt;chr&gt;                                       &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n 1 (Intercept)                              -1.64       0.500    -3.28   1.03e-3\n 2 fami_personashogar_9                     -0.243      0.0418   -5.82   5.73e-9\n 3 fami_cuartoshogar_92                      0.100      0.161     0.622  5.34e-1\n 4 fami_cuartoshogar_93                      0.230      0.162     1.42   1.56e-1\n 5 fami_cuartoshogar_94                      0.209      0.178     1.18   2.38e-1\n 6 fami_cuartoshogar_95                      0.287      0.224     1.28   1.99e-1\n 7 fami_cuartoshogar_96                      0.0285     0.253     0.113  9.10e-1\n 8 fami_educacionpadre_9No aplica            0.00678    0.158     0.0428 9.66e-1\n 9 fami_educacionpadre_9Primaria            -0.149      0.0894   -1.67   9.57e-2\n10 fami_educacionpadre_9Técnico o Tecnólogo  0.555      0.0921    6.02   1.70e-9\n# ℹ 39 more rows\n\nlm_results |&gt; glance()\n\n# A tibble: 1 × 8\n  null.deviance df.null logLik   AIC   BIC deviance df.residual  nobs\n          &lt;dbl&gt;   &lt;int&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;       &lt;int&gt; &lt;int&gt;\n1         7781.    5888 -3420. 6938. 7265.    6840.        5840  5889\n\n\n\n\ntidy(): Esta función se utiliza para convertir los resultados de un modelo en un marco de datos “ordenado” que muestra los coeficientes del modelo, los errores estándar, los valores t y los valores p para cada variable independiente.\nglance(): Esta función se utiliza para resumir los resultados de un modelo como estadísticas globales del modelo, por ejemplo, R-cuadrado ajustado, el AIC y el BIC.\n\n\n\n\n\n\n\n\nTip\n\n\n\n\n\n\nlm_results |&gt; tidy(exp=TRUE, conf.int=TRUE)\n\n# A tibble: 49 × 7\n   term                  estimate std.error statistic p.value conf.low conf.high\n   &lt;chr&gt;                    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n 1 (Intercept)              0.194    0.500    -3.28   1.03e-3   0.0684     0.494\n 2 fami_personashogar_9     0.784    0.0418   -5.82   5.73e-9   0.722      0.851\n 3 fami_cuartoshogar_92     1.11     0.161     0.622  5.34e-1   0.809      1.52 \n 4 fami_cuartoshogar_93     1.26     0.162     1.42   1.56e-1   0.919      1.74 \n 5 fami_cuartoshogar_94     1.23     0.178     1.18   2.38e-1   0.873      1.75 \n 6 fami_cuartoshogar_95     1.33     0.224     1.28   1.99e-1   0.860      2.07 \n 7 fami_cuartoshogar_96     1.03     0.253     0.113  9.10e-1   0.626      1.69 \n 8 fami_educacionpadre_…    1.01     0.158     0.0428 9.66e-1   0.736      1.37 \n 9 fami_educacionpadre_…    0.862    0.0894   -1.67   9.57e-2   0.722      1.03 \n10 fami_educacionpadre_…    1.74     0.0921    6.02   1.70e-9   1.45       2.09 \n# ℹ 39 more rows\n\n\ntidy(exp=TRUE, conf.int=TRUE): Esta función se utiliza para convertir los resultados de un modelo en un marco de datos “ordenado” que muestra los coeficientes del modelo, los errores estándar, los valores t y los valores p para cada variable independiente. Los argumentos exp y conf.int se utilizan para incluir los intervalos de confianza y los exponentes en los resultados"
  },
  {
    "objectID": "archive/2023-11-icfes/2-taller-icfes.html#estimar-un-modelo",
    "href": "archive/2023-11-icfes/2-taller-icfes.html#estimar-un-modelo",
    "title": "Taller Introducción a Machine Learning en el 14° Seminario Internacional de Investigación sobre la Calidad de la Educación - SiiCE",
    "section": "",
    "text": "Hay muchas formas de estimar modelos en R\n\nlm(formula, data, ...)\nstan_glm(formula, data, family= \"gaussian\",...)\nglmnet(x=matrix, y=vector, family=\"gaussian\",...)\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nlm(): Ajusta un modelo de regresión lineal a los datos.\nstan_glm(): Ajusta un modelo de regresión utilizando el paquete Stan.\nglmnet(): Ajusta un modelo de regresión utilizando la regularización Lasso o Ridge.\n\n\n\nTidymodels ofrece una sintaxis general para estimar los modelos\n\nEspecificar el tipo de modelo\n\nlinear_reg(), logistic_reg(), decition_tree()\n\nEspecificar el tipo de outcome\n\nRegresión para outcomes continuos\nClasificación: multinomial, ordinal, binaria\n\n\n\nlinear_reg() |&gt; \n  set_engine(\"lm\") \n\nLinear Regression Model Specification (regression)\n\nComputational engine: lm \n\nlinear_reg() |&gt; \n    set_engine(\"glmnet\") \n\nLinear Regression Model Specification (regression)\n\nComputational engine: glmnet \n\nlinear_reg() |&gt;\n    set_engine(\"stan\") \n\nLinear Regression Model Specification (regression)\n\nComputational engine: stan \n\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nlibrary(): Carga el paquete tidymodels en R.\ntidymodels_prefer(): Establece el paquete tidymodels como el preferido para las funciones de modelado en R.\nlinear_reg(): Crea una especificación de modelo de regresión lineal en el marco de trabajo tidymodels.\nset_engine(): Establece el motor de cálculo para un objeto de especificación de modelo. Se establece en “lm” para la primera llamada a linear_reg(), “glmnet” para la segunda llamada y “stan” para la tercera.\n\n\n\nPara estimar un modelo hay que hacer los siguientes pasos:\n\n\n\nlm_model &lt;-\n    logistic_reg() %&gt;% \n    set_engine(\"glm\", family=\"binomial\") |&gt;\n    set_mode(\"classification\")\n\nEspecificar un modelo de regresión logística. Se establece el “paquete”, en este caso “glm” y opciones del paquete (la distribución de la variable de respuesta). Además, se establece el modo de modelado en “classification” para indicar que es una variable categórica. El resultado se almacena en el objeto lm_model.\n\n\n\n\nlm_results &lt;- lm_model |&gt;\n    fit(puntaje ~ ., data = taller_icfes)\n\nAquí se ajusta-estima el modelo utilizando la función fit(). Se especifica la variable de respuesta (puntaje) y los predictores (.) y se utiliza el objeto taller_icfes como base de datos.\n\n\n\n\nlm_results |&gt; tidy() \n\n# A tibble: 49 × 5\n   term                                     estimate std.error statistic p.value\n   &lt;chr&gt;                                       &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n 1 (Intercept)                              -1.64       0.500    -3.28   1.03e-3\n 2 fami_personashogar_9                     -0.243      0.0418   -5.82   5.73e-9\n 3 fami_cuartoshogar_92                      0.100      0.161     0.622  5.34e-1\n 4 fami_cuartoshogar_93                      0.230      0.162     1.42   1.56e-1\n 5 fami_cuartoshogar_94                      0.209      0.178     1.18   2.38e-1\n 6 fami_cuartoshogar_95                      0.287      0.224     1.28   1.99e-1\n 7 fami_cuartoshogar_96                      0.0285     0.253     0.113  9.10e-1\n 8 fami_educacionpadre_9No aplica            0.00678    0.158     0.0428 9.66e-1\n 9 fami_educacionpadre_9Primaria            -0.149      0.0894   -1.67   9.57e-2\n10 fami_educacionpadre_9Técnico o Tecnólogo  0.555      0.0921    6.02   1.70e-9\n# ℹ 39 more rows\n\nlm_results |&gt; glance()\n\n# A tibble: 1 × 8\n  null.deviance df.null logLik   AIC   BIC deviance df.residual  nobs\n          &lt;dbl&gt;   &lt;int&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;       &lt;int&gt; &lt;int&gt;\n1         7781.    5888 -3420. 6938. 7265.    6840.        5840  5889\n\n\n\n\ntidy(): Esta función se utiliza para convertir los resultados de un modelo en un marco de datos “ordenado” que muestra los coeficientes del modelo, los errores estándar, los valores t y los valores p para cada variable independiente.\nglance(): Esta función se utiliza para resumir los resultados de un modelo como estadísticas globales del modelo, por ejemplo, R-cuadrado ajustado, el AIC y el BIC.\n\n\n\n\n\n\n\n\nTip\n\n\n\n\n\n\nlm_results |&gt; tidy(exp=TRUE, conf.int=TRUE)\n\n# A tibble: 49 × 7\n   term                  estimate std.error statistic p.value conf.low conf.high\n   &lt;chr&gt;                    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n 1 (Intercept)              0.194    0.500    -3.28   1.03e-3   0.0684     0.494\n 2 fami_personashogar_9     0.784    0.0418   -5.82   5.73e-9   0.722      0.851\n 3 fami_cuartoshogar_92     1.11     0.161     0.622  5.34e-1   0.809      1.52 \n 4 fami_cuartoshogar_93     1.26     0.162     1.42   1.56e-1   0.919      1.74 \n 5 fami_cuartoshogar_94     1.23     0.178     1.18   2.38e-1   0.873      1.75 \n 6 fami_cuartoshogar_95     1.33     0.224     1.28   1.99e-1   0.860      2.07 \n 7 fami_cuartoshogar_96     1.03     0.253     0.113  9.10e-1   0.626      1.69 \n 8 fami_educacionpadre_…    1.01     0.158     0.0428 9.66e-1   0.736      1.37 \n 9 fami_educacionpadre_…    0.862    0.0894   -1.67   9.57e-2   0.722      1.03 \n10 fami_educacionpadre_…    1.74     0.0921    6.02   1.70e-9   1.45       2.09 \n# ℹ 39 more rows\n\n\ntidy(exp=TRUE, conf.int=TRUE): Esta función se utiliza para convertir los resultados de un modelo en un marco de datos “ordenado” que muestra los coeficientes del modelo, los errores estándar, los valores t y los valores p para cada variable independiente. Los argumentos exp y conf.int se utilizan para incluir los intervalos de confianza y los exponentes en los resultados"
  },
  {
    "objectID": "archive/2023-11-icfes/2-taller-icfes.html#dividir-los-datos",
    "href": "archive/2023-11-icfes/2-taller-icfes.html#dividir-los-datos",
    "title": "Taller Introducción a Machine Learning en el 14° Seminario Internacional de Investigación sobre la Calidad de la Educación - SiiCE",
    "section": "Dividir los datos",
    "text": "Dividir los datos\n\nDividir los datos en dos conjuntos\n\nEntrenamiento\n\nLa mayoría de los datos (¿70%, 80%?)\nAquí se ajusta el modelo\n\nPrueba\n\nUn pequeño conjunto de datos\nAquí se evaluará el modelo final\n\n\n\nLos datos de prueba se utilizan una sola vez, si se utilizan más de una vez, se convierten en parte del proceso de entrenamiento.\n\n\n\n\n\n\nWarning\n\n\n\nLa división de los datos se hace al nivel de unidad independiente de observación.\nEvitar a toda costa la contaminación del los datos de prueba (information leakage), es decir, no se puede filtrar la información de una base a la otra.\n\n\nEntonces, uno puede crear dos bases de datos con por ejemplo 80% y 20% de los datos. Pero, ¿cómo se hace esto en R?\n\nset.seed(1234)\n\ndatos_divididos &lt;- initial_split(taller_icfes, prop = 0.8, strata = \"puntaje\")\n\ndatos_entrenamiento &lt;- training(datos_divididos)\ndatos_prueba &lt;- testing(datos_divididos)\n\nLa opción strata es para que los datos de entrenamiento y prueba tengan la misma distribución de la variable puntaje\nA veces la selección aleatoria de la muestra es problemática, por ejemplo cuando hay una componente de tiempo en los datos. En este caso, se puede usar la función initial_time_split().\n\n\n\n\n\n\nTip\n\n\n\nset.seed(): se utiliza para establecer una semilla para la generación de números aleatorios en R. En este caso, se utiliza para establecer la semilla en 1234, lo que garantiza que los resultados sean reproducibles. Esto es especialmente importante cuando se trabaja con modelos de aprendizaje automático, ya que los resultados pueden variar según la semilla utilizada para la generación de números aleatorios.\ninitial_split(): Esta función se utiliza para dividir un data frame o tibble en conjuntos de entrenamiento y prueba. En este caso, se utiliza para dividir el objeto “taller_icfes” en conjuntos de entrenamiento y prueba en una proporción de 80/20, y estratificando por la columna “puntaje”.\ntraining(): Esta función se utiliza para extraer el conjunto de entrenamiento de un objeto creado con la función initial_split(). En este caso, se utiliza para extraer el conjunto de entrenamiento del objeto “datos_divididos”.\ntesting(): Esta función se utiliza para extraer el conjunto de prueba de un objeto creado con la función initial_split(). En este caso, se utiliza para extraer el conjunto de prueba del objeto “datos_divididos”.\n\n\nAhora, podemos repetir la estimación del modelo anterior, pero solo vamos a necesitar los pasos 2 y 3."
  },
  {
    "objectID": "archive/2023-11-icfes/2-taller-icfes.html#estimar-el-modelo-1",
    "href": "archive/2023-11-icfes/2-taller-icfes.html#estimar-el-modelo-1",
    "title": "Taller Introducción a Machine Learning en el 14° Seminario Internacional de Investigación sobre la Calidad de la Educación - SiiCE",
    "section": "2. Estimar el modelo",
    "text": "2. Estimar el modelo\nEstimación del modelo: Se utiliza la función lm_model() y fit() para ajustar un modelo de regresión lineal. La fórmula puntaje ~ . indica que se está modelando la variable puntaje como una función de todas las otras variables en el dataframe “datos_entrenamiento”.\n\nlm_results &lt;- lm_model |&gt;\n    fit(puntaje ~ ., data = datos_entrenamiento)"
  },
  {
    "objectID": "archive/2023-11-icfes/2-taller-icfes.html#visualizar-los-resultados-del-modelo",
    "href": "archive/2023-11-icfes/2-taller-icfes.html#visualizar-los-resultados-del-modelo",
    "title": "Taller Introducción a Machine Learning en el 14° Seminario Internacional de Investigación sobre la Calidad de la Educación - SiiCE",
    "section": "3. Visualizar los resultados del modelo",
    "text": "3. Visualizar los resultados del modelo\nVisualizar los resultados del modelo: Se utiliza la función tidy para obtener un resumen limpio y ordenado de los resultados del modelo. En el segundo uso de tidy, se exponencian los coeficientes y los intervalos de confianza.\n\nlm_results |&gt; tidy()\n\n# A tibble: 49 × 5\n   term                                     estimate std.error statistic p.value\n   &lt;chr&gt;                                       &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n 1 (Intercept)                               -1.68      0.524    -3.21   1.31e-3\n 2 fami_personashogar_9                      -0.261     0.0474   -5.50   3.76e-8\n 3 fami_cuartoshogar_92                       0.197     0.186     1.06   2.90e-1\n 4 fami_cuartoshogar_93                       0.358     0.187     1.91   5.62e-2\n 5 fami_cuartoshogar_94                       0.332     0.205     1.62   1.05e-1\n 6 fami_cuartoshogar_95                       0.485     0.255     1.90   5.74e-2\n 7 fami_cuartoshogar_96                       0.117     0.286     0.411  6.81e-1\n 8 fami_educacionpadre_9No aplica             0.0173    0.177     0.0979 9.22e-1\n 9 fami_educacionpadre_9Primaria             -0.0868    0.0992   -0.875  3.81e-1\n10 fami_educacionpadre_9Técnico o Tecnólogo   0.574     0.103     5.57   2.54e-8\n# ℹ 39 more rows\n\n\nPero,\n¿Cómo sabemos que el modelo es bueno?"
  },
  {
    "objectID": "archive/2023-11-icfes/2-taller-icfes.html#evaluar-el-modelo",
    "href": "archive/2023-11-icfes/2-taller-icfes.html#evaluar-el-modelo",
    "title": "Taller Introducción a Machine Learning en el 14° Seminario Internacional de Investigación sobre la Calidad de la Educación - SiiCE",
    "section": "4. Evaluar el modelo",
    "text": "4. Evaluar el modelo\nEvaluación del modelo: se hace una “predicción” utilizando el modelo ajustado. Primero, se seleccionan algunos valores de datos_entrenamiento para predecir. Luego, se utiliza la función predict para obtener las predicciones del modelo. En el segundo uso de predict, se solicita la probabilidad de las predicciones.\n\npredecir_estos_valores &lt;- datos_entrenamiento %&gt;% \n    select(-puntaje) %&gt;% \n    slice(1:10)\n\npredict(lm_results, predecir_estos_valores)\n\n# A tibble: 10 × 1\n   .pred_class\n   &lt;fct&gt;      \n 1 0          \n 2 0          \n 3 0          \n 4 0          \n 5 0          \n 6 0          \n 7 1          \n 8 0          \n 9 0          \n10 0          \n\n\n\npredict(lm_results, predecir_estos_valores, type=\"prob\")\n\n# A tibble: 10 × 2\n   .pred_0 .pred_1\n     &lt;dbl&gt;   &lt;dbl&gt;\n 1   0.923  0.0766\n 2   0.633  0.367 \n 3   0.772  0.228 \n 4   0.849  0.151 \n 5   0.703  0.297 \n 6   0.676  0.324 \n 7   0.475  0.525 \n 8   0.537  0.463 \n 9   0.700  0.300 \n10   0.788  0.212"
  },
  {
    "objectID": "archive/2023-11-icfes/2-taller-icfes.html#predicción-en-el-conjunto-completo-de-datos",
    "href": "archive/2023-11-icfes/2-taller-icfes.html#predicción-en-el-conjunto-completo-de-datos",
    "title": "Taller Introducción a Machine Learning en el 14° Seminario Internacional de Investigación sobre la Calidad de la Educación - SiiCE",
    "section": "Predicción en el conjunto completo de datos",
    "text": "Predicción en el conjunto completo de datos\nAhora vamos a realizar una predicción en todo el conjunto de datos de entrenamiento y los vamos a unir con los datos de entrenamiento originales. Luego, vamos a seleccionar y reordenar las columnas.\n\nentrenamiento &lt;- datos_entrenamiento %&gt;% \n    select(-puntaje)\n\nprediccion &lt;- predict(lm_results, entrenamiento)\n\nresultados_prueba &lt;- cbind(prediccion, datos_entrenamiento) |&gt; \n  select(.pred_class, puntaje, everything()) |&gt; \n  tibble()\n\nresultados_prueba  |&gt;  head(10)\n\n# A tibble: 10 × 16\n   .pred_class puntaje fami_personashogar_9 fami_cuartoshogar_9\n   &lt;fct&gt;       &lt;fct&gt;                  &lt;dbl&gt; &lt;chr&gt;              \n 1 0           0                          5 4                  \n 2 0           0                          3 3                  \n 3 0           0                          4 4                  \n 4 0           0                          4 3                  \n 5 0           0                          5 5                  \n 6 0           0                          5 3                  \n 7 1           0                          3 3                  \n 8 0           0                          4 4                  \n 9 0           0                          3 2                  \n10 0           0                          3 3                  \n# ℹ 12 more variables: fami_educacionpadre_9 &lt;chr&gt;,\n#   fami_educacionmadre_9 &lt;chr&gt;, fami_tienecomputador_9 &lt;chr&gt;,\n#   fami_tienelavadora_9 &lt;chr&gt;, fami_tienehornomicroogas_9 &lt;chr&gt;,\n#   fami_tieneautomovil_9 &lt;chr&gt;, fami_tieneconsolavideojuegos_9 &lt;chr&gt;,\n#   fami_tieneinternet_9 &lt;chr&gt;, fami_tieneserviciotv_9 &lt;chr&gt;,\n#   fami_trabajolaborpadre_9 &lt;chr&gt;, fami_trabajolabormadre_9 &lt;chr&gt;,\n#   fami_numlibros_9 &lt;chr&gt;"
  },
  {
    "objectID": "archive/2023-11-icfes/2-taller-icfes.html#métricas-para-evaluar-el-modelo",
    "href": "archive/2023-11-icfes/2-taller-icfes.html#métricas-para-evaluar-el-modelo",
    "title": "Taller Introducción a Machine Learning en el 14° Seminario Internacional de Investigación sobre la Calidad de la Educación - SiiCE",
    "section": "Métricas para evaluar el modelo",
    "text": "Métricas para evaluar el modelo\nAccuracy (Exactitud): Es una métrica que mide la proporción de predicciones correctas realizadas por un modelo en comparación con el total de predicciones realizadas. Es decir, la cantidad de veces que el modelo acertó sobre el total de datos que se le presentaron.\nSensitivity (Sensibilidad): Es la proporción de verdaderos positivos (TP) que son identificados correctamente por el modelo en relación con el total de verdaderos positivos y falsos negativos (FN). La sensibilidad mide la capacidad del modelo para detectar correctamente los casos positivos.\nSpecificity (Especificidad): Es la proporción de verdaderos negativos (TN) que son identificados correctamente por el modelo en relación con el total de verdaderos negativos y falsos positivos (FP). La especificidad mide la capacidad del modelo para detectar correctamente los casos negativos.\nPrecision (Precisión): Es la proporción de verdaderos positivos (TP) que son identificados correctamente por el modelo en relación con el total de verdaderos positivos y falsos positivos (FP). La precisión mide la capacidad del modelo para no identificar falsamente un caso como positivo.\nRecall (Recuperación): Es la proporción de verdaderos positivos (TP) que son identificados correctamente por el modelo en relación con el total de verdaderos positivos y falsos negativos (FN). El recall mide la capacidad del modelo para identificar todos los casos positivos.\nF-measure (Puntuación F): Es una métrica que combina la precisión y el recall en una sola puntuación. El valor de la F-measure oscila entre 0 y 1, siendo 1 el valor óptimo.\nKappa (Coeficiente Kappa): Es una medida de concordancia que compara la cantidad de acuerdos observados entre el modelo y las observaciones reales con la cantidad de acuerdos que se esperarían por casualidad. Un valor de kappa cercano a 1 indica una concordancia casi perfecta entre el modelo y las observaciones reales.\nMatthews Correlation Coefficient (Coeficiente de Correlación de Matthews): Es una medida que se utiliza para evaluar la calidad de la clasificación binaria. El coeficiente de correlación de Matthews oscila entre -1 y 1, siendo 1 el valor óptimo. Un valor cercano a 1 indica una clasificación perfecta, mientras que un valor cercano a -1 indica una clasificación completamente incorrecta."
  },
  {
    "objectID": "archive/2023-11-icfes/2-taller-icfes.html#calcular-las-métricas",
    "href": "archive/2023-11-icfes/2-taller-icfes.html#calcular-las-métricas",
    "title": "Taller Introducción a Machine Learning en el 14° Seminario Internacional de Investigación sobre la Calidad de la Educación - SiiCE",
    "section": "Calcular las métricas",
    "text": "Calcular las métricas\n\nconf_mat(resultados_prueba, truth = puntaje,\n         estimate = .pred_class)\n\n          Truth\nPrediction    0    1\n         0 2522  990\n         1  430  768\n\naccuracy(resultados_prueba, truth = puntaje,\n         estimate = .pred_class)\n\n# A tibble: 1 × 3\n  .metric  .estimator .estimate\n  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;\n1 accuracy binary         0.699\n\nsens(resultados_prueba, truth = puntaje,\n    estimate = .pred_class, \n    event_level = \"second\")\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 sens    binary         0.437\n\nspec(resultados_prueba, truth = puntaje,\n    estimate = .pred_class, \n    event_level = \"second\")\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 spec    binary         0.854\n\nprecision(resultados_prueba, truth = puntaje,\n    estimate = .pred_class,\n    event_level = \"second\")\n\n# A tibble: 1 × 3\n  .metric   .estimator .estimate\n  &lt;chr&gt;     &lt;chr&gt;          &lt;dbl&gt;\n1 precision binary         0.641\n\nrecall(resultados_prueba, truth = puntaje,\n    estimate = .pred_class,\n    event_level = \"second\")\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 recall  binary         0.437\n\nkap(resultados_prueba, truth = puntaje,\n    estimate = .pred_class,\n    event_level = \"second\")\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 kap     binary         0.311\n\n\nTambién se pueden calcular con menos repetición del código\n\ncustom_metrics &lt;- metric_set(accuracy, sens, spec, precision, recall, f_meas, kap, mcc)\n\ncustom_metrics(resultados_prueba,\n  truth = puntaje,\n  estimate = .pred_class,\n  event_level = \"second\"\n)\n\n# A tibble: 8 × 3\n  .metric   .estimator .estimate\n  &lt;chr&gt;     &lt;chr&gt;          &lt;dbl&gt;\n1 accuracy  binary         0.699\n2 sens      binary         0.437\n3 spec      binary         0.854\n4 precision binary         0.641\n5 recall    binary         0.437\n6 f_meas    binary         0.520\n7 kap       binary         0.311\n8 mcc       binary         0.323\n\n\nY las podemos guardar en una tabla.\n\nlm_metrics &lt;- custom_metrics(resultados_prueba,\n  truth = puntaje,\n  estimate = .pred_class,\n  event_level = \"second\"\n) |&gt;\n  mutate(model = \"lm\")"
  },
  {
    "objectID": "archive/2023-11-icfes/2-taller-icfes.html#área-bajo-la-curva",
    "href": "archive/2023-11-icfes/2-taller-icfes.html#área-bajo-la-curva",
    "title": "Taller Introducción a Machine Learning en el 14° Seminario Internacional de Investigación sobre la Calidad de la Educación - SiiCE",
    "section": "Área bajo la curva",
    "text": "Área bajo la curva\nLa función roc_auc() se utiliza para calcular el área bajo la curva (AUC) de la curva (ROC).\nLa curva ROC es una representación gráfica de la sensibilidad frente a la especificidad para un sistema clasificador binario.\nEl AUC es una métrica de rendimiento para los modelos de clasificación. Su valor varía de 0 a 1, donde un valor de 1 indica que el modelo tiene una capacidad de clasificación perfecta, mientras que un valor de 0.5 indica que el modelo no tiene capacidad de clasificación, es decir, clasifica al azar.\nEn general, un modelo se considera bueno si el AUC es 0.7 o superior. Sin embargo, esto puede variar dependiendo del contexto y del problema específico que se esté abordando.\n\nprediccion_auc &lt;- predict(lm_results, entrenamiento, type = \"prob\")\n\nresultados_prueba_auc &lt;- cbind(prediccion_auc, datos_entrenamiento) |&gt;\n  tibble()\n\nroc_auc(resultados_prueba_auc,\n  truth = puntaje,\n  `.pred_1`,\n  event_level = \"second\"\n)\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 roc_auc binary         0.728\n\n\nY se puede crear una gráfica\n\nroc_curve(resultados_prueba_auc,\nevent_level = \"second\",\n  truth = puntaje,\n  .pred_1\n) |&gt; autoplot()\n\n\n\n\nAhora, ¿cómo podemos mejorar el modelo?"
  },
  {
    "objectID": "archive/2023-11-icfes/2-taller-icfes.html#árboles-de-decisión",
    "href": "archive/2023-11-icfes/2-taller-icfes.html#árboles-de-decisión",
    "title": "Taller Introducción a Machine Learning en el 14° Seminario Internacional de Investigación sobre la Calidad de la Educación - SiiCE",
    "section": "Árboles de decisión",
    "text": "Árboles de decisión\nLos árboles de decisión son un tipo de modelo de aprendizaje automático que se utiliza para resolver problemas de clasificación y regresión. El objetivo es tomar decisiones basadas en preguntas y respuestas que se hacen a los datos para llegar a una conclusión o predicción. En un árbol de decisión, cada punto o “nodo” representa una característica de los datos que estamos estudiando. Cada “rama” del árbol muestra una respuesta posible a esa característica."
  },
  {
    "objectID": "archive/2023-11-icfes/2-taller-icfes.html#arbusto",
    "href": "archive/2023-11-icfes/2-taller-icfes.html#arbusto",
    "title": "Taller Introducción a Machine Learning en el 14° Seminario Internacional de Investigación sobre la Calidad de la Educación - SiiCE",
    "section": "Arbusto",
    "text": "Arbusto\nPara estimar un árbol pequeño, hay que seguir los mismos pasos que para estimar un modelo de regresión logística, como hicimos anteriormente.\n\nEspecificación del modelo: Se especifica un modelo de árbol de decisión con un parámetro de complejidad de 0. Se utiliza el paquete rpart y se establece el modo en classification.\n\n\ntree_spec &lt;- \n  decision_tree(cost_complexity= 0.01) |&gt; \n  set_engine(\"rpart\") |&gt; \n  set_mode(\"classification\") \n\n\nAjuste del modelo: Se ajusta el modelo de árbol de decisión utilizando la fórmula puntaje ~ ., lo que significa que se está modelando puntaje como una función de todas las otras variables en el dataframe taller_icfes.\n\n\ntree_results &lt;- tree_spec |&gt;\n    fit(puntaje ~ ., data = taller_icfes)\n\n\nVisualización del árbol de decisión: Se extrae el modelo ajustado del resultado del ajuste y se visualiza utilizando la función tree_diagram del paquete treemisc.\n\n\ncart_tree_fit &lt;- tree_results$fit\n\ntreemisc::tree_diagram(cart_tree_fit, roundint = FALSE)\n\n\n\n\n¿Cómo se decide por dónde cortar los datos en un árbol de decisión? ver esto"
  },
  {
    "objectID": "archive/2023-11-icfes/2-taller-icfes.html#árboles-de-clasificación-y-regresión-cart",
    "href": "archive/2023-11-icfes/2-taller-icfes.html#árboles-de-clasificación-y-regresión-cart",
    "title": "Taller Introducción a Machine Learning en el 14° Seminario Internacional de Investigación sobre la Calidad de la Educación - SiiCE",
    "section": "Árboles de clasificación y regresión (CART)",
    "text": "Árboles de clasificación y regresión (CART)\nAhora, que ya sabemos cómo se construye el árbol, utilicemos todos los datos.\nPaso 1. Especificar el modelo\n\ntree_spec &lt;- \n  decision_tree() |&gt; \n  set_mode(\"classification\") |&gt; \n  set_engine(\"rpart\")\n\nPaso 2. Estimar el modelo\n\ntree_results &lt;- tree_spec |&gt;\n  fit(puntaje ~ ., data = datos_entrenamiento)\n\nAhora, vamos a pasar a evaluar el model.\n\nentrenamiento &lt;- datos_entrenamiento %&gt;%\n  select(-puntaje)\n\nprediccion_tree &lt;- predict(tree_results, entrenamiento)\n\nresultados_prueba_tree &lt;- cbind(prediccion_tree, datos_entrenamiento) |&gt;\n  tibble()\n\nY calculemos las métricas\n\ntree_metrics &lt;- custom_metrics(resultados_prueba_tree,\n  truth = puntaje,\n  estimate = .pred_class, \n  event_level= \"second\"\n) |&gt;\n  mutate(model = \"tree\")\n\nrbind(tree_metrics, lm_metrics) |&gt;\n  pivot_wider(names_from = model, values_from = .estimate)\n\n# A tibble: 8 × 4\n  .metric   .estimator  tree    lm\n  &lt;chr&gt;     &lt;chr&gt;      &lt;dbl&gt; &lt;dbl&gt;\n1 accuracy  binary     0.678 0.699\n2 sens      binary     0.296 0.437\n3 spec      binary     0.906 0.854\n4 precision binary     0.652 0.641\n5 recall    binary     0.296 0.437\n6 f_meas    binary     0.408 0.520\n7 kap       binary     0.227 0.311\n8 mcc       binary     0.261 0.323"
  },
  {
    "objectID": "archive/2023-11-icfes/2-taller-icfes.html#cart-con-hiperparámetros",
    "href": "archive/2023-11-icfes/2-taller-icfes.html#cart-con-hiperparámetros",
    "title": "Taller Introducción a Machine Learning en el 14° Seminario Internacional de Investigación sobre la Calidad de la Educación - SiiCE",
    "section": "CART con hiperparámetros",
    "text": "CART con hiperparámetros\nLos hiperparámetros son valores específicos para los modelos que se pueden ajustar y que permiten controlar el proceso de entrenamiento de un modelo.\n\ntree_spec &lt;- \n  decision_tree(min_n = 5, cost_complexity = 0.001) |&gt; \n  set_mode(\"classification\") |&gt; \n  set_engine(\"rpart\")\n\nEn este caso, se están indicando dos hiperparámetros para el modelo de árbol de decisión:\n\nmin_n: Es el número mínimo de observaciones que se requieren para dividir un nodo en un árbol de decisión. Un valor más alto de min_n implica que el árbol será menos profundo, ya que se requerirán más muestras para realizar una división en cada nodo.\ncost_complexity: Es un parámetro de regularización. Es una medida de la penalización que se aplica al árbol en función de su complejidad. Un valor más alto de cost_complexity implica una penalización más fuerte en la complejidad del árbol, lo que lleva a un árbol más pequeño y menos profundo.\n\nAhora, a estimar el modelo\n\ntree2_results &lt;- tree_spec |&gt;\n    fit(puntaje ~ ., data = datos_entrenamiento)\n\nPodemos obtener las predicciones\n\ntree2_predicciones &lt;- predict(tree2_results, entrenamiento)\n\nresultados_prueba_tree2 &lt;- cbind(tree2_predicciones, datos_entrenamiento) |&gt;\n  tibble()\n\ntree2_metrics &lt;- custom_metrics(resultados_prueba_tree2,\n  truth = puntaje,\n  estimate = .pred_class,\n  event_level = \"second\"\n) |&gt;\n  mutate(model = \"tree2\")\n\nY finalmente, podemos comparar los modelos\n\nrbind(tree2_metrics, tree_metrics, lm_metrics) |&gt;\n  pivot_wider(names_from = model, values_from = .estimate)\n\n# A tibble: 8 × 5\n  .metric   .estimator tree2  tree    lm\n  &lt;chr&gt;     &lt;chr&gt;      &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 accuracy  binary     0.773 0.678 0.699\n2 sens      binary     0.572 0.296 0.437\n3 spec      binary     0.892 0.906 0.854\n4 precision binary     0.760 0.652 0.641\n5 recall    binary     0.572 0.296 0.437\n6 f_meas    binary     0.653 0.408 0.520\n7 kap       binary     0.489 0.227 0.311\n8 mcc       binary     0.500 0.261 0.323"
  },
  {
    "objectID": "archive/2023-11-icfes/2-taller-icfes.html#pero-todo-esto-pasa-en-los-datos-de-prueba",
    "href": "archive/2023-11-icfes/2-taller-icfes.html#pero-todo-esto-pasa-en-los-datos-de-prueba",
    "title": "Taller Introducción a Machine Learning en el 14° Seminario Internacional de Investigación sobre la Calidad de la Educación - SiiCE",
    "section": "¡Pero todo esto pasa en los datos de prueba!",
    "text": "¡Pero todo esto pasa en los datos de prueba!"
  },
  {
    "objectID": "archive/2023-11-icfes/2-taller-icfes.html#por-qué-es-malo",
    "href": "archive/2023-11-icfes/2-taller-icfes.html#por-qué-es-malo",
    "title": "Taller Introducción a Machine Learning en el 14° Seminario Internacional de Investigación sobre la Calidad de la Educación - SiiCE",
    "section": "¿Por qué es malo?",
    "text": "¿Por qué es malo?\nUno puede crear un modelo que tenga cerro error en los datos de prueba. Pero, ¿cómo sabemos que el modelo es bueno?\n\n# Seleccionar el valor del puntaje\ndatos_prueba2_out &lt;- \n  datos_prueba |&gt; \n    select(puntaje) \n\n# Utilizar los datos de prueba para predecir el puntaje utilizando el modelo de regresión logística  \nlm_predicciones &lt;- cbind(predict(lm_results, datos_prueba), datos_prueba2_out)|&gt; mutate(model=\"lm\")\n\n# Utilizar los datos de prueba para predecir el puntaje utilizando el modelo de árbol de decisión\ntree_predicciones &lt;- cbind(predict(tree_results, datos_prueba), datos_prueba2_out)|&gt; mutate(model=\"tree\")\n\n\n# Utilizar los datos de prueba para predecir el puntaje utilizando el modelo de árbol de decisión con hiperparámetros\ntree2_predicciones &lt;- cbind(predict(tree2_results, datos_prueba), datos_prueba2_out) |&gt;  mutate(model=\"tree2\")\n\n# Unir los resultados\nall_models &lt;- \nrbind(lm_predicciones, tree_predicciones, tree2_predicciones) \n\n# all_models\n\nFinalmente, podemos comparar las métricas de los modelos.\n\nall_models2 &lt;- all_models |&gt; \n  group_split(model) %&gt;%\n   setNames(unique(all_models$model)) %&gt;%\n  map_dfr(., ~custom_metrics(.x,\n               truth = puntaje,\n               estimate = .pred_class), .id = \"names\")\n\nall_models2 |&gt; \n  pivot_wider(names_from = names, values_from = .estimate)\n\n# A tibble: 8 × 5\n  .metric   .estimator    lm  tree tree2\n  &lt;chr&gt;     &lt;chr&gt;      &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 accuracy  binary     0.703 0.686 0.681\n2 sens      binary     0.869 0.926 0.827\n3 spec      binary     0.425 0.284 0.436\n4 precision binary     0.717 0.685 0.711\n5 recall    binary     0.869 0.926 0.827\n6 f_meas    binary     0.786 0.787 0.765\n7 kap       binary     0.316 0.238 0.279\n8 mcc       binary     0.332 0.282 0.286"
  },
  {
    "objectID": "archive/2023-11-icfes/2-taller-icfes.html#cómo-vamos-a-elegir-el-mejor-modelo-si-solo-podemos-evaluar-un-modelo-en-los-datos-de-prueba",
    "href": "archive/2023-11-icfes/2-taller-icfes.html#cómo-vamos-a-elegir-el-mejor-modelo-si-solo-podemos-evaluar-un-modelo-en-los-datos-de-prueba",
    "title": "Taller Introducción a Machine Learning en el 14° Seminario Internacional de Investigación sobre la Calidad de la Educación - SiiCE",
    "section": "¿Cómo vamos a elegir el mejor modelo si solo podemos evaluar un modelo en los datos de prueba?",
    "text": "¿Cómo vamos a elegir el mejor modelo si solo podemos evaluar un modelo en los datos de prueba?\n\nSegunda idea: dividir los datos de entrenamiento en dos grupos, uno para entrenar y otro para validar, de tal manera que podamos estimar el error del modelo en los datos de prueba."
  },
  {
    "objectID": "archive/2023-11-icfes/2-taller-icfes.html#validación-cruzada",
    "href": "archive/2023-11-icfes/2-taller-icfes.html#validación-cruzada",
    "title": "Taller Introducción a Machine Learning en el 14° Seminario Internacional de Investigación sobre la Calidad de la Educación - SiiCE",
    "section": "Validación Cruzada",
    "text": "Validación Cruzada\nSupongamos que estamos trabajando en un problema de clasificación y disponemos de un conjunto de datos con 1000 observaciones. Queremos evaluar el rendimiento de un modelo de regresión logística utilizando la validación cruzada k-fold.\nPaso a paso del proceso de k-fold cross-validation:\nDividir el conjunto de datos: Primero, dividimos el conjunto de datos en k subconjuntos (folds) de igual tamaño. En este ejemplo, elegimos k=10, lo que significa que dividimos el conjunto de datos en 10 subconjuntos de 100 registros cada uno.\nEntrenar y evaluar el modelo: Luego, realizamos lo siguiente para cada uno de los k subconjuntos:\n\nTomamos un subconjunto como el conjunto de prueba (validación) y los k-1 subconjuntos restantes como el conjunto de entrenamiento. Por ejemplo, en la primera iteración, usamos el primer subconjunto como conjunto de prueba y los subconjuntos del 2 al 10 como conjunto de entrenamiento.\nEntrenamos el modelo de regresión logística utilizando el conjunto de entrenamiento.\nEvaluamos el rendimiento del modelo en el conjunto de prueba utilizando una métrica adecuada, como la precisión, la exhaustividad o el F1-score. Anotamos el resultado de la métrica para esta iteración.\n\nPromediar los resultados: Después de completar las k iteraciones, calculamos la media de los resultados de la métrica para todas las iteraciones. Esta media nos proporciona una estimación más robusta del rendimiento del modelo, ya que el modelo ha sido evaluado en diferentes subconjuntos del conjunto de datos.\nMás información aquí y aquí"
  },
  {
    "objectID": "archive/2023-11-icfes/2-taller-icfes.html#cart-con-hiperparametros-y-validación-cruzada",
    "href": "archive/2023-11-icfes/2-taller-icfes.html#cart-con-hiperparametros-y-validación-cruzada",
    "title": "Taller Introducción a Machine Learning en el 14° Seminario Internacional de Investigación sobre la Calidad de la Educación - SiiCE",
    "section": "CART con hiperparametros y validación cruzada",
    "text": "CART con hiperparametros y validación cruzada\nLo primero que vamos a necesitar es crear un objecto en R que contenga los datos organizados de tal manera que podamos implementar la validación cruzada. Para esto, vamos a utilizar la función vfold_cv() del paquete rsample.\n\ncrossvalidation &lt;-\n  vfold_cv(datos_entrenamiento, \n           v = 5,  # número de cajas\n           strata = \"puntaje\")\n\nAhora, vamos a especificar el modelo. Cuando se especifica un modelo de árbol de decisión, vamos a indicar que queremos que se prueben diferentes valores de los hiperparámetros “min_n” y “cost_complexity”. Para eso, vamos a utilizar el paquete tune.\n\ntree_spec &lt;- \n  decision_tree(\n    cost_complexity = tune(), \n    tree_depth = tune(),\n    min_n = tune()\n  ) |&gt; \n  set_mode(\"classification\") |&gt; \n  set_engine(\"rpart\")\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nCost_complexity: Cost_complexity es un parámetro de regularización. Es una medida de la penalización que se aplica al árbol en función de su complejidad. Un valor más alto de cost_complexity implica una penalización más fuerte en la complejidad del árbol, lo que lleva a un árbol más pequeño y menos profundo. La idea es encontrar un valor óptimo de cost_complexity que equilibre la precisión y la complejidad del árbol, reduciendo tanto el sesgo como la varianza.\nTree_depth (profundidad del árbol): Tree_depth se refiere a la longitud máxima del camino más largo desde la raíz hasta una hoja en un árbol de decisión. Un árbol más profundo es más complejo y puede capturar relaciones más complicadas en los datos. Sin embargo, un árbol demasiado profundo también puede ser propenso al sobreajuste, ya que puede adaptarse demasiado a las peculiaridades de los datos de entrenamiento.\nmin_n (mínimo número de muestras para dividir un nodo): Min_n es un parámetro que controla el número mínimo de datos requeridas para dividir un nodo en un árbol de decisión. Un valor más alto de min_n implica que el árbol será menos profundo, ya que se requerirán más muestras para realizar una división en cada nodo. Un valor más bajo de min_n permite que el árbol se divida más fácilmente y, por lo tanto, puede resultar en un árbol más complejo y profundo.\n\n\n\nAhora, vamos a especificar la rejilla de búsqueda. La rejilla de búsqueda es una tabla que contiene los valores que se van a probar para cada combinación de hiperparámetros.\n\ntree_grid &lt;- grid_regular(\n    cost_complexity(range = c(-10L, -1L)), \n    tree_depth (range = c(4L, 7L)), \n    min_n(range = c(10L, 30L)))\n\nEl siguiente paso es estimar el desempeño de los modelos en los datos de validación, utilizando los modelos creados con las diferentes combinaciones de hiperparámetros. Para esto, vamos a utilizar la función tune_grid() del paquete tune.\n\ndoParallel::registerDoParallel()\n\nset.seed(345)\ntree_rs &lt;-\n  tune_grid(\n    tree_spec,\n    puntaje ~ .,\n    resamples = crossvalidation,\n    grid = tree_grid,\n    metrics = metric_set(accuracy, roc_auc, sensitivity, specificity)\n  )\n\ndoParallel::stopImplicitCluster()\n\n\n\n\n\n\n\nTip\n\n\n\n\n\ndoParallel es un excelente paquete creado para facilitar la programación paralela en R. Utilizar R en “paralelo” permite aprovechar la potencia de los computadores para ahorrar tiempo.\n\n\n\nEsto nos va a dar una tabla con los resultados de cada modelo, y podemos pedir que nos muestre la combinación de hiperparámetros que tuvo el mejor desempeño.\n\nshow_best(tree_rs)\n\nWarning: No value of `metric` was given; metric 'accuracy' will be used.\n\n\n# A tibble: 5 × 9\n  cost_complexity tree_depth min_n .metric  .estimator  mean     n std_err\n            &lt;dbl&gt;      &lt;int&gt; &lt;int&gt; &lt;chr&gt;    &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt;\n1    0.0000000001          4    10 accuracy binary     0.673     5 0.00434\n2    0.00000316            4    10 accuracy binary     0.673     5 0.00434\n3    0.0000000001          4    20 accuracy binary     0.673     5 0.00434\n4    0.00000316            4    20 accuracy binary     0.673     5 0.00434\n5    0.0000000001          4    30 accuracy binary     0.673     5 0.00434\n# ℹ 1 more variable: .config &lt;chr&gt;\n\n\nY podemos visualizar los resultados\n\nautoplot(tree_rs)\n\n\n\n\nFinalmente, podemos seleccionar el mejor modelo y estimarlo con los datos de entrenamiento.\n\nsimpler_tree &lt;- select_best(tree_rs, min_n, metric = \"accuracy\")\n\nfinal_tree &lt;- finalize_model(tree_spec, simpler_tree)\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nLa función finalize_model permite actualizar la especificación del modelo con los hiperparámetros seleccionados.\n\n\n\nAhora, volvemos a hacer lo que hemos estado haciendo: estimar el modelo con los datos de entrenamiento.\n\nfinal_fit &lt;- fit(final_tree, puntaje ~ ., datos_entrenamiento)\n\nYa sabemos cómo evaluar el modelo, así que vamos a hacerlo. Para eso, vamos a utilizar la función last_fit(), que va a hacer un montón de trabajo por nosotros. Esta función va a estimar el modelo con los datos de entrenamiento y va a calcular las métricas de evaluación en los datos de entrenamiento y prueba.\n\nfinal_cart &lt;- last_fit(final_tree, puntaje ~ ., datos_divididos,\n  metrics = metric_set(accuracy, roc_auc, sensitivity, specificity),\n  control = control_grid(event_level = \"second\")\n)\n\nWarning: Unknown or uninitialised column: `.extracts`.\n\n\nY podemos recolectar las métricas\n\ncollect_metrics(final_cart)\n\n# A tibble: 4 × 4\n  .metric     .estimator .estimate .config             \n  &lt;chr&gt;       &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               \n1 accuracy    binary         0.683 Preprocessor1_Model1\n2 sensitivity binary         0.332 Preprocessor1_Model1\n3 specificity binary         0.892 Preprocessor1_Model1\n4 roc_auc     binary         0.632 Preprocessor1_Model1\n\n\n¿Y podemos visualizar el árbol?\n\nfinal_cart &lt;- last_fit(final_tree, puntaje ~ ., datos_divididos,\n  metrics = metric_set(accuracy, roc_auc, sensitivity, specificity))\n\ncart_trained &lt;- \n  final_cart  |&gt; extract_fit_parsnip()\n\ncart_tree_fit &lt;- cart_trained$fit\n\ntreemisc::tree_diagram(cart_tree_fit, roundint=FALSE)\n\nWarning: labs do not fit even at cex 0.15, there may be some overplotting\n\n\n\n\n\n\nExtra idea: los árboles son muy buenos para aprender la distribuación de los datos de prueba, pero a veces, tienden a sobre especializarse en los datos en los que son entrenados. Una forma de solucionar esto, es hacer muchos árboles, que podamos después promediar."
  },
  {
    "objectID": "archive/2023-11-icfes/2-taller-icfes.html#random-forest",
    "href": "archive/2023-11-icfes/2-taller-icfes.html#random-forest",
    "title": "Taller Introducción a Machine Learning en el 14° Seminario Internacional de Investigación sobre la Calidad de la Educación - SiiCE",
    "section": "Random Forest",
    "text": "Random Forest\nYa sabemos por qué es Forest, pero ¿por qué es random?\n\nNúmero de predictores que se usan para cada árbol (mtry)\nNúmero de observaciones por árbol\n\n\nRandom Forest\nLos pasos son los mismo, solo cambia la especificación del modelo.\n\nrf_spec &lt;- \n  rand_forest()  |&gt; \n  set_mode(\"classification\") |&gt; \n  set_engine(\"ranger\", importance = \"permutation\")\n\nHay algunos métodos para tratar de identificar cuáles fueron las variables más relevantes en el momento de hacer las mejores predicciones.\n\nrf_results &lt;- rf_spec |&gt; \nfit(puntaje ~ ., data = datos_entrenamiento)\n\nlibrary(vip)\nimportance_plot_rf &lt;- \n  rf_results |&gt; \n  vip() +\n  ggtitle(\"Random Forest\") +\n  theme_minimal() +\n  geom_bar(stat=\"identity\", \n  color=\"green\", fill=\"green\", alpha=0.2)\n\nAhora, a recolectar métricas.\n\nrf_predicciones &lt;- predict(rf_results, entrenamiento)\n\nresultados_rf &lt;- cbind(rf_predicciones,datos_entrenamiento) |&gt; \n  tibble()\n\nrf_metrics &lt;- custom_metrics(resultados_rf,\n               truth = puntaje,\n               estimate = .pred_class,\n               event_level= \"second\") |&gt;\n  mutate(model=\"rf\")\n\nY a comparar los modelos\n\nrbind(rf_metrics, tree2_metrics, tree_metrics, lm_metrics) |&gt; \n  pivot_wider(names_from = model, values_from = .estimate)\n\n# A tibble: 8 × 6\n  .metric   .estimator    rf tree2  tree    lm\n  &lt;chr&gt;     &lt;chr&gt;      &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 accuracy  binary     0.868 0.773 0.678 0.699\n2 sens      binary     0.711 0.572 0.296 0.437\n3 spec      binary     0.962 0.892 0.906 0.854\n4 precision binary     0.918 0.760 0.652 0.641\n5 recall    binary     0.711 0.572 0.296 0.437\n6 f_meas    binary     0.801 0.653 0.408 0.520\n7 kap       binary     0.705 0.489 0.227 0.311\n8 mcc       binary     0.718 0.500 0.261 0.323\n\n\nLa ley es que los datos de prueba se utilizan solo una vez, pero los hemos utilizado muchas veces. Veamos por última vez, cómo se comportaron los modelos en la base de prueba.\n\nrf_predicciones &lt;- cbind(predict(rf_results, datos_prueba), datos_prueba2_out) |&gt;  mutate(model=\"rf\")\n\nall_models &lt;- \nrbind(lm_predicciones, rf_predicciones,tree_predicciones, tree2_predicciones) \n\n\nall_models2 &lt;- all_models |&gt; \n  group_split(model) %&gt;%\n   setNames(unique(all_models$model)) %&gt;%\n  map_dfr(., ~custom_metrics(.x,\n               truth = puntaje,\n               estimate = .pred_class,\n               event_level= \"second\"), .id = \"names\")\nall_models2 |&gt; \n  pivot_wider(names_from = names, values_from = .estimate)\n\n# A tibble: 8 × 6\n  .metric   .estimator    lm    rf  tree tree2\n  &lt;chr&gt;     &lt;chr&gt;      &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 accuracy  binary     0.703 0.684 0.686 0.681\n2 sens      binary     0.425 0.386 0.284 0.436\n3 spec      binary     0.869 0.861 0.926 0.827\n4 precision binary     0.658 0.623 0.694 0.6  \n5 recall    binary     0.425 0.386 0.284 0.436\n6 f_meas    binary     0.517 0.477 0.403 0.505\n7 kap       binary     0.316 0.268 0.238 0.279\n8 mcc       binary     0.332 0.283 0.282 0.286"
  },
  {
    "objectID": "archive/2023-11-icfes/2-taller-icfes.html#sesgo-y-varianza",
    "href": "archive/2023-11-icfes/2-taller-icfes.html#sesgo-y-varianza",
    "title": "Taller Introducción a Machine Learning en el 14° Seminario Internacional de Investigación sobre la Calidad de la Educación - SiiCE",
    "section": "Sesgo y varianza",
    "text": "Sesgo y varianza\nEstos dos conceptos son cruciales para entender el equilibrio entre la complejidad del modelo y su capacidad para generalizar a nuevos datos.\nSesgo (Bias): a. Definición: El sesgo es la diferencia entre la predicción promedio de nuestro modelo y el valor verdadero que intentamos predecir.El sesgo, en términos estadísticos, se refiere a la diferencia sistemática entre la esperanza (o promedio) de las estimaciones que produce un estimador y el valor real del parámetro que se desea estimar. Un modelo con alta varianza es muy sensible a pequeñas variaciones en los datos de entrenamiento, lo que puede resultar en un sobreajuste. Es decir, el modelo se ajusta muy bien a los datos de entrenamiento, pero tiene un rendimiento deficiente en datos no vistos o de prueba.\n\nEjemplo: Un modelo de regresión lineal simple podría tener un alto sesgo si los datos reales tienen una relación no lineal.\nImplicaciones: Un modelo con alto sesgo es demasiado simple y no captura la estructura subyacente de los datos. Esto conduce a un bajo rendimiento en el conjunto de entrenamiento y prueba.\n\nVarianza (Variance): a. Definición: La varianza es la cantidad de variabilidad en las predicciones del modelo para un dato. b. Ejemplo: Un modelo de árbol de decisión muy profundo podría tener alta varianza, ya que es muy sensible a pequeñas variaciones en los datos de entrenamiento. c. Implicaciones: Un modelo con alta varianza tiende a sobreajustarse a los datos de entrenamiento, lo que resulta en un buen rendimiento en el conjunto de entrenamiento pero un bajo rendimiento en el conjunto de prueba.\nEl objetivo en Machine Learning es equilibrar el sesgo y la varianza para minimizar el error de predicción general en el modelo a. Objetivo: Encontrar un equilibrio entre sesgo y varianza que minimice el error total de predicción. b. Estrategias: Seleccionar un modelo con la complejidad adecuada, usar técnicas de regularización, y validar el modelo con conjuntos de datos de entrenamiento y prueba separados.\n\nTercera idea: en Machine Learning todo se trata de encontrar el mejor balance entre el sesgo y la varianza del modelo."
  },
  {
    "objectID": "archive/2023-11-icfes/2-taller-icfes.html#formas-de-disminur-el-sesgo",
    "href": "archive/2023-11-icfes/2-taller-icfes.html#formas-de-disminur-el-sesgo",
    "title": "Taller Introducción a Machine Learning en el 14° Seminario Internacional de Investigación sobre la Calidad de la Educación - SiiCE",
    "section": "Formas de disminur el sesgo",
    "text": "Formas de disminur el sesgo\nAumentar la complejidad del modelo: Un modelo más complejo puede capturar mejor la estructura subyacente de los datos. Por ejemplo, en lugar de utilizar una regresión lineal simple, podrías probar una regresión polinomial o un modelo de árbol de decisión.\nAñadir más variables: A veces, el sesgo puede ser el resultado de no tener en cuenta variables importantes que influyen en la variable objetivo. Añadir más variables relevantes puede ayudar a reducir el sesgo del modelo.\nUtilizar técnicas de “ingeniería de predictores”: Transformar o combinar las variables existentes para crear nuevas características puede ayudar a capturar mejor la relación entre las variables de entrada y salida. Por ejemplo, si estás trabajando en un problema de predicción de precios de viviendas, podrías crear una nueva característica que represente la relación entre el tamaño de la casa y el número de habitaciones.\nAumentar el tamaño del conjunto de datos: Si tu conjunto de datos es pequeño o no es representativo de la población general, es posible que el modelo tenga un sesgo alto. Aumentar el tamaño del conjunto de datos y asegurarte de que es representativo puede ayudar a reducir el sesgo.\nUtilizar ensembles de modelos: Combinar varios modelos en un ensemble puede ayudar a reducir el sesgo, ya que cada modelo puede capturar diferentes aspectos de la relación entre las variables de entrada y salida. Por ejemplo, puedes utilizar métodos de ensemble como Bagging, Boosting o Stacking."
  },
  {
    "objectID": "archive/2023-11-icfes/2-taller-icfes.html#técnicas-para-reducir-la-varianza",
    "href": "archive/2023-11-icfes/2-taller-icfes.html#técnicas-para-reducir-la-varianza",
    "title": "Taller Introducción a Machine Learning en el 14° Seminario Internacional de Investigación sobre la Calidad de la Educación - SiiCE",
    "section": "Técnicas para reducir la varianza",
    "text": "Técnicas para reducir la varianza\nReducir la complejidad del modelo: Un modelo más simple tiende a tener una menor varianza y es menos propenso al sobreajuste. Por ejemplo, podrías limitar la profundidad de un árbol de decisión.\nUtilizar regularización: La regularización es una técnica que añade una penalización a los coeficientes del modelo para evitar que se ajusten demasiado a los datos de entrenamiento.Por ejemplo, regularización L1 (Lasso) y L2 (Ridge).\nAumentar el tamaño del conjunto de datos: Si dispones de más datos, el modelo será menos sensible a pequeñas variaciones en los datos de entrenamiento y tendrá una menor varianza.\nEliminar características ruidosas: Si tu modelo incluye características que no están relacionadas con la variable objetivo o que contienen mucho ruido, estas pueden aumentar la varianza del modelo. Realizar un análisis de importancia de características y eliminar las características poco importantes puede ayudar a reducir la varianza.\nValidación cruzada (cross-validation): Utilizar la validación cruzada, como k-fold cross-validation, te permite evaluar el rendimiento del modelo en diferentes subconjuntos del conjunto de datos de entrenamiento. Esto puede ayudarte a identificar si el modelo está sobreajustando los datos y ajustar la complejidad del modelo en consecuencia.\nUtilizar diferentes modelos: Combinar varios modelos en un ensemble puede ayudar a reducir la varianza, ya que la variabilidad de cada modelo individual se promedia. Por ejemplo, puedes utilizar métodos de ensemble como Bagging (Bootstrap Aggregating) o Random Forest, que promedian las predicciones de múltiples árboles de decisión entrenados en subconjuntos aleatorios de los datos."
  },
  {
    "objectID": "archive/2023-10-Unal/index.html",
    "href": "archive/2023-10-Unal/index.html",
    "title": "Taller en la Universidad Nacional",
    "section": "",
    "text": "Este taller se llevará a cabo en la Universidad Nacional de Colombia el día 30 de octubre. En esta página pueden encontrar las diapositivas y otra información relevante para el taller."
  },
  {
    "objectID": "archive/2023-10-Unal/index.html#organizadores",
    "href": "archive/2023-10-Unal/index.html#organizadores",
    "title": "Taller en la Universidad Nacional",
    "section": "Organizadores",
    "text": "Organizadores\nFrancisco Cardozo.\nKaren Forero. Universidad Nacional.\nRoberto Posada. Universidad Nacional."
  },
  {
    "objectID": "archive/2023-03-Uniandes/index.html",
    "href": "archive/2023-03-Uniandes/index.html",
    "title": "Bienvenidos",
    "section": "",
    "text": "Le damos la bienvenida a este taller que se llevará a cabo en la Universidad de los Andes los días 26 y 27 de marzo. En el taller nos enfocaremos en algunas de las técnicas de aprendizaje automático más utilizadas en la actualidad. En esta página, hemos compilado todos los materiales necesarios para cada sesión, incluidas las diapositivas. Esperamos que estos recursos diseñados especialmente para ustedes sean de su agrado.\nEn este taller vamos a trabajar sobre tres ideas principales:\n\nEstimar del error de generalización.\nSeparar el error entre sesgo y varianza.\nRegularización."
  },
  {
    "objectID": "archive/2023-03-Uniandes/index.html#pasos-previos-al-taller",
    "href": "archive/2023-03-Uniandes/index.html#pasos-previos-al-taller",
    "title": "Bienvenidos",
    "section": "Pasos Previos al Taller",
    "text": "Pasos Previos al Taller\nPara aprovechar al máximo este taller, es necesario completar las siguientes tareas antes de que inicie el evento:\n\nCreación de una cuenta en Posit Cloud: Si aún no tienes una, por favor, crea una cuenta gratuita en Posit Cloud.\n\nEsperamos que este taller sea una experiencia enriquecedora para todos. Si tienen preguntas o inquietudes previas al evento, no duden en contactarnos."
  },
  {
    "objectID": "archive/2023-03-Uniandes/index.html#agenda-del-workshop",
    "href": "archive/2023-03-Uniandes/index.html#agenda-del-workshop",
    "title": "Bienvenidos",
    "section": "Agenda del Workshop",
    "text": "Agenda del Workshop\n\nDía 1\n\nIntroducción a Machine Learning\nProcesamiento de datos\nRegresión logística\nÁrboles de decisión\n\n\n\nDía 2\n\nRandom Forest\nRegresión lineal\nRegularización\n\n\n\nOrganizadores\n\nFrancisco Cardozo (foc9@miami.edu)\nMaría Fernanda Reyes\nEric C. Brown"
  },
  {
    "objectID": "archive/2023-03-Uniandes/index.html#día-1-1",
    "href": "archive/2023-03-Uniandes/index.html#día-1-1",
    "title": "Bienvenidos",
    "section": "Día 1",
    "text": "Día 1\n\n\nIntroducción\n\n\nPreprocesamiento de datos\n\n\nRegresión logística\n\n\nÁrboles de decisión"
  },
  {
    "objectID": "archive/2023-03-Uniandes/index.html#día-2-1",
    "href": "archive/2023-03-Uniandes/index.html#día-2-1",
    "title": "Bienvenidos",
    "section": "Día 2",
    "text": "Día 2\n\n\nRandom Forest\n\n\nRegresión\n\n\nRegularización"
  },
  {
    "objectID": "archive/2023-03-Uniandes/6-regresion.html#sesgo-y-varianza",
    "href": "archive/2023-03-Uniandes/6-regresion.html#sesgo-y-varianza",
    "title": "6. Regresión",
    "section": "Sesgo y varianza",
    "text": "Sesgo y varianza\nEstos dos conceptos son cruciales para entender el equilibrio entre la complejidad del modelo y su capacidad para generalizar a nuevos datos.\nSesgo (Bias): a. Definición: El sesgo es la diferencia entre la predicción promedio de nuestro modelo y el valor verdadero que intentamos predecir.El sesgo, en términos estadísticos, se refiere a la diferencia sistemática entre la esperanza (o promedio) de las estimaciones que produce un estimador y el valor real del parámetro que se desea estimar. Un modelo con alta varianza es muy sensible a pequeñas variaciones en los datos de entrenamiento, lo que puede resultar en un sobreajuste. Es decir, el modelo se ajusta muy bien a los datos de entrenamiento, pero tiene un rendimiento deficiente en datos no vistos o de prueba.\n\nEjemplo: Un modelo de regresión lineal simple podría tener un alto sesgo si los datos reales tienen una relación no lineal.\nImplicaciones: Un modelo con alto sesgo es demasiado simple y no captura la estructura subyacente de los datos. Esto conduce a un bajo rendimiento en el conjunto de entrenamiento y prueba.\n\nVarianza (Variance): a. Definición: La varianza es la cantidad de variabilidad en las predicciones del modelo para un punto de datos dado. b. Ejemplo: Un modelo de árbol de decisión muy profundo podría tener alta varianza, ya que es muy sensible a pequeñas variaciones en los datos de entrenamiento. c. Implicaciones: Un modelo con alta varianza tiende a sobreajustarse a los datos de entrenamiento, lo que resulta en un buen rendimiento en el conjunto de entrenamiento pero un bajo rendimiento en el conjunto de prueba.\nEl objetivo en Machine Learning es equilibrar el sesgo y la varianza para minimizar el error de predicción general en el modelo\n\nObjetivo: Encontrar un equilibrio entre sesgo y varianza que minimice el error total de predicción.\nEstrategias: Seleccionar un modelo con la complejidad adecuada, usar técnicas de regularización, y validar el modelo con conjuntos de datos de entrenamiento y prueba separados.\n\nFormas de disminur el sesgo\nAumentar la complejidad del modelo: Un modelo más complejo puede capturar mejor la estructura subyacente de los datos. Por ejemplo, en lugar de utilizar una regresión lineal simple, podrías probar una regresión polinomial o un modelo de árbol de decisión.\nAñadir más variables: A veces, el sesgo puede ser el resultado de no tener en cuenta variables importantes que influyen en la variable objetivo. Añadir más variables relevantes puede ayudar a reducir el sesgo del modelo.\nUtilizar técnicas de “ingeniería de predictores”: Transformar o combinar las variables existentes para crear nuevas características puede ayudar a capturar mejor la relación entre las variables de entrada y salida. Por ejemplo, si estás trabajando en un problema de predicción de precios de viviendas, podrías crear una nueva característica que represente la relación entre el tamaño de la casa y el número de habitaciones.\nAumentar el tamaño del conjunto de datos: Si tu conjunto de datos es pequeño o no es representativo de la población general, es posible que el modelo tenga un sesgo alto. Aumentar el tamaño del conjunto de datos y asegurarte de que es representativo puede ayudar a reducir el sesgo.\nUtilizar ensembles de modelos: Combinar varios modelos en un ensemble puede ayudar a reducir el sesgo, ya que cada modelo puede capturar diferentes aspectos de la relación entre las variables de entrada y salida. Por ejemplo, puedes utilizar métodos de ensemble como Bagging, Boosting o Stacking."
  },
  {
    "objectID": "archive/2023-03-Uniandes/6-regresion.html#técnicas-para-reducir-la-varianza",
    "href": "archive/2023-03-Uniandes/6-regresion.html#técnicas-para-reducir-la-varianza",
    "title": "6. Regresión",
    "section": "Técnicas para reducir la varianza",
    "text": "Técnicas para reducir la varianza\nReducir la complejidad del modelo: Un modelo más simple tiende a tener una menor varianza y es menos propenso al sobreajuste. Por ejemplo, podrías limitar la profundidad de un árbol de decisión.\nUtilizar regularización: La regularización es una técnica que añade una penalización a los coeficientes del modelo para evitar que se ajusten demasiado a los datos de entrenamiento.Por ejemplo, regularización L1 (Lasso) y L2 (Ridge).\nAumentar el tamaño del conjunto de datos: Si dispones de más datos, el modelo será menos sensible a pequeñas variaciones en los datos de entrenamiento y tendrá una menor varianza.\nEliminar características ruidosas: Si tu modelo incluye características que no están relacionadas con la variable objetivo o que contienen mucho ruido, estas pueden aumentar la varianza del modelo. Realizar un análisis de importancia de características y eliminar las características poco importantes puede ayudar a reducir la varianza.\n\nValidación cruzada (cross-validation): Utilizar la validación cruzada, como k-fold cross-validation, te permite evaluar el rendimiento del modelo en diferentes subconjuntos del conjunto de datos de entrenamiento. Esto puede ayudarte a identificar si el modelo está sobreajustando los datos y ajustar la complejidad del modelo en consecuencia.\nUtilizar diferentes modelos: Combinar varios modelos en un ensemble puede ayudar a reducir la varianza, ya que la variabilidad de cada modelo individual se promedia. Por ejemplo, puedes utilizar métodos de ensemble como Bagging (Bootstrap Aggregating) o Random Forest, que promedian las predicciones de múltiples árboles de decisión entrenados en subconjuntos aleatorios de los datos.\n\n\n\nMachine Learning"
  },
  {
    "objectID": "archive/2023-03-Uniandes/4-arboles.html#árboles-de-decisión",
    "href": "archive/2023-03-Uniandes/4-arboles.html#árboles-de-decisión",
    "title": "4. Árboles de decisión",
    "section": "Árboles de decisión",
    "text": "Árboles de decisión\n(mejorar esto) El objetivo es tomar una serie de decisiones, basadas en las respuestas a cada pregunta, para llegar a una conclusión o predicción final. Cada nodo del árbol representa una característica de los datos que se están analizando y cada rama representa una posible respuesta a esa característica.\nLos árboles de decisión son útiles porque proporcionan una forma fácil de visualizar y entender cómo se toman las decisiones en un modelo"
  },
  {
    "objectID": "archive/2023-03-Uniandes/4-arboles.html#arbusto",
    "href": "archive/2023-03-Uniandes/4-arboles.html#arbusto",
    "title": "4. Árboles de decisión",
    "section": "Arbusto",
    "text": "Arbusto\n\nmi_primer_arbol &lt;- los_datos |&gt; \n  select(\"PYALC\", \"GETALC\", \"GENDER\", \"GRADE\")\n\n\ntree_spec &lt;- \n  decision_tree() |&gt; \n  set_mode(\"classification\") |&gt; \n  set_engine(\"rpart\")\n\n\ntree_results &lt;- tree_spec |&gt;\n    fit(PYALC ~ ., data = mi_primer_arbol)\n\n\ncart_tree_fit &lt;- tree_results$fit\n\ntreemisc::tree_diagram(cart_tree_fit, roundint = FALSE)\n\nhttps://mlu-explain.github.io/decision-tree/\nÁrboles de clasificación y regresión (CART)\n\ntree_spec &lt;- \n  decision_tree() |&gt; \n  set_mode(\"classification\") |&gt; \n  set_engine(\"rpart\")\n\n\ntree_results &lt;- tree_spec |&gt;\n  fit(PYALC ~ ., data = datos_entrenamiento)\n\n\npredict(tree_results, predecir_estos_valores)\n\nentrenamiento &lt;- datos_entrenamiento %&gt;%\n  select(-PYALC)\n\nprediccion_tree &lt;- predict(tree_results, entrenamiento)\n\nresultados_prueba_tree &lt;- cbind(prediccion_tree, datos_entrenamiento) |&gt;\n  tibble()\n\n\ncustom_metrics(resultados_prueba_tree,\n  truth = PYALC,\n  estimate = .pred_class\n) |&gt;\n  mutate(model = \"tree\")\n\ntree_metrics &lt;- custom_metrics(resultados_prueba_tree,\n  truth = PYALC,\n  estimate = .pred_class\n) |&gt;\n  mutate(model = \"tree\")\n\nrbind(tree_metrics, lm_metrics) |&gt;\n  pivot_wider(names_from = model, values_from = .estimate)"
  },
  {
    "objectID": "archive/2023-03-Uniandes/4-arboles.html#por-qué-es-malo",
    "href": "archive/2023-03-Uniandes/4-arboles.html#por-qué-es-malo",
    "title": "4. Árboles de decisión",
    "section": "¿Por qué es malo?",
    "text": "¿Por qué es malo?\n\ndatos_prueba2_out &lt;- \n  datos_prueba |&gt; \n    select(PYALC) \n  \nlm_predicciones &lt;- cbind(predict(lm_results, datos_prueba), datos_prueba2_out)|&gt; mutate(model=\"lm\")\n\ntree_predicciones &lt;- cbind(predict(tree_results, datos_prueba), datos_prueba2_out)|&gt; mutate(model=\"tree\")\n\ntree2_predicciones &lt;- cbind(predict(tree2_results, datos_prueba), datos_prueba2_out) |&gt;  mutate(model=\"tree2\")\n\nall_models &lt;- \nrbind(lm_predicciones, tree_predicciones, tree2_predicciones) \n\nall_models\n\n\nall_models2 &lt;- all_models |&gt; \n  group_split(model) %&gt;%\n   setNames(unique(all_models$model)) %&gt;%\n  map_dfr(., ~custom_metrics(.x,\n               truth = PYALC,\n               estimate = .pred_class), .id = \"names\")\n\nall_models2 |&gt; \n  pivot_wider(names_from = names, values_from = .estimate)"
  },
  {
    "objectID": "archive/2023-03-Uniandes/2-procesamiento.html#nuevos-rumbos",
    "href": "archive/2023-03-Uniandes/2-procesamiento.html#nuevos-rumbos",
    "title": "2. Procesamiento de datos con tidyverse",
    "section": "Nuevos Rumbos",
    "text": "Nuevos Rumbos\n::: {.r-fit-text}\nIntroducción\n\nOrganización sin ánimo de lucro: Enfocada en la investigación y prevención de problemas sociales.\nÁreas de Interés: Consumo de sustancias, delincuencia, y violencia.\nAlcance Geográfico: Colombia y América Latina.\n\nFundación y Trayectoria\n\nEstablecida en Bogotá: Octubre de 2002.\nTrayectoria: Más de dos décadas comprometidas con la prevención y la investigación.\n\nColaboraciones y Alianzas\n\nOrganizaciones Locales: Alcaldías y gobernaciones, Ministerios de Salud y de Justicia, Instituto Colombiano de Bienestar Familiar.\nOrganizaciones Internacionales: Organización Panamericana de la Salud, Comisión Europea, CICAD/OEA.\nInstituciones Académicas: Universidades de New Jersey, Washington, y Miami.\n\nMás información aquí\n:::"
  },
  {
    "objectID": "archive/2023-03-Uniandes/2-procesamiento.html#base-de-datos",
    "href": "archive/2023-03-Uniandes/2-procesamiento.html#base-de-datos",
    "title": "2. Procesamiento de datos con tidyverse",
    "section": "Base de datos",
    "text": "Base de datos\n\nFactores de riesgo y de protección\n\nDisponibilidad percibida de drogas\nActitudes de la comunidad frente al consumo de drogas\nActitudes de los padres frente al consumo de drogas\nInvolucramiento en actividades comunitarias\n\nConsumo de alcohol y otras drogas\n\nConsumo de alcohol en la vida, 12 meses últimos 30 días\nHaber estado en una pelea\n\nCaracterísticas demográficas\n\nEdad\nSexo\nGrado"
  },
  {
    "objectID": "archive/2023-03-Uniandes/2-procesamiento.html#importar-la-base-de-datos",
    "href": "archive/2023-03-Uniandes/2-procesamiento.html#importar-la-base-de-datos",
    "title": "2. Procesamiento de datos con tidyverse",
    "section": "Importar la base de datos",
    "text": "Importar la base de datos\n\nlibrary(tidyverse)\nlibrary()\nlos_datos &lt;- readRDS(\"DATA/base_NR.rds\") |&gt; \n             as_tibble()\n\n\n\n\n\n\n\n\nTip\n\n\n\nreadRDS(): esta función se utiliza para leer un archivo de datos en formato RDS. En este caso, se utiliza para leer el archivo “base_NR.rds” y almacenar los datos en un objeto llamado “los_datos”.\n|&gt;:se puede leer como “siguiente”. Este operador se utiliza para encadenar varias operaciones juntas en una sola línea de código. En este caso, se utiliza para encadenar la función readRDS() a la función as_tibble().\nas_tibble(): esta función se utiliza para convertir un objeto en un tibble, que es una versión mejorada de un data frame en R. En este caso, se utiliza para convertir el objeto “los_datos” en un tibble."
  },
  {
    "objectID": "archive/2023-03-Uniandes/2-procesamiento.html#explorar-los-datos",
    "href": "archive/2023-03-Uniandes/2-procesamiento.html#explorar-los-datos",
    "title": "2. Procesamiento de datos con tidyverse",
    "section": "Explorar los datos",
    "text": "Explorar los datos\n\nlos_datos %&gt;% \n  glimpse()\n\n ::: {.callout-tip}\n\nglimpse(): Esta función se utiliza para imprimir una vista previa de los datos, incluyendo el tipo de datos de cada columna y las primeras filas de los datos. En este caso, se utiliza para explorar los datos almacenados en el objeto “los_datos”.\n\n:::"
  },
  {
    "objectID": "archive/2023-03-Uniandes/2-procesamiento.html#select",
    "href": "archive/2023-03-Uniandes/2-procesamiento.html#select",
    "title": "2. Procesamiento de datos con tidyverse",
    "section": "select()",
    "text": "select()\nEsta función selecciona columnas de una base de datos.\nEn este ejemplo, quiero una nueva base de datos que tenga la variable NHPROUD (“Hay gente en mi barrio que se siente orgullosa de mí cuando hago algo bien”)\n\nlos_datos |&gt; \n  select(NHPROUD) |&gt;\n  distinct()\n\n ::: {.callout-tip}\n\nselect(): Esta función se utiliza para seleccionar columnas específicas de un data frame o tibble. En este caso, se utiliza para seleccionar la columna “NHPROUD” del objeto “los_datos”.\ndistinct(): Esta función se utiliza para eliminar filas duplicadas de un data frame o tibble. En este caso, se utiliza para eliminar filas duplicadas de la columna “NHPROUD” del objeto “los_datos”.\n\n:::"
  },
  {
    "objectID": "archive/2023-03-Uniandes/2-procesamiento.html#select-1",
    "href": "archive/2023-03-Uniandes/2-procesamiento.html#select-1",
    "title": "2. Procesamiento de datos con tidyverse",
    "section": "select()",
    "text": "select()\nEn este ejemplo voy a seleccionar las variables GENDER, AWRMAR, AWRALC, AWRCIG\n\nGENDER: Sexo\n\n“Qué tan mal ven la mayoría de los adultos de tu barrio (aquellos más cercanos a ti) el que los jóvenes de tu edad…”\n\nAWRMAR = fumen marihuana\nAWRALC = Consuman alcohol\nAWRCIG = fumen cigarrillo\n\n\nlos_datos |&gt; \n  select(GENDER, AWRMAR, AWRALC, AWRCIG)"
  },
  {
    "objectID": "archive/2023-03-Uniandes/2-procesamiento.html#mutate",
    "href": "archive/2023-03-Uniandes/2-procesamiento.html#mutate",
    "title": "2. Procesamiento de datos con tidyverse",
    "section": "mutate()",
    "text": "mutate()\nEsta función crea una nueva variable -añade una nueva columna a la base de datos- o tranforma una variable que esté presente en la base de datos.\nPor ejemplo, si quiero transformar las tres variables del ejemplo anterior para asignar un puntaje de las percepciones de los estudiantes sobre las creencias de los adultos…\n¿Qué debo hacer?\n\nTransformar el texto que hay en la base por los valores: 1, 2, 3 y 4.\nCrear una nueva variable que calcule la media de los puntajes."
  },
  {
    "objectID": "archive/2023-03-Uniandes/2-procesamiento.html#mutate-1",
    "href": "archive/2023-03-Uniandes/2-procesamiento.html#mutate-1",
    "title": "2. Procesamiento de datos con tidyverse",
    "section": "mutate()",
    "text": "mutate()\n\nlos_datos |&gt; \n  select(AWRMAR, AWRALC, AWRCIG) |&gt; \n  mutate(AWRMAR = case_when(\n    AWRMAR == \"Muy mal\" ~ 1,\n    AWRMAR == \"Mal\" ~ 2,\n    AWRMAR == \"Notan mal\" ~ 3,\n    AWRMAR == \"Para nada mal\" ~ 4,\n   TRUE ~ NA\n  ))\n\nlos_datos |&gt; \n  select(AWRMAR, AWRALC, AWRCIG) |&gt; \n  mutate(across(everything(), transformar_respuesta)) |&gt; \n  mutate(TOTAL = (AWRMAR + AWRALC + AWRCIG)/3)\n\n\n\n\n\n\n\n\nTip\n\n\n\n## Pro\ntransformar_respuesta &lt;- function(x) {\n  case_when(\n    x == \"Muy mal\" ~ 1,\n    x == \"Mal\" ~ 2,\n    x == \"Notan mal\" ~ 3,\n    x == \"Para nada mal\" ~ 4,\n    TRUE ~ NA\n  )\n}\n\nlos_datos |&gt; \n  select(AWRMAR, AWRALC, AWRCIG) |&gt; \n  mutate(across(everything(), transformar_respuesta)) |&gt; \n   mutate(TOTAL = (AWRMAR + AWRALC + AWRCIG)/3)"
  },
  {
    "objectID": "archive/2023-03-Uniandes/2-procesamiento.html#mutate-2",
    "href": "archive/2023-03-Uniandes/2-procesamiento.html#mutate-2",
    "title": "2. Procesamiento de datos con tidyverse",
    "section": "mutate()",
    "text": "mutate()\n\n\n\n\n\n\nTip\n\n\n\ncase_when(): Esta función se utiliza para realizar una serie de comparaciones y asignar valores en función de las comparaciones. En este caso, se utiliza para asignar un valor numérico a la columna “AWRMAR” del objeto “los_datos” en función de los valores de texto que contiene.\nacross(): Esta función se utiliza para aplicar una función a varias columnas de un data frame o tibble. En este caso, se utiliza para aplicar la función transformar_respuesta() a todas las columnas del objeto “los_datos”.\neverything(): Esta función se utiliza para seleccionar todas las columnas de un data frame o tibble. En este caso, se utiliza para aplicar la función transformar_respuesta() a todas las columnas del objeto “los_datos”."
  },
  {
    "objectID": "archive/2023-03-Uniandes/2-procesamiento.html#filter",
    "href": "archive/2023-03-Uniandes/2-procesamiento.html#filter",
    "title": "2. Procesamiento de datos con tidyverse",
    "section": "filter()",
    "text": "filter()\nfilter() es una función que permite seleccionar filas de la base de datos según una condición.\nAhora voy a utilizar un filtro para seleccionar solamente las filas en las que los adultos respondieron “No tan mal” para el consumo de marihuana (AWRMAR).\n\nlos_datos |&gt; \n  select(GENDER, AWRMAR, AWRALC, AWRCIG) |&gt; \n  filter(AWRMAR == \"No tan mal\")\n\n\nCon este filtro puedo ver que en los primeros 10 casos, cuando un adulto juzga que no está tan mal fumar marihuana, el juicio de consumo de alcohol y cigarrillo parece seguir el mismo patrón."
  },
  {
    "objectID": "archive/2023-03-Uniandes/2-procesamiento.html#filter-1",
    "href": "archive/2023-03-Uniandes/2-procesamiento.html#filter-1",
    "title": "2. Procesamiento de datos con tidyverse",
    "section": "filter()",
    "text": "filter()\nAhora miremos qué pasa si filtro por la opción “Muy mal”\n\nlos_datos |&gt; \n  select(GENDER, AWRMAR, AWRALC, AWRCIG) |&gt; \n  filter(AWRMAR == \"Muy mal\")\n\n\nEs diferente al primer ejemplo, juzgar el consumo de marihuana como Muy mal parece también coincidir con el consumo de alcohol y cigarrillo.\n\n\n\n\n\n\nTip\n\n\n\nfilter(): Esta función se utiliza para seleccionar filas específicas de un data frame o tibble en función de una o varias condiciones. En este caso, se utiliza para seleccionar las filas del objeto “los_datos” en las que la columna “AWRMAR” es igual a “No tan mal”."
  },
  {
    "objectID": "archive/2023-03-Uniandes/2-procesamiento.html#summarise",
    "href": "archive/2023-03-Uniandes/2-procesamiento.html#summarise",
    "title": "2. Procesamiento de datos con tidyverse",
    "section": "summarise()",
    "text": "summarise()\nEsta función permiten obtener medidas de resumen de la base de datos, como por ejemplo, la media, moda, frecuencias, desviación estándar, etc.\n\n# Para marihuana\n\nlos_datos |&gt; \n  select(GENDER, AWRMAR, AWRALC, AWRCIG) |&gt; \n  mutate(across(starts_with(\"A\"),transformar_respuesta)) |&gt; \n  summarise(mean_AWRMAR = mean(AWRMAR, na.rm = TRUE),\n            sd_AWRMAR = sd(AWRMAR, na.rm = TRUE), \n            max_AWRMAR = max(AWRMAR, na.rm = TRUE), \n            min_AWRMAR = min(AWRMAR, na.rm = TRUE))\n\n\n\n\n\n\n\nTip\n\n\n\nsummarise(): Esta función se utiliza para obtener medidas de resumen de un data frame o tibble. En este caso, se utiliza para obtener la media, la desviación estándar, el valor máximo y el valor mínimo de la columna “AWRMAR” del objeto “los_datos”.\nstarts_with(): Esta función se utiliza para seleccionar columnas que comienzan con un determinado prefijo. En este caso, se utiliza para seleccionar las columnas que comienzan con “A” del objeto “los_datos”."
  },
  {
    "objectID": "archive/2023-03-Uniandes/2-procesamiento.html#explorar-los-datos-1-1",
    "href": "archive/2023-03-Uniandes/2-procesamiento.html#explorar-los-datos-1-1",
    "title": "2. Procesamiento de datos con tidyverse",
    "section": "Explorar los datos 1",
    "text": "Explorar los datos 1\n\nfactores_de_riesgo &lt;- c(\"CRPAD\", \"CRLNFD\", \"FRPFD\", \"FRPFM\", \"SRLCS\", \"PRFAD\", \n                        \"PRATA\", \"PRFUD\", \"PRIAP\", \"FPOPI\", \"FPRPI\", \"SPRPI\")\ndemograficas &lt;- c(\"YEAR\", \"GRADE\", \"GENDER\", \"AGE\")\nconsumo_alcohol &lt;- c(\"PYALC\")\n\n\n\nlos_datos %&gt;% \n  select(all_of(factores_de_riesgo), \n         all_of(demograficas), \n         all_of(consumo_alcohol)) %&gt;% \n  glimpse()\n\n\n\nmini_datos &lt;- los_datos %&gt;% \n  select(all_of(factores_de_riesgo), \n         all_of(demograficas), \n         all_of(consumo_alcohol)) \n\n\n\nmini_datos |&gt; \n  skimr::skim()\n\n\n\n\nMachine Learning"
  },
  {
    "objectID": "slides/2-R-MED-MIGRACION.html",
    "href": "slides/2-R-MED-MIGRACION.html",
    "title": "R para la programación en Bioestadística y Ciencia de Datos: data frames",
    "section": "",
    "text": "Antes de comenzar con el análisis es importante definir la organización de los archivos del proyecto. Esto puede variar según la complejidad del proyecto. Una estructura bien definida nos ayudará a localizar fácilmente los archivos y facilitará la reproducibilidad del análisis. Por ejemplo, en este proyecto vamos a tener una carpeta principal llamada “Rmed-101-esp” que contendrá las siguientes carpetas:\ndata: datos para analizar\nscripts: scripts de R\nimg: imágenes generadas"
  },
  {
    "objectID": "slides/2-R-MED-MIGRACION.html#archivos-en-data",
    "href": "slides/2-R-MED-MIGRACION.html#archivos-en-data",
    "title": "R para la programación en Bioestadística y Ciencia de Datos: data frames",
    "section": "Archivos en data",
    "text": "Archivos en data\nVamos a utilizar una base de datos en formato excel descargado de la página datos abiertos del gobierno de Colombia. Esta base contiene información sobre atenciones en los servicios de salud a la población migrante en la ciudad de Bucaramanga, la cual se encuentra ubicada cerca a la frontera entre Colombia y Venezuela.\n\n\n\n\n\n\n\n\nLa base de datos contiene más de 200 mil registros de atenciones a la población migrante reportadas por diferentes prestadores de servicios de salud de la ciudad.\n\nNos interesa saber si el número de atenciones prestadas a la población migrante ha tenido algún cambio entre los años 2017 y 2021.\n\nPara responder esto, debemos cumplir varios pasos, como por ejemplo, limpiar y organizar la base de datos. En este taller, vamos a hacer el análisis completo para responder a esta pregunta de interés."
  },
  {
    "objectID": "slides/2-R-MED-MIGRACION.html#archivos-en-scripts",
    "href": "slides/2-R-MED-MIGRACION.html#archivos-en-scripts",
    "title": "R para la programación en Bioestadística y Ciencia de Datos: data frames",
    "section": "Archivos en scripts",
    "text": "Archivos en scripts\nNecesitamos crear un archivo con formato .qmd en la carpeta scripts. El nombre del archivo va a ser “atenciones_migrantes.qmd”. El título del documento puede ser “Informe sobre atenciones a la población migrante en la ciudad de Bucaramanga.”"
  },
  {
    "objectID": "slides/2-R-MED-MIGRACION.html#instalar-los-paquetes",
    "href": "slides/2-R-MED-MIGRACION.html#instalar-los-paquetes",
    "title": "R para la programación en Bioestadística y Ciencia de Datos: data frames",
    "section": "Instalar los paquetes",
    "text": "Instalar los paquetes\nDebemos instalar los siguientes paquetes para utilizar sus funciones durante este taller.\n\ninstall.packages(\"here\") # Paquete para gestionar rutas de archivos\ninstall.packages(\"tidyverse\") # Paquete principal para el análisis de datos\ninstall.packages(\"janitor\") # Paquete para limpiar la base de datos\ninstall.packages(\"readxl\") # Paquete para leer archivos excel"
  },
  {
    "objectID": "slides/2-R-MED-MIGRACION.html#cargar-los-paquetes",
    "href": "slides/2-R-MED-MIGRACION.html#cargar-los-paquetes",
    "title": "R para la programación en Bioestadística y Ciencia de Datos: data frames",
    "section": "Cargar los paquetes",
    "text": "Cargar los paquetes\nUna de las ventajas de R es la disponibilidad de paquetes creados para hacer la vida de los investigadores más fácil. Un paquete es un conjunto de funciones y datos que se pueden instalar y cargar en R para realizar tareas específicas. En este caso, vamos a cargar los paquetes necesarios para el análisis de datos.\nPara cargar un paquete en R, se utiliza la función library(). En este caso, vamos a cargar los paquetes here, tidyverse, janitor y readxl.\n\nlibrary(here) # Paquete para gestionar rutas de archivos\nlibrary(tidyverse) # Paquete principal para el análisis de datos\nlibrary(janitor) # Paquete para limpiar la base de datos\nlibrary(readxl) # Paquete para leer archivos excel"
  },
  {
    "objectID": "slides/2-R-MED-MIGRACION.html#importar-la-base-de-datos",
    "href": "slides/2-R-MED-MIGRACION.html#importar-la-base-de-datos",
    "title": "R para la programación en Bioestadística y Ciencia de Datos: data frames",
    "section": "Importar la base de datos",
    "text": "Importar la base de datos\nA continuación, vamos a importar los datos a R y los vamos a guardar en un objeto llamado atenciones_migrantes. Para hacer esto, vamos a utilizar la función read_xlsx() del paquete readxl.\nPara importar los datos y correr el código vamos a crear un chunk. Para crear el chunk con el teclado los usuarios de Mac presionan Option + Command + I, los usuarios de Windows Ctrl + Alt + I\nPara correr el código podemos presionar el triangulo verde en el chunk o podemos poner el cursor en cualquier lugar de la línea del código y los usuarios de Mac presionan Command + enter, los usuarios de Windows Ctrl + enter\nNo estamos familiarizados con la base de datos, por lo que vamos a explorarla un poco. Por ejemplo, podemos identificar cuántas columnas y filas tiene la base de datos, así como los nombres de las columnas.\n\natenciones_migrantes &lt;- read_xlsx(\"data/atenciones_migrantes.xlsx\")\n\n\natenciones_migrantes\n\n# A tibble: 234,824 × 11\n   MES            Año FECHA_CARGO         tipo_de_servicio SERVICIO ESPECIALIDAD\n   &lt;chr&gt;        &lt;dbl&gt; &lt;dttm&gt;              &lt;chr&gt;            &lt;chr&gt;    &lt;chr&gt;       \n 1 12. Diciemb…  2017 2017-04-12 00:00:00 Laboratorio      37105 M… IMAGENOLOGI…\n 2 12. Diciemb…  2017 2017-04-12 00:00:00 Laboratorio      37105 M… IMAGENOLOGI…\n 3 07. Julio     2017 2017-07-20 00:00:00 Laboratorio      37105 M… IMAGENOLOGI…\n 4 07. Julio     2017 2017-07-20 00:00:00 Laboratorio      37105 M… IMAGENOLOGI…\n 5 08. Agosto    2017 2017-10-08 00:00:00 Laboratorio      37105 M… IMAGENOLOGI…\n 6 08. Agosto    2017 2017-10-08 00:00:00 Laboratorio      37105 M… IMAGENOLOGI…\n 7 08. Agosto    2017 2017-08-13 00:00:00 Laboratorio      37105 M… IMAGENOLOGI…\n 8 08. Agosto    2017 2017-08-13 00:00:00 Laboratorio      37105 M… IMAGENOLOGI…\n 9 09. Septiem…  2017 2017-01-09 00:00:00 Laboratorio      37105 M… IMAGENOLOGI…\n10 09. Septiem…  2017 2017-01-09 00:00:00 Laboratorio      37105 M… IMAGENOLOGI…\n# ℹ 234,814 more rows\n# ℹ 5 more variables: CANTIDAD &lt;dbl&gt;, VALOR_SERVICIO &lt;dbl&gt;, LUGAR &lt;chr&gt;,\n#   `Curso de vida` &lt;chr&gt;, Sexo &lt;chr&gt;\n\n\nAl haber utilizado read_xlsx(), la base de datos se ha guardado en un objeto de tipo tibble, que es una estructura de datos similar a un data.frame pero con algunas mejoras. Por ejemplo, los tibbles no convierten el texto en factores y muestran las dimensiones del objeto de manera más accesible. En nuesetro caso, la base de datos contiene 234824 filas, que corresponden a las atenciones prestadas a la población migrante, y 11 columnas, que corresponden a las variables capturadas por los prestadores de servicios.\nSi quieremos ver los nombres de las columnas, podemos hacerlo de la siguiente manera:\n\natenciones_migrantes |&gt;\n  names()\n\n [1] \"MES\"              \"Año\"              \"FECHA_CARGO\"      \"tipo_de_servicio\"\n [5] \"SERVICIO\"         \"ESPECIALIDAD\"     \"CANTIDAD\"         \"VALOR_SERVICIO\"  \n [9] \"LUGAR\"            \"Curso de vida\"    \"Sexo\"            \n\n\nEsto |&gt; o %&gt;% es llamado pipe y debe leerse como y después. Para crearlo Mac users: Cmd + Shift + M Windows users: Ctrl + Shift + M.\nAunque los nombres son claros, hay algunos problemas. Por ejemplo, los nombres de las columnas contienen espacios y caracteres especiales, lo que puede generar algunos problemas. Además, no se utilizaron de manera consistente las minúsculas y mayúsculas. Es importnate tener un forma de nombrar las variables. Hay diferentes formatos, para más información puede consultar aquí: naming conventions.\nVamos a limpiar los nombres de las columnas utilizando la función clean_names() del paquete janitor.\n\natenciones_migrantes &lt;- atenciones_migrantes |&gt;\n  clean_names()\n\natenciones_migrantes |&gt; names()\n\n [1] \"mes\"              \"ano\"              \"fecha_cargo\"      \"tipo_de_servicio\"\n [5] \"servicio\"         \"especialidad\"     \"cantidad\"         \"valor_servicio\"  \n [9] \"lugar\"            \"curso_de_vida\"    \"sexo\"            \n\n\nAhora podemos definir las variables de interés para el análisis. Queremos saber si las atenciones prestadas a la población migrante han tenido algún cambio entre los años 2017 y 2021. Por ahora, vamos a ignorar que los servicios prestados pueden clasificarse en diferentes categorias. Primero, vamos a tomar todas las atenciones prestadas en los años 2017 y 2021, sin importar su clasificación.\nUtilizaremos la función select() para seleccionar las columnas de interes. En este caso, solo nos interesa la columna ano. Una vez la selecionamos, podemos contar cuantas atenciones se prestaron en cada año.\n\natenciones_migrantes |&gt; # El nombre de los datos\n  select(ano) |&gt; # Seleccionamos la columna de interes\n  count(ano) # Contamos cuantas atenciones se prestaron en cada año\n\n# A tibble: 9 × 2\n    ano     n\n  &lt;dbl&gt; &lt;int&gt;\n1  2014     2\n2  2015     4\n3  2016    72\n4  2017  8754\n5  2018 26498\n6  2019 65553\n7  2020 49527\n8  2021 78849\n9  2022  5565\n\n\nObservamos que la base de datos contiene atenciones desde los años 2014 hasta el 2022. Sin embargo, solo vamos a concentrarnos en los años 2017 a 2021. Para seleccionar las atenciones prestadas en estos años, podemos utilizar la función filter().\n\natenciones_migrantes |&gt;\n  select(ano) |&gt;\n  filter(ano &gt;= 2017 & ano &lt;= 2021) |&gt;\n  count(ano)\n\n# A tibble: 5 × 2\n    ano     n\n  &lt;dbl&gt; &lt;int&gt;\n1  2017  8754\n2  2018 26498\n3  2019 65553\n4  2020 49527\n5  2021 78849\n\n\nAhora que tenemos las atenciones prestadas en los años de interés, podemos calcular el porcentaje para cada año. Para hacer esto, vamos a utilizar la función mutate() para crear una nueva columna llamada porcentaje que contenga el porcentaje de atenciones en cada año.\n\natenciones_migrantes |&gt;\n  select(ano) |&gt;\n  filter(ano &gt;= 2017 & ano &lt;= 2021) |&gt;\n  count(ano) |&gt;\n  mutate(porcentaje = n / sum(n) * 100)\n\n# A tibble: 5 × 3\n    ano     n porcentaje\n  &lt;dbl&gt; &lt;int&gt;      &lt;dbl&gt;\n1  2017  8754       3.82\n2  2018 26498      11.6 \n3  2019 65553      28.6 \n4  2020 49527      21.6 \n5  2021 78849      34.4 \n\n\n\nRetoSolución\n\n\n¿Cómo obtener el porcentaje solo para los años 2017, 2019, 2021?\n\n\nPara obtener el porcentaje solo para los años 2017, 2019 y 2021, podemos utilizar la función filter() para seleccionar solo las filas correspondientes a estos años. Podemos utilizar el operador %in% para seleccionar los años de interés. Por ejemplo, filter(ano %in% c(2017, 2019, 2021)) seleccionará solo las filas correspondientes a los años 2017, 2019 y 2021.\n\n\n\nUna vez construida la tabla de porcentajes, podemos visualizarla en un gráfico. Vamos a utilizar la función ggplot() del paquete ggplot2 para crear un gráfico de lineas que muestre el porcentaje de atenciones prestadas en cada año.\n\natenciones_migrantes |&gt;\n  select(ano) |&gt;\n  filter(ano &gt;= 2017 & ano &lt;= 2021) |&gt;\n  count(ano) |&gt;\n  mutate(porcentaje = n / sum(n) * 100) |&gt;\n  ggplot(aes(x = ano, y = porcentaje, group = 1)) +\n  geom_line() +\n  geom_point() +\n  labs(\n    title = \"Porcentaje de atenciones prestadas a población migrante en Bucaramanga\",\n    x = \"Año\",\n    y = \"Porcentaje de atenciones\"\n  )\n\n\n\n\nggplot2() es una de las herramientas más atractivas de R debido a su flexibilidad y capacidad para crear gráficos de alta calidad. En este caso, hemos utilizado ggplot() para crear un gráfico de líneas que muestra el porcentaje de atenciones prestadas a la población migrante en Bucaramanga entre los años 2017 y 2021. Hemos utilizado geom_line() para trazar la línea y geom_point() para agregar los puntos al gráfico. También, hemos utilizado labs() para agregar títulos a los ejes y al gráfico.\n\nReto 1Solución 1Reto 2Solución 2\n\n\nCambie el color de las líneas y de los puntos en el gráfico.\n\n\nPara cambiar el color podemos utilizar el argumento “color” en la función geom_*. Tenga en cuenta que si especifica el lugar por fuera de la función aes() podrá especificar el color directamente. Si lo hace dentro, el color cambiará de acuerdo a la información de la base de datos. En ese caso, puede cambiar el color agregando la función scale_color_manual() a su ggplot.\n\n\nAgrege la funcionción theme_minimal() para cambiar el formato del gráfico. Explore otros formatos disponibles en ggplot2 aquí: themes\n\n\nAl final del gráfico agregue el símbolo + seguido de theme_minimal(). Tenga en cuenta que los formatos del gráfico son altamente modificables. Usted puede cambiar colores, líneas, tamaños de letra, entre otros.\n\n\n\nSe observa un incremento de las atenciones a traves del tiempo. Sin embargo, sería más interesante saber si este incremento es similar para hombres y mujeres. Para hacer esto, vamos a utilizar nuevamente la función count() pero esta vez vamos a especificar dos variables para contar el número de atenciones. Además, vamos a calcular el porcentaje de atenciones para grupo. Para esto, vamos a agregar la opción .by a la función mutate.\n\natenciones_migrantes |&gt;\n  select(ano, sexo) |&gt;\n  filter(ano &gt;= 2017 & ano &lt;= 2021) |&gt;\n  count(ano, sexo) |&gt;\n  mutate(porcentaje = n / sum(n) * 100, .by = sexo)\n\n# A tibble: 10 × 4\n     ano sexo          n porcentaje\n   &lt;dbl&gt; &lt;chr&gt;     &lt;int&gt;      &lt;dbl&gt;\n 1  2017 Femenino   6811       3.85\n 2  2017 Masculino  1943       3.71\n 3  2018 Femenino  21743      12.3 \n 4  2018 Masculino  4755       9.08\n 5  2019 Femenino  50330      28.5 \n 6  2019 Masculino 15223      29.1 \n 7  2020 Femenino  38857      22.0 \n 8  2020 Masculino 10670      20.4 \n 9  2021 Femenino  59087      33.4 \n10  2021 Masculino 19762      37.7 \n\n\nHemos utilizado count() con dos variables, ano y sexo, para contar el número de atenciones prestadas a hombres y mujeres en cada año. Hemos utilizado mutate() para calcular el porcentaje de atenciones prestadas a hombres y mujeres en cada año. La opción .by le ha indicado a mutate que haga el proceso de suma para cada grupo de manera separada, de tal manera que el porcentaje de atenciónes sumará 100% para hombres y para mujeres.\nAhora, vamos a visualizar estos resultados en un gráfico de lineas utilizando ggplot2.\n\natenciones_migrantes |&gt;\n  select(ano, sexo) |&gt;\n  filter(ano &gt;= 2017 & ano &lt;= 2021) |&gt;\n  count(ano, sexo) |&gt;\n  mutate(porcentaje = n / sum(n) * 100, .by = sexo) |&gt;\n  ggplot(aes(x = ano, y = porcentaje, group = sexo, color = sexo)) +\n  geom_line() +\n  geom_point() +\n  labs(\n    title = \"Porcentaje de atenciones prestadas a población migrante en Bucaramanga\",\n    x = \"Año\",\n    y = \"Porcentaje de atenciones\",\n    color = \"Sexo\"\n  ) +\n  scale_color_manual(values = c(\"blue\", \"red\"))\n\n\n\n\nEn este caso, hemos utilizado ggplot() para crear un gráfico de líneas que muestra el porcentaje de atenciones prestadas a la población migrante en Bucaramanga en los años 2017 a 2021, desglosado por sexo. Hemos utilizado el argumento color al interior de la funcion aes(), lo que nos ha permitido separar las líneas en dos grupos. La función scale_color_manual() nos permitió cambiar los colores de las líneas y los puntos en el gráfico.\n\nReto 4Solución 4Reto 5Solución 5\n\n\nCambie el tipo de línea en el gráfico.\n\n\nPara cambiar el tipo de línea puede utilizar el argumento linetype al interior de geom_line().\n\n\nCambiar el tamaño de los puntos en el gráfico.\n\n\nPara cambiar el tamaño de los puntos puede utilizar el argumento size al interior del geom_point(). Tenga en cuenta que si especifica el argumento size al interior de la función aes() el tamaño variará de acuerdo con una variable numérica en la base de datos.\n\n\n\nAhora, vamos a explorar un poco más la base de datos. Exploremos la variable tipo_de_servicio. Para hacer esto, vamos a contar cuántas atenciones se han prestado en cada tipo de servicio.\n\natenciones_migrantes |&gt;\n  count(tipo_de_servicio)\n\n# A tibble: 16 × 2\n   tipo_de_servicio        n\n   &lt;chr&gt;               &lt;int&gt;\n 1 CONSULTA            60768\n 2 Consulta              303\n 3 Derecho de Sala         2\n 4 Estancia                8\n 5 Honorario               4\n 6 Imagenologia           23\n 7 Interconsulta           5\n 8 Laboratorio        100312\n 9 OTROS SERVICIOS      6059\n10 Otro procedimiento    301\n11 Otros servicios       127\n12 PROC QUIRURGICO      1931\n13 PROCEDIMIENTO       63030\n14 Quirurgico              4\n15 VACUNACION           1909\n16 Vacunas                38\n\n\nLa información no esta muy bien organizada en esta variable. Tenemos valores repetidos, como “CONSULTA” y “Consulta”, que deberían ser considerados como el mismo valor. Para solucionar esto, vamos a convertir todos los valores de la variable tipo_de_servicio a minúsculas utilizando la función str_to_sentence() la cual nos permite mantener en mayuscula la primera letra y en minúscula el resto. Luego, vamos a contar cuántas atenciones se han prestado en cada tipo de servicio.\n\natenciones_migrantes |&gt;\n  mutate(tipo_de_servicio = str_to_sentence(tipo_de_servicio)) |&gt;\n  count(tipo_de_servicio)\n\n# A tibble: 14 × 2\n   tipo_de_servicio        n\n   &lt;chr&gt;               &lt;int&gt;\n 1 Consulta            61071\n 2 Derecho de sala         2\n 3 Estancia                8\n 4 Honorario               4\n 5 Imagenologia           23\n 6 Interconsulta           5\n 7 Laboratorio        100312\n 8 Otro procedimiento    301\n 9 Otros servicios      6186\n10 Proc quirurgico      1931\n11 Procedimiento       63030\n12 Quirurgico              4\n13 Vacunacion           1909\n14 Vacunas                38\n\n\nHemos arreglado la opcion consulta, pero aun hay valores repetidos. Por ejemplo, “Vacunas” y “vacunacion” deberían ser considerados como el mismo valor. Para esto, vamos a utilizar la funcion case_when() que nos permite reemplazar valores de una columna de acuerdo a una condición. En este caso, vamos a reemplazar “Vacunas” por “Vacunacion”. También podemos reemplazar “Quirurgico” por “Proc Quirurgico”.\n\natenciones_migrantes |&gt;\n  mutate(tipo_de_servicio = str_to_sentence(tipo_de_servicio)) |&gt;\n  mutate(\n    tipo_de_servicio =\n      case_when(\n        tipo_de_servicio == \"vacunas\" ~ \"vacunacion\",\n        tipo_de_servicio == \"quirurgico\" ~ \"proc quirurgico\",\n        .default = tipo_de_servicio\n      )\n  ) |&gt;\n  count(tipo_de_servicio)\n\n# A tibble: 14 × 2\n   tipo_de_servicio        n\n   &lt;chr&gt;               &lt;int&gt;\n 1 Consulta            61071\n 2 Derecho de sala         2\n 3 Estancia                8\n 4 Honorario               4\n 5 Imagenologia           23\n 6 Interconsulta           5\n 7 Laboratorio        100312\n 8 Otro procedimiento    301\n 9 Otros servicios      6186\n10 Proc quirurgico      1931\n11 Procedimiento       63030\n12 Quirurgico              4\n13 Vacunacion           1909\n14 Vacunas                38\n\n\nHay varios tipos de servicios que tienen una frecuencia muy baja y podríamos agrupar en una categoría llamada “Otros”. Para hacer esto, vamos a utilizar nuevamente la función case_when() para reemplazar los valores de la variable tipo_de_servicio de acuerdo a una condición.\n\natenciones_migrantes |&gt;\n  mutate(tipo_de_servicio = str_to_sentence(tipo_de_servicio)) |&gt;\n  mutate(\n    tipo_de_servicio =\n      case_when(\n        tipo_de_servicio == \"Vacunas\" ~ \"Vacunacion\",\n        tipo_de_servicio == \"Quirurgico\" ~ \"Proc quirurgico\",\n        tipo_de_servicio %in% c(\n          \"Derecho de sala\", \"Estancia\", \"Honorario\",\n          \"Imagenologia\",\n          \"Interconsulta\",\n          \"Otro procedimiento\"\n        ) ~ \"Otros\",\n        .default = tipo_de_servicio\n      )\n  ) |&gt;\n  count(tipo_de_servicio)\n\n# A tibble: 7 × 2\n  tipo_de_servicio      n\n  &lt;chr&gt;             &lt;int&gt;\n1 Consulta          61071\n2 Laboratorio      100312\n3 Otros               343\n4 Otros servicios    6186\n5 Proc quirurgico    1935\n6 Procedimiento     63030\n7 Vacunacion         1947\n\n\nAhora que hemos arreglado las categorías para los servicios prestados, podemos calcular el porcentaje de atenciones prestadas en cada categoria por año. Vamos a guardar esta informacion en un objeto llamado atenciones_por_servicio. También vamos a filtrar la información de los años 2017 a 2021 y vamos a calcular los porcentajes para cada año.\n\natenciones_por_servicio &lt;- atenciones_migrantes |&gt;\n  mutate(tipo_de_servicio = str_to_sentence(tipo_de_servicio)) |&gt;\n  mutate(\n    tipo_de_servicio =\n      case_when(\n        tipo_de_servicio == \"Vacunas\" ~ \"Vacunacion\",\n        tipo_de_servicio == \"Quirurgico\" ~ \"Proc quirurgico\",\n        tipo_de_servicio %in% c(\n          \"Derecho de sala\", \"Estancia\", \"Honorario\",\n          \"Imagenologia\",\n          \"Interconsulta\",\n          \"Otro procedimiento\"\n        ) ~ \"Otros\",\n        .default = tipo_de_servicio\n      )\n  ) |&gt;\n  filter(ano &gt;= 2017 & ano &lt;= 2021) |&gt;\n  count(ano, tipo_de_servicio) |&gt;\n  mutate(porcentaje = n / sum(n) * 100, .by = ano)\n\nAhora podemos hacer un gráfico que muestre estos resultados.\n\natenciones_por_servicio |&gt;\n  ggplot(aes(x = ano, y = porcentaje, group = tipo_de_servicio, color = tipo_de_servicio)) +\n  geom_line() +\n  geom_point() +\n  labs(\n    title = \"Atenciones prestadas a población migrante en Bucaramanga por tipo de servicio\",\n    x = \"Año\",\n    y = \"Número de atenciones\",\n    color = \"Tipo de servicio\"\n  )\n\n\n\n\nSe observan algunos cambios en la tendencia de algunos servicios. Por ejemplo, una disminución en el uso de laboratorio u un aumento en los procedimientos. Los demás servicios parecen más estables.\n\nReto 7Solución 7Reto 8Solución 8\n\n\nCrear un gráfico en el que solo estén presentes los valores de Consulta, Laboratorio y Procedimiento.\n\n\nPuede utilizar la función filter()\n\n\nla escala del eje debería indicar porcentajes. Por ejemplo, en lugar de 40, 40%.\n\n\nPuede agregar a su ggplot + scale_y_continuous(labels=scales::percent) para expresar los valores de su escala en porcentajes. Sin embargo, es posible que deba hacer un cambio en su base datos para el resultado correcto.\n\n\n\nEsta gráfica la podemos guardar en nuestra carpeta de imágenes. Para esto, vamos a utilizar la función ggsave().\n\nggsave(here(\"img\", \"atenciones_por_servicio.png\"))\n\nSaving 7 x 5 in image\n\n\n\nReto 9Solución\n\n\nCambie el tamaño de la gráfica y observe qué impacto tiene esto.\n\n\nEncontrar el tamaño ideal para su gráfica es un proceso que requiere varios ensayos. Si usted quiere, puede utilizar el argumento units = \"cm\" en la función ggsave() para indicar el tamaño en centímetros."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Bienvenidos",
    "section": "",
    "text": "Le damos la bienvenida a este taller que es parte de Rmed. En este taller nos enfocaremos en los fundamentos de R y la creación de análisis que sean reproducibles. En esta página, hemos compilado todos los materiales necesarios para la sesión y esperamos que estos recursos diseñados especialmente para ustedes sean de su agrado.\nEn este taller vamos a trabajar sobre tres ideas principales:\n\nIntroducción a R\nTipos de variables\nEjemplo de análisis de datos"
  },
  {
    "objectID": "index.html#pasos-previos-al-taller",
    "href": "index.html#pasos-previos-al-taller",
    "title": "Bienvenidos",
    "section": "Pasos previos al taller",
    "text": "Pasos previos al taller\nPara aprovechar al máximo este taller, es necesario completar las siguientes tareas antes de que inicie el evento:\n\nCreación de una cuenta en Posit Cloud: si aún no tienes una, por favor, crea una cuenta gratuita en Posit Cloud."
  },
  {
    "objectID": "index.html#agenda-del-workshop",
    "href": "index.html#agenda-del-workshop",
    "title": "Bienvenidos",
    "section": "Agenda del Workshop",
    "text": "Agenda del Workshop"
  },
  {
    "objectID": "slides/1-R-MED-INTRO-A-R.html#introducción",
    "href": "slides/1-R-MED-INTRO-A-R.html#introducción",
    "title": "R para la programación en Bioestadística y Ciencia de Datos: Introducción a R",
    "section": "Introducción",
    "text": "Introducción\nEn este taller, aprenderemos sobre los tipos de datos que existen en R. Aprender a identificar los diferentes tipos de datos es escencial para poder sacar más provecho de este paquete. Primero, vamos a definir cuáles tipos de variables existen en R."
  },
  {
    "objectID": "slides/1-R-MED-INTRO-A-R.html#tipos-de-variables-en-r",
    "href": "slides/1-R-MED-INTRO-A-R.html#tipos-de-variables-en-r",
    "title": "R para la programación en Bioestadística y Ciencia de Datos: Introducción a R",
    "section": "Tipos de variables en R",
    "text": "Tipos de variables en R\n\n1. Números\n\nEnteros\nLos números enteros son números sin decimales. En R, los enteros se definen utilizando la función as.integer() o agregando una L al final del número.\n\nun_numero &lt;- 10\nmi_entero &lt;- as.integer(10)\nmi_entero2 &lt;- 10L\n\nclass(un_numero)\n\n[1] \"numeric\"\n\nclass(mi_entero)\n\n[1] \"integer\"\n\nclass(mi_entero2)\n\n[1] \"integer\"\n\n\n\n\nNúmeros Decimales (Double)\nLos números decimales en R se denominan “double” o “numeric”. Se definen simplemente escribiendo el número con decimales.\n\n# Definiendo un número decimal\nmi_decimal &lt;- 10.5\n\n# Mostrando el tipo de dato\nclass(mi_decimal)\n\n[1] \"numeric\"\n\n\n\n\n\n2. Caracteres/palabras (Strings)\nLos caracteres son letras o número que se definen entre comillas simples o dobles.\n\nmi_caracter &lt;- \"Hola, mundo!\"\n\nclass(mi_caracter)\n\n[1] \"character\"\n\n\n\n\n3. Lógicos (Booleanos)\nLos valores lógicos son TRUE o FALSE.\n\nmi_logico &lt;- TRUE\nmi_logico\n\n[1] TRUE\n\nclass(mi_logico)\n\n[1] \"logical\"\n\n\n\n\n4. Factores\nLos factores se utilizan para datos categóricos y pueden tener niveles ordenados o no ordenados.\n\nmi_factor &lt;- factor(c(\"bajo\", \"medio\", \"alto\"))\n\nclass(mi_factor)\n\n[1] \"factor\"\n\nmi_factor\n\n[1] bajo  medio alto \nLevels: alto bajo medio\n\nmi_factor_ordenado &lt;- factor(c(\"bajo\", \"medio\", \"alto\"), ordered = TRUE)\n\nclass(mi_factor_ordenado)\n\n[1] \"ordered\" \"factor\" \n\nmi_factor_ordenado\n\n[1] bajo  medio alto \nLevels: alto &lt; bajo &lt; medio\n\n\n\n\nEn resumen"
  },
  {
    "objectID": "slides/1-R-MED-INTRO-A-R.html#tipos-de-objetos-en-r",
    "href": "slides/1-R-MED-INTRO-A-R.html#tipos-de-objetos-en-r",
    "title": "R para la programación en Bioestadística y Ciencia de Datos: Introducción a R",
    "section": "Tipos de objetos en R",
    "text": "Tipos de objetos en R\n\n1. Vectores\nUn vector es una colección de elementos del mismo tipo. Se puede crear utilizando la función c().\n\nmi_vector &lt;- c(1, 2, 3, 4, 5)\n\nclass(mi_vector)\n\n[1] \"numeric\"\n\nlength(mi_vector)\n\n[1] 5\n\n\n\n\n2. Matrices\nUna matriz es una colección de elementos del mismo tipo organizados en dos dimensiones. Se puede crear utilizando la función matrix().\n\nmi_matriz &lt;- matrix(1:9, nrow = 3, ncol = 3)\n\nprint(mi_matriz)\n\n     [,1] [,2] [,3]\n[1,]    1    4    7\n[2,]    2    5    8\n[3,]    3    6    9\n\nclass(mi_matriz)\n\n[1] \"matrix\" \"array\" \n\n\n\n\n3. Data Frames\nUn data frame es una colecciónde elementos donde las columnas pueden ser de diferentes tipos. Se puede crear utilizando la función data.frame(). Más adelante vamos a llamar a los “data.frame” como “tibble”, cuando agreguemos algunas características adicionales que hacen más fácil el entendimiento de la estructura de los datos.\n\nmi_data_frame &lt;- data.frame(\n  nombre = c(\"Ana\", \"Luis\", \"Carlos\"),\n  edad = c(23, 25, 30),\n  altura = c(160, 175, 168)\n)\n\nprint(mi_data_frame)\n\n  nombre edad altura\n1    Ana   23    160\n2   Luis   25    175\n3 Carlos   30    168\n\nclass(mi_data_frame)\n\n[1] \"data.frame\"\n\n\n\n\n4. Listas\nUna lista es una colección de elementos que pueden ser de diferentes tipos. Se puede crear utilizando la función list().\n\nmi_lista &lt;- list(\n  nombre = \"Ana\",\n  edad = 23,\n  alturas = c(160, 175, 168)\n)\n\n# Mostrando la lista y su tipo de dato\nprint(mi_lista)\n\n$nombre\n[1] \"Ana\"\n\n$edad\n[1] 23\n\n$alturas\n[1] 160 175 168\n\nclass(mi_lista)\n\n[1] \"list\""
  },
  {
    "objectID": "slides/1-R-MED-INTRO-A-R.html#ejercicio",
    "href": "slides/1-R-MED-INTRO-A-R.html#ejercicio",
    "title": "R para la programación en Bioestadística y Ciencia de Datos: Introducción a R",
    "section": "Ejercicio",
    "text": "Ejercicio\n\nEjercicio 1: Crear un vector\nCrea un vector con los números del 1 al 10 y muestra su longitud y tipo de dato.\n\n# codigo aquí\n\n\nEjercicio 2: Crear un data frame\nCrea un data frame con los nombres y edades de 3 personas. Muestra el data frame.\n\n# Código aquí"
  },
  {
    "objectID": "archive/2023-03-Uniandes/1-introduccion.html#temas",
    "href": "archive/2023-03-Uniandes/1-introduccion.html#temas",
    "title": "1 - Introducción a Machine Learning in tidymodels",
    "section": "Temas",
    "text": "Temas\n\n\n\n\nTipos de modelos\n\nDescriptivo\nInferencial\nPredictivo\n\nMachine Learning - Supervised\n\nClasificación\nRegresión - Unsupervised\nClustering\n\nEquilibrio entre la varianza y el sesgo\nValidación Cruzada\n\n\n\nEvaluación de los Modelos - Separación entrenamiento y prueba - Remuestreo\n\nLeave One Out\nK-Fold\nBoostraping"
  },
  {
    "objectID": "archive/2023-03-Uniandes/1-introduccion.html#tipos-de-modelos",
    "href": "archive/2023-03-Uniandes/1-introduccion.html#tipos-de-modelos",
    "title": "1 - Introducción a Machine Learning in tidymodels",
    "section": "Tipos de modelos",
    "text": "Tipos de modelos\n\nDescriptivosInferencialPredictivo\n\n\n\nDescribir las características de una base de datos\nVisualizar los datos\nResumir los datos\nGenerar hipótesis\n\n\n\n\nEstimar la probabilidad de que ocurra un evento\nProducir una estimación de un parámetro poblacional\nProbar una hipótesis\nIdea predeterminada y se prueba\nValor p, intervalo de confianza\n\n\n\n\nAnticipar el valor de una variable\nAplicar una regla a un evento que no ha ocurrido\nMayor interés en la predicción que en la inferencia\nPuede ser que no importe el mecanismo"
  },
  {
    "objectID": "archive/2023-03-Uniandes/1-introduccion.html#otra-clasificación-es",
    "href": "archive/2023-03-Uniandes/1-introduccion.html#otra-clasificación-es",
    "title": "1 - Introducción a Machine Learning in tidymodels",
    "section": "Otra clasificación es",
    "text": "Otra clasificación es\n\nModelos explicativos\nModelos predictivos"
  },
  {
    "objectID": "archive/2023-03-Uniandes/1-introduccion.html#machine-learning",
    "href": "archive/2023-03-Uniandes/1-introduccion.html#machine-learning",
    "title": "1 - Introducción a Machine Learning in tidymodels",
    "section": "Machine Learning",
    "text": "Machine Learning\nMuchos modelos de machine learning son predictivos por ejemplo:\n\nk-nearest neighbors\nÁrboles de decisión\nRandom Forests\nSupport Vector Machines"
  },
  {
    "objectID": "archive/2023-03-Uniandes/1-introduccion.html#machine-learning-1",
    "href": "archive/2023-03-Uniandes/1-introduccion.html#machine-learning-1",
    "title": "1 - Introducción a Machine Learning in tidymodels",
    "section": "Machine Learning",
    "text": "Machine Learning\n\nMachine LearningUnsupervisedSupervised\n\n\n\n\n\nNo hay una variable de resultado\n\nComponentes principales\n\n\n\n\nHay una variable de resultado\n\nRegresión: variable de resultado continua\nClasificación: variable de resultado categórica"
  },
  {
    "objectID": "archive/2023-03-Uniandes/1-introduccion.html#cuál-es-el-proceso-del-análisis-de-datos",
    "href": "archive/2023-03-Uniandes/1-introduccion.html#cuál-es-el-proceso-del-análisis-de-datos",
    "title": "1 - Introducción a Machine Learning in tidymodels",
    "section": "Cuál es el proceso del análisis de datos",
    "text": "Cuál es el proceso del análisis de datos\n\n\n¿La creación del modelo es el primer paso?\n¿Limpiar los datos?\n¿Explorar los datos?\n¿Cómo se van a evaluar los modelos?"
  },
  {
    "objectID": "archive/2023-03-Uniandes/1-introduccion.html#gráfico-del-proceso-de-análisis-de-datos",
    "href": "archive/2023-03-Uniandes/1-introduccion.html#gráfico-del-proceso-de-análisis-de-datos",
    "title": "1 - Introducción a Machine Learning in tidymodels",
    "section": "Gráfico del proceso de análisis de datos",
    "text": "Gráfico del proceso de análisis de datos"
  },
  {
    "objectID": "archive/2023-03-Uniandes/1-introduccion.html#proceso-de-análisis-de-datos",
    "href": "archive/2023-03-Uniandes/1-introduccion.html#proceso-de-análisis-de-datos",
    "title": "1 - Introducción a Machine Learning in tidymodels",
    "section": "Proceso de análisis de datos",
    "text": "Proceso de análisis de datos\n\n\n\nExplorar los datos (EDA)\n“Ingeniería de variables”- crear nuevas variables\nAjustar-sintonizar los modelos\nEvaluar los modelos"
  },
  {
    "objectID": "archive/2023-03-Uniandes/1-introduccion.html#tres-ideas-importantes",
    "href": "archive/2023-03-Uniandes/1-introduccion.html#tres-ideas-importantes",
    "title": "1 - Introducción a Machine Learning in tidymodels",
    "section": "Tres ideas importantes",
    "text": "Tres ideas importantes\n\n\nUtilizar la muestra para estimar el error de generalización\nDescomponer el error en tres fuentes: varianza, sesgo y ruido.\nUtilizar recursos computacionales"
  },
  {
    "objectID": "archive/2023-03-Uniandes/1-introduccion.html#cuál-es-el-mejor-sofware-para-hacer-esto",
    "href": "archive/2023-03-Uniandes/1-introduccion.html#cuál-es-el-mejor-sofware-para-hacer-esto",
    "title": "1 - Introducción a Machine Learning in tidymodels",
    "section": "¿Cuál es el mejor sofware para hacer esto?",
    "text": "¿Cuál es el mejor sofware para hacer esto?\n\n\n\nPython\nR\nJulia\nMatlab\nProgramas\n\nMplus\nStata\nSAS\nSPSS"
  },
  {
    "objectID": "archive/2023-03-Uniandes/1-introduccion.html#tidyverse",
    "href": "archive/2023-03-Uniandes/1-introduccion.html#tidyverse",
    "title": "1 - Introducción a Machine Learning in tidymodels",
    "section": "Tidyverse",
    "text": "Tidyverse\n\n\nggplot2 - para visualización de gráficos\ndplyr - para el procesamiento de datos\ntidyr - para la transformación de datos en formato “tidy” (ordenado)\nreadr - para la lectura de datos en diferentes formatos (CSV, TSV, etc.)\npurrr - para la programación funcional\ntibble - para la creación de data frames en formato “tidy”\nstringr - para la manipulación de cadenas de texto\nforcats- para la manipulación de factores"
  },
  {
    "objectID": "archive/2023-03-Uniandes/1-introduccion.html#tidyverse-1",
    "href": "archive/2023-03-Uniandes/1-introduccion.html#tidyverse-1",
    "title": "1 - Introducción a Machine Learning in tidymodels",
    "section": "Tidyverse",
    "text": "Tidyverse\n\nEstilo\n\nPipe\nnombre_de_los_objetos\nuso de las comillas\nretorna un objeto de la misma clase\nprogramación funcional\n\n\n\n\n\nMachine Learning"
  },
  {
    "objectID": "archive/2023-03-Uniandes/3-modelos.html#agenda",
    "href": "archive/2023-03-Uniandes/3-modelos.html#agenda",
    "title": "3. Estimar un modelo",
    "section": "Agenda",
    "text": "Agenda\nParte I\n\nEspecificar un modelo\nEstimar un modelo\nVer los resultados del modelo\n\nParte II\n\nDividir los datos\nEspecificar un modelo\nEstimar un modelo\nEvaluar el modelo\nEstimar un modelo mejor"
  },
  {
    "objectID": "archive/2023-03-Uniandes/3-modelos.html#estimar-un-modelo",
    "href": "archive/2023-03-Uniandes/3-modelos.html#estimar-un-modelo",
    "title": "3. Estimar un modelo",
    "section": "Estimar un modelo",
    "text": "Estimar un modelo\n\nHay muchas formas de estimar modelos en R\n\nlm(formula, data, ...)\nstan_glm(formula, data, family= \"gaussian\",...)\nglmnet(x=matrix, y=vector, family=\"gaussian\",...)\n\n\n\n\n\n\n\nTip\n\n\nlm(): Ajusta un modelo de regresión lineal a los datos.\nstan_glm(): Ajusta un modelo de regresión utilizando el paquete Stan.\nglmnet(): Ajusta un modelo de regresión utilizando la regularización Lasso o Ridge."
  },
  {
    "objectID": "archive/2023-03-Uniandes/3-modelos.html#especificar-el-modelo-en-tidymodels",
    "href": "archive/2023-03-Uniandes/3-modelos.html#especificar-el-modelo-en-tidymodels",
    "title": "3. Estimar un modelo",
    "section": "Especificar el modelo en tidymodels",
    "text": "Especificar el modelo en tidymodels\nTidymodels ofrece una sintaxis general para estimar los modelos\nhttps://www.tidymodels.org/\n\nEspecificar el tipo de modelo\n\nlinear_reg(), logistic_reg(), decition_tree()\n\nEspecificar el tipo de outcome\n\nRegresión para outcomes continuos\nClasificación: multinomial, ordinal, binaria\n\n\n\n\nlibrary(tidymodels)\n\ntidymodels_prefer()\n\nlinear_reg() |&gt; \n  set_engine(\"lm\") \n\nlinear_reg() |&gt; \n    set_engine(\"glmnet\") \n    \nlinear_reg() |&gt;\n    set_engine(\"stan\")"
  },
  {
    "objectID": "archive/2023-03-Uniandes/3-modelos.html#especificar-el-modelo-en-tidymodels-1",
    "href": "archive/2023-03-Uniandes/3-modelos.html#especificar-el-modelo-en-tidymodels-1",
    "title": "3. Estimar un modelo",
    "section": "Especificar el modelo en tidymodels",
    "text": "Especificar el modelo en tidymodels\n\n\n\n\n\n\nTip\n\n\nlibrary(): Carga el paquete tidymodels en R.\ntidymodels_prefer(): Establece el paquete tidymodels como el preferido para las funciones de modelado en R.\nlinear_reg(): Crea una especificación de modelo de regresión lineal en el marco de trabajo tidymodels.\nset_engine(): Establece el motor de cálculo para un objeto de especificación de modelo. Se establece en “lm” para la primera llamada a linear_reg(), “glmnet” para la segunda llamada y “stan” para la tercera."
  },
  {
    "objectID": "archive/2023-03-Uniandes/3-modelos.html#estimar-un-modelo-1",
    "href": "archive/2023-03-Uniandes/3-modelos.html#estimar-un-modelo-1",
    "title": "3. Estimar un modelo",
    "section": "Estimar un modelo",
    "text": "Estimar un modelo\nEstimar un modelo de regresión logistica para evaluar la asociación entre el consumo de alcohol y los factores de riesgo\n\nmini_datos |&gt;\n    select(PYALC,factores_de_riesgo) |&gt;\n    table1::table1( ~ ., data=_)\n\n\n\nmini_datos |&gt;\n    select(PYALC,factores_de_riesgo) |&gt;\n    filter(!is.na(PYALC)) |&gt; \n    table1::table1( ~ . | PYALC, data=_)"
  },
  {
    "objectID": "archive/2023-03-Uniandes/3-modelos.html#explorar-los-datos-visualmente",
    "href": "archive/2023-03-Uniandes/3-modelos.html#explorar-los-datos-visualmente",
    "title": "3. Estimar un modelo",
    "section": "Explorar los datos visualmente",
    "text": "Explorar los datos visualmente\n\nmini_datos |&gt; \n  group_by(PYALC) |&gt; \n  summarise(across(\"CRPAD\":\"SPRPI\", \\(x) mean(x, na.rm = TRUE))) |&gt; \n  pivot_longer(-PYALC) |&gt; \n  filter(!is.na(PYALC)) |&gt; \n  ggplot(aes(value, fct_reorder(name, value), fill = PYALC)) +\n  geom_col(alpha = 0.8, position = \"dodge\") +\n  scale_x_continuous() +\n  labs(x = \"Promedio\", y = NULL, fill = NULL)"
  },
  {
    "objectID": "archive/2023-03-Uniandes/3-modelos.html#especificar-el-modelo",
    "href": "archive/2023-03-Uniandes/3-modelos.html#especificar-el-modelo",
    "title": "3. Estimar un modelo",
    "section": "1. Especificar el modelo",
    "text": "1. Especificar el modelo\n\nlm_model &lt;-\n    logistic_reg() %&gt;% \n    set_engine(\"glm\", family=\"binomial\") |&gt;\n    set_mode(\"classification\")\n\n\nEspecificar un modelo de regresión logística. Se establece el “paquete”, en este caso “glm” y opciones del paquete (la distribución de la variable de respuesta). Además, se establece el modo de modelado en “classification” para indicar que es una variable categórica. El resultado se almacena en el objeto lm_model."
  },
  {
    "objectID": "archive/2023-03-Uniandes/3-modelos.html#estimar-el-modelo",
    "href": "archive/2023-03-Uniandes/3-modelos.html#estimar-el-modelo",
    "title": "3. Estimar un modelo",
    "section": "2. Estimar el modelo",
    "text": "2. Estimar el modelo\n\nlm_results &lt;- lm_model |&gt;\n    fit(PYALC ~ ., data = mini_datos)\n\n\nAquí se ajusta-estima el modelo utilizando la función fit(). Se especifica la variable de respuesta (PYALC) y los predictores (.) y se utiliza el objeto mini_datos como base de datos."
  },
  {
    "objectID": "archive/2023-03-Uniandes/3-modelos.html#ver-los-resultados-del-modelo",
    "href": "archive/2023-03-Uniandes/3-modelos.html#ver-los-resultados-del-modelo",
    "title": "3. Estimar un modelo",
    "section": "3. Ver los resultados del modelo",
    "text": "3. Ver los resultados del modelo\n\nlm_results |&gt; tidy() \n\nlm_results |&gt; glance()\n\n\ntidy(): Esta función se utiliza para convertir los resultados de un modelo en un marco de datos “ordenado” que muestra los coeficientes del modelo, los errores estándar, los valores t y los valores p para cada variable independiente.\nglance(): Esta función se utiliza para resumir los resultados de un modelo como estadísticas globales del modelo, por ejemplo, R-cuadrado ajustado, el AIC y el BIC.\n\n\n\n\n\n\n\nTip\n\n\n\nlm_results |&gt; tidy(exp=TRUE, conf.int=TRUE)\n\ntidy(exp=TRUE, conf.int=TRUE): Esta función se utiliza para convertir los resultados de un modelo en un marco de datos “ordenado” que muestra los coeficientes del modelo, los errores estándar, los valores t y los valores p para cada variable independiente. Los argumentos exp y conf.int se utilizan para incluir los intervalos de confianza y los exponentes en los resultados"
  },
  {
    "objectID": "archive/2023-03-Uniandes/3-modelos.html#para-qué-necesitamos-los-datos",
    "href": "archive/2023-03-Uniandes/3-modelos.html#para-qué-necesitamos-los-datos",
    "title": "3. Estimar un modelo",
    "section": "Para qué necesitamos los datos?",
    "text": "Para qué necesitamos los datos?\nNecesitamos:\n- Estimar parametros\n- Seleccionar modelos\n- Sintonizar los modelos (tunning)\n- Evaluar los modelos\n¿Cómo gastarnos los datos de una forma que sea eficiente para todos estos pasos? (validación empírica)"
  },
  {
    "objectID": "archive/2023-03-Uniandes/3-modelos.html#dividir-los-datos",
    "href": "archive/2023-03-Uniandes/3-modelos.html#dividir-los-datos",
    "title": "3. Estimar un modelo",
    "section": "Dividir los datos",
    "text": "Dividir los datos\n\nDividir los datos en dos conjuntos\n\nEntrenamiento\n\nLa mayoría de los datos (¿70%, 80%?)\nAquí se ajusta el modelo\n\nPrueba\n\nUn pequeño conjunto de datos\nAquí se evaluará el modelo final\n\n\n\nLos datos de prueba se utilizan una sola vez, si se utilizan más de una vez, se convierten en parte del proceso de entrenamiento.\n\nLa división de los datos se hace al nivel de unidad independiente de observación."
  },
  {
    "objectID": "archive/2023-03-Uniandes/3-modelos.html#dividir-los-datos-1",
    "href": "archive/2023-03-Uniandes/3-modelos.html#dividir-los-datos-1",
    "title": "3. Estimar un modelo",
    "section": "Dividir los datos",
    "text": "Dividir los datos\nCrear dos bases: 80% y 20%\n\nset.seed(1234)\n\nmini_datos &lt;- mini_datos |&gt; drop_na()\n\ndatos_divididos &lt;- initial_split(mini_datos, prop = 0.8, strata = \"PYALC\")\n\ndatos_entrenamiento &lt;- training(datos_divididos)\ndatos_prueba &lt;- testing(datos_divididos)\n\n\nLa opción strata es para que los datos de entrenamiento y prueba tengan la misma distribución de la variable PYALC\n\nA veces la selección aleatoria de la muestra es problemática, por ejemplo cuando hay una componente de tiempo en los datos. En este caso, se puede usar la función initial_time_split()."
  },
  {
    "objectID": "archive/2023-03-Uniandes/3-modelos.html#dividir-los-datos-2",
    "href": "archive/2023-03-Uniandes/3-modelos.html#dividir-los-datos-2",
    "title": "3. Estimar un modelo",
    "section": "Dividir los datos",
    "text": "Dividir los datos\nset.seed(): se utiliza para establecer una semilla para la generación de números aleatorios en R. En este caso, se utiliza para establecer la semilla en 1234, lo que garantiza que los resultados sean reproducibles. Esto es especialmente importante cuando se trabaja con modelos de aprendizaje automático, ya que los resultados pueden variar según la semilla utilizada para la generación de números aleatorios.\ndrop_na(): Esta función se utiliza para eliminar filas con valores faltantes de un data frame o tibble. En este caso, se utiliza para eliminar filas con valores faltantes del objeto “mini_datos”.\ninitial_split(): Esta función se utiliza para dividir un data frame o tibble en conjuntos de entrenamiento y prueba. En este caso, se utiliza para dividir el objeto “mini_datos” en conjuntos de entrenamiento y prueba en una proporción de 80/20, y estratificando por la columna “PYALC”.\ntraining(): Esta función se utiliza para extraer el conjunto de entrenamiento de un objeto creado con la función initial_split(). En este caso, se utiliza para extraer el conjunto de entrenamiento del objeto “datos_divididos”.\ntesting(): Esta función se utiliza para extraer el conjunto de prueba de un objeto creado con la función initial_split(). En este caso, se utiliza para extraer el conjunto de prueba del objeto “datos_divididos”."
  },
  {
    "objectID": "archive/2023-03-Uniandes/3-modelos.html#especificar-el-modelo-1",
    "href": "archive/2023-03-Uniandes/3-modelos.html#especificar-el-modelo-1",
    "title": "3. Estimar un modelo",
    "section": "1. Especificar el modelo",
    "text": "1. Especificar el modelo\n\nlm_model &lt;-\n  logistic_reg() %&gt;%\n  set_engine(\"glm\", family = \"binomial\") |&gt;\n  set_mode(\"classification\")"
  },
  {
    "objectID": "archive/2023-03-Uniandes/3-modelos.html#estimar-el-modelo-1",
    "href": "archive/2023-03-Uniandes/3-modelos.html#estimar-el-modelo-1",
    "title": "3. Estimar un modelo",
    "section": "2. Estimar el modelo",
    "text": "2. Estimar el modelo\n\nlm_results &lt;- lm_model |&gt;\n    fit(PYALC ~ ., data = datos_entrenamiento)"
  },
  {
    "objectID": "archive/2023-03-Uniandes/3-modelos.html#ver-los-resultados-del-modelo-1",
    "href": "archive/2023-03-Uniandes/3-modelos.html#ver-los-resultados-del-modelo-1",
    "title": "3. Estimar un modelo",
    "section": "3. Ver los resultados del modelo",
    "text": "3. Ver los resultados del modelo\n\nlm_results |&gt; tidy()\n\n\nlm_results |&gt; tidy(exp=TRUE, conf.int=TRUE)"
  },
  {
    "objectID": "archive/2023-03-Uniandes/3-modelos.html#evaluar-el-modelo",
    "href": "archive/2023-03-Uniandes/3-modelos.html#evaluar-el-modelo",
    "title": "3. Estimar un modelo",
    "section": "4. Evaluar el modelo",
    "text": "4. Evaluar el modelo\n\npredecir_estos_valores &lt;- datos_entrenamiento %&gt;% \n    select(-PYALC) %&gt;% \n    slice(1:10)\n\npredict(lm_results, predecir_estos_valores)\n\n\npredict(lm_results, predecir_estos_valores, type=\"prob\")\n\n\nentrenamiento &lt;- datos_entrenamiento %&gt;% \n    select(-PYALC)\n\nprediccion &lt;- predict(lm_results, entrenamiento)\n\nresultados_prueba &lt;- cbind(prediccion, datos_entrenamiento) |&gt; \n  select(.pred_class, PYALC, everything()) |&gt; \n  tibble()"
  },
  {
    "objectID": "archive/2023-03-Uniandes/3-modelos.html#calcular-las-métricas",
    "href": "archive/2023-03-Uniandes/3-modelos.html#calcular-las-métricas",
    "title": "3. Estimar un modelo",
    "section": "Calcular las métricas",
    "text": "Calcular las métricas\n\nconf_mat(resultados_prueba, truth = PYALC,\n         estimate = .pred_class)\n\naccuracy(resultados_prueba, truth = PYALC,\n         estimate = .pred_class)\n\nsens(resultados_prueba, truth = PYALC,\n    estimate = .pred_class)"
  },
  {
    "objectID": "archive/2023-03-Uniandes/3-modelos.html#calcular-las-métricas-1",
    "href": "archive/2023-03-Uniandes/3-modelos.html#calcular-las-métricas-1",
    "title": "3. Estimar un modelo",
    "section": "Calcular las métricas",
    "text": "Calcular las métricas\n\nspec(resultados_prueba, truth = PYALC,\n    estimate = .pred_class)\n\nprecision(resultados_prueba, truth = PYALC,\n    estimate = .pred_class)\n\nrecall(resultados_prueba, truth = PYALC,\n    estimate = .pred_class)\n\nkap(resultados_prueba, truth = PYALC,\n    estimate = .pred_class)"
  },
  {
    "objectID": "archive/2023-03-Uniandes/3-modelos.html#calcular-las-métricas-2",
    "href": "archive/2023-03-Uniandes/3-modelos.html#calcular-las-métricas-2",
    "title": "3. Estimar un modelo",
    "section": "Calcular las métricas",
    "text": "Calcular las métricas\n\ncustom_metrics &lt;- metric_set(accuracy, sens, spec, precision, recall, f_meas, kap, mcc)\n\ncustom_metrics(resultados_prueba,\n  truth = PYALC,\n  estimate = .pred_class\n)\n\nlm_metrics &lt;- custom_metrics(resultados_prueba,\n  truth = PYALC,\n  estimate = .pred_class\n) |&gt;\n  mutate(model = \"lm\")"
  },
  {
    "objectID": "archive/2023-03-Uniandes/3-modelos.html#tabla-de-métricas",
    "href": "archive/2023-03-Uniandes/3-modelos.html#tabla-de-métricas",
    "title": "3. Estimar un modelo",
    "section": "Tabla de Métricas",
    "text": "Tabla de Métricas\n\nlibrary(gt)\n\ncustom_metrics(resultados_prueba,\n  truth = PYALC,\n  estimate = .pred_class\n) |&gt; gt()"
  },
  {
    "objectID": "archive/2023-03-Uniandes/3-modelos.html#área-bajo-la-curva",
    "href": "archive/2023-03-Uniandes/3-modelos.html#área-bajo-la-curva",
    "title": "3. Estimar un modelo",
    "section": "Área bajo la curva",
    "text": "Área bajo la curva\n\nprediccion_auc &lt;- predict(lm_results, entrenamiento, type = \"prob\")\n\nresultados_prueba_auc &lt;- cbind(prediccion_auc, datos_entrenamiento) |&gt;\n  tibble()\n\nroc_auc(resultados_prueba_auc,\n  truth = PYALC,\n  `.pred_No ha consumido`\n)\n\nroc_curve(resultados_prueba_auc,\n  truth = PYALC,\n  `.pred_No ha consumido`\n) |&gt; autoplot()"
  },
  {
    "objectID": "archive/2023-03-Uniandes/5-forest.html#validación-cruzada",
    "href": "archive/2023-03-Uniandes/5-forest.html#validación-cruzada",
    "title": "5. Random Forest",
    "section": "Validación Cruzada",
    "text": "Validación Cruzada\nSupongamos que estamos trabajando en un problema de clasificación binaria y disponemos de un conjunto de datos con 1000 registros. Queremos evaluar el rendimiento de un modelo de regresión logística utilizando la validación cruzada k-fold.\nPaso a paso del proceso de k-fold cross-validation:\nDividir el conjunto de datos: Primero, dividimos el conjunto de datos en k subconjuntos (folds) de igual tamaño. En este ejemplo, elegimos k=10, lo que significa que dividimos el conjunto de datos en 10 subconjuntos de 100 registros cada uno.\nEntrenar y evaluar el modelo: Luego, realizamos lo siguiente para cada uno de los k subconjuntos:\n\nTomamos un subconjunto como el conjunto de prueba (validación) y los k-1 subconjuntos restantes como el conjunto de entrenamiento. Por ejemplo, en la primera iteración, usamos el primer subconjunto como conjunto de prueba y los subconjuntos del 2 al 10 como conjunto de entrenamiento.\nEntrenamos el modelo de regresión logística utilizando el conjunto de entrenamiento.\nEvaluamos el rendimiento del modelo en el conjunto de prueba utilizando una métrica adecuada, como la precisión, la exhaustividad o el F1-score. Anotamos el resultado de la métrica para esta iteración.\n\nPromediar los resultados: Después de completar las k iteraciones, calculamos la media de los resultados de la métrica para todas las iteraciones. Esta media nos proporciona una estimación más robusta del rendimiento del modelo, ya que el modelo ha sido evaluado en diferentes subconjuntos del conjunto de datos.\nhttps://scikit-learn.org/stable/modules/cross_validation.html https://www.tmwr.org/resampling.html"
  },
  {
    "objectID": "archive/2023-03-Uniandes/5-forest.html#cart",
    "href": "archive/2023-03-Uniandes/5-forest.html#cart",
    "title": "5. Random Forest",
    "section": "CART",
    "text": "CART\nHay tres variables que están más relacionadas con no consumir alcohol.\n\ncrossvalidation &lt;-\n  vfold_cv(datos_entrenamiento, \n           v = 5,  # número de cajas\n           strata = \"PYALC\")\n\n\ntree_spec &lt;- \n  decision_tree(\n    cost_complexity = tune(), \n    tree_depth = tune(),\n    min_n = tune()\n  ) |&gt; \n  set_mode(\"classification\") |&gt; \n  set_engine(\"rpart\")\n\nCost_complexity (tmedida de complejidad alfa o parámetro de poda alfa):\nCost_complexity es un parámetro de regularización. Es una medida de la penalización que se aplica al árbol en función de su complejidad. Un valor más alto de cost_complexity implica una penalización más fuerte en la complejidad del árbol, lo que lleva a un árbol más pequeño y menos profundo. La idea es encontrar un valor óptimo de cost_complexity que equilibre la precisión y la complejidad del árbol, reduciendo tanto el sesgo como la varianza.\nTree_depth (profundidad del árbol):\nTree_depth se refiere a la longitud máxima del camino más largo desde la raíz hasta una hoja en un árbol de decisión. Un árbol más profundo es más complejo y puede capturar relaciones más complicadas en los datos. Sin embargo, un árbol demasiado profundo también puede ser propenso al sobreajuste, ya que puede adaptarse demasiado a las peculiaridades de los datos de entrenamiento.\nMin_n (mínimo número de muestras para dividir un nodo):\nMin_n es un parámetro que controla el número mínimo de datos requeridas para dividir un nodo en un árbol de decisión. Un valor más alto de min_n implica que el árbol será menos profundo, ya que se requerirán más muestras para realizar una división en cada nodo. Un valor más bajo de min_n permite que el árbol se divida más fácilmente y, por lo tanto, puede resultar en un árbol más complejo y profundo.\n\ntree_grid &lt;- grid_regular(cost_complexity(range = c(-10L, -1L)), \n                          tree_depth (range = c(5L, 10L)), \n                          min_n(range = c(5L, 30L)))\n\n\ndoParallel::registerDoParallel()\n\nset.seed(345)\ntree_rs &lt;-\n  tune_grid(\n    tree_spec,\n    PYALC ~ .,\n    resamples = crossvalidation,\n    grid = tree_grid,\n    metrics = metric_set(accuracy, roc_auc, sensitivity, specificity)\n  )\n\ndoParallel::stopImplicitCluster()\n\n\nshow_best(tree_rs)\n\nautoplot(tree_rs)\n\n\nsimpler_tree &lt;- select_best(tree_rs, min_n, metric = \"accuracy\")\n\nfinal_tree &lt;- finalize_model(tree_spec, simpler_tree)\n\n\nfinal_fit &lt;- fit(final_tree, PYALC ~ ., datos_entrenamiento)\n\n\nfinal_cart &lt;- last_fit(final_tree, PYALC ~ ., datos_divididos,\n  metrics = metric_set(accuracy, roc_auc, sensitivity, specificity)\n)\n\n\ncollect_metrics(final_cart)\n\n\ncart_trained &lt;- \n  final_cart  |&gt; extract_fit_parsnip()\n\ncart_tree_fit &lt;- cart_trained$fit\n\ntreemisc::tree_diagram(cart_tree_fit, roundint=FALSE)"
  },
  {
    "objectID": "archive/2023-03-Uniandes/5-forest.html#random-forest",
    "href": "archive/2023-03-Uniandes/5-forest.html#random-forest",
    "title": "5. Random Forest",
    "section": "Random Forest",
    "text": "Random Forest\n\nNúmero de predictores que se usan para cada árbol (mtry)\nNúmero de árboles (trees)\nProfundidad de los árboles (min_n)\n\nRandom Forest\n\nrf_spec &lt;- \n  rand_forest()  |&gt; \n  set_mode(\"classification\") |&gt; \n  set_engine(\"ranger\", importance = \"permutation\")\n\n\nrf_results &lt;- rf_spec |&gt; \nfit(PYALC ~ ., data = datos_entrenamiento)\n\nlibrary(vip)\nimportance_plot_rf &lt;- \n  rf_results |&gt; \n  vip() +\n  ggtitle(\"Random Forest\")\n\n\nrf_predicciones &lt;- predict(rf_results, entrenamiento)\n\nresultados_rf &lt;- cbind(rf_predicciones,datos_entrenamiento) |&gt; \n  tibble()\n\nrf_metrics &lt;- custom_metrics(resultados_rf,\n               truth = PYALC,\n               estimate = .pred_class) |&gt;\n  mutate(model=\"rf\")\n\nrbind(rf_metrics, tree2_metrics, tree_metrics, lm_metrics) |&gt; \n  pivot_wider(names_from = model, values_from = .estimate)\n\n\nrf_predicciones &lt;- cbind(predict(rf_results, datos_prueba), datos_prueba2_out) |&gt;  mutate(model=\"rf\")\n\nall_models &lt;- \nrbind(lm_predicciones, rf_predicciones,tree_predicciones, tree2_predicciones) \n\n\nall_models2 &lt;- all_models |&gt; \n  group_split(model) %&gt;%\n   setNames(unique(all_models$model)) %&gt;%\n  map_dfr(., ~custom_metrics(.x,\n               truth = PYALC,\n               estimate = .pred_class), .id = \"names\")\nall_models2 |&gt; \n  pivot_wider(names_from = names, values_from = .estimate)"
  },
  {
    "objectID": "archive/2023-03-Uniandes/5-forest.html#sesgo-y-varianza",
    "href": "archive/2023-03-Uniandes/5-forest.html#sesgo-y-varianza",
    "title": "5. Random Forest",
    "section": "Sesgo y varianza",
    "text": "Sesgo y varianza\nEstos dos conceptos son cruciales para entender el equilibrio entre la complejidad del modelo y su capacidad para generalizar a nuevos datos.\nSesgo (Bias): a. Definición: El sesgo es la diferencia entre la predicción promedio de nuestro modelo y el valor verdadero que intentamos predecir.El sesgo, en términos estadísticos, se refiere a la diferencia sistemática entre la esperanza (o promedio) de las estimaciones que produce un estimador y el valor real del parámetro que se desea estimar. Un modelo con alta varianza es muy sensible a pequeñas variaciones en los datos de entrenamiento, lo que puede resultar en un sobreajuste. Es decir, el modelo se ajusta muy bien a los datos de entrenamiento, pero tiene un rendimiento deficiente en datos no vistos o de prueba.\n\nEjemplo: Un modelo de regresión lineal simple podría tener un alto sesgo si los datos reales tienen una relación no lineal.\nImplicaciones: Un modelo con alto sesgo es demasiado simple y no captura la estructura subyacente de los datos. Esto conduce a un bajo rendimiento en el conjunto de entrenamiento y prueba.\n\nVarianza (Variance): a. Definición: La varianza es la cantidad de variabilidad en las predicciones del modelo para un punto de datos dado. b. Ejemplo: Un modelo de árbol de decisión muy profundo podría tener alta varianza, ya que es muy sensible a pequeñas variaciones en los datos de entrenamiento. c. Implicaciones: Un modelo con alta varianza tiende a sobreajustarse a los datos de entrenamiento, lo que resulta en un buen rendimiento en el conjunto de entrenamiento pero un bajo rendimiento en el conjunto de prueba.\nEl objetivo en Machine Learning es equilibrar el sesgo y la varianza para minimizar el error de predicción general en el modelo a. Objetivo: Encontrar un equilibrio entre sesgo y varianza que minimice el error total de predicción. b. Estrategias: Seleccionar un modelo con la complejidad adecuada, usar técnicas de regularización, y validar el modelo con conjuntos de datos de entrenamiento y prueba separados.\nFormas de disminur el sesgo\nAumentar la complejidad del modelo: Un modelo más complejo puede capturar mejor la estructura subyacente de los datos. Por ejemplo, en lugar de utilizar una regresión lineal simple, podrías probar una regresión polinomial o un modelo de árbol de decisión.\nAñadir más variables: A veces, el sesgo puede ser el resultado de no tener en cuenta variables importantes que influyen en la variable objetivo. Añadir más variables relevantes puede ayudar a reducir el sesgo del modelo.\nUtilizar técnicas de “ingeniería de predictores”: Transformar o combinar las variables existentes para crear nuevas características puede ayudar a capturar mejor la relación entre las variables de entrada y salida. Por ejemplo, si estás trabajando en un problema de predicción de precios de viviendas, podrías crear una nueva característica que represente la relación entre el tamaño de la casa y el número de habitaciones.\nAumentar el tamaño del conjunto de datos: Si tu conjunto de datos es pequeño o no es representativo de la población general, es posible que el modelo tenga un sesgo alto. Aumentar el tamaño del conjunto de datos y asegurarte de que es representativo puede ayudar a reducir el sesgo.\nUtilizar ensembles de modelos: Combinar varios modelos en un ensemble puede ayudar a reducir el sesgo, ya que cada modelo puede capturar diferentes aspectos de la relación entre las variables de entrada y salida. Por ejemplo, puedes utilizar métodos de ensemble como Bagging, Boosting o Stacking."
  },
  {
    "objectID": "archive/2023-03-Uniandes/5-forest.html#técnicas-para-reducir-la-varianza",
    "href": "archive/2023-03-Uniandes/5-forest.html#técnicas-para-reducir-la-varianza",
    "title": "5. Random Forest",
    "section": "Técnicas para reducir la varianza",
    "text": "Técnicas para reducir la varianza\nReducir la complejidad del modelo: Un modelo más simple tiende a tener una menor varianza y es menos propenso al sobreajuste. Por ejemplo, podrías limitar la profundidad de un árbol de decisión.\nUtilizar regularización: La regularización es una técnica que añade una penalización a los coeficientes del modelo para evitar que se ajusten demasiado a los datos de entrenamiento.Por ejemplo, regularización L1 (Lasso) y L2 (Ridge).\nAumentar el tamaño del conjunto de datos: Si dispones de más datos, el modelo será menos sensible a pequeñas variaciones en los datos de entrenamiento y tendrá una menor varianza.\nEliminar características ruidosas: Si tu modelo incluye características que no están relacionadas con la variable objetivo o que contienen mucho ruido, estas pueden aumentar la varianza del modelo. Realizar un análisis de importancia de características y eliminar las características poco importantes puede ayudar a reducir la varianza.\nValidación cruzada (cross-validation): Utilizar la validación cruzada, como k-fold cross-validation, te permite evaluar el rendimiento del modelo en diferentes subconjuntos del conjunto de datos de entrenamiento. Esto puede ayudarte a identificar si el modelo está sobreajustando los datos y ajustar la complejidad del modelo en consecuencia.\nUtilizar diferentes modelos: Combinar varios modelos en un ensemble puede ayudar a reducir la varianza, ya que la variabilidad de cada modelo individual se promedia. Por ejemplo, puedes utilizar métodos de ensemble como Bagging (Bootstrap Aggregating) o Random Forest, que promedian las predicciones de múltiples árboles de decisión entrenados en subconjuntos aleatorios de los datos.\n\n\n\nMachine Learning"
  },
  {
    "objectID": "archive/2023-03-Uniandes/7-regularizacion.html#usar-recetas",
    "href": "archive/2023-03-Uniandes/7-regularizacion.html#usar-recetas",
    "title": "7. Regularización",
    "section": "Usar recetas",
    "text": "Usar recetas\nConstruir la receta:\nrecipe(punt_matematicas_11 ~ ., data = datos_entrenamiento) crea un objeto recipe que especifica que se va a predecir la variable punt_matematicas_11 usando todas las otras variables (.) en los datos de entrenamiento datos_entrenamiento.\nstep_mutate(across(everything(), ~ if_else(.x == \"NA\", NA, .x))) reemplaza todos los valores de “NA” en todas las columnas con el valor NA. Esto se hace para asegurarse de que los datos faltantes estén representados correctamente en el conjunto de datos.\nstep_mutate(estu_cod_mcpio_presentacion_9 = as_factor(estu_cod_mcpio_presentacion_9)) convierte la columna estu_cod_mcpio_presentacion_9 a un factor. Esto es necesario porque esta columna representa códigos de municipios y no debería tratarse como una variable numérica continua.\nstep_mutate(estu_cod_depto_presentacion_9 = as_factor(estu_cod_depto_presentacion_9)) convierte la columna estu_cod_depto_presentacion_9 a un factor. Esto se hace por la misma razón que en el paso anterior.\nstep_mutate(estu_edad_9 = as.numeric(str_extract_all(estu_edad_9, \"\\\\d+\"))) extrae los números de la columna estu_edad_9 y los convierte a valores numéricos. Esto se hace para asegurarse de que la variable se trate como numérica en lugar de como un factor.\nstep_mutate(fami_cuartoshogar_9 = if_else(fami_cuartoshogar_9 == \"NA\", NA, fami_cuartoshogar_9)) reemplaza los valores “NA” en la columna fami_cuartoshogar_9 con el valor NA. Esto es necesario para asegurarse de que los datos faltantes estén representados correctamente.\nstep_mutate(fami_cuartoshogar_9 = as.numeric(fami_cuartoshogar_9)) convierte la columna fami_cuartoshogar_9 a valores numéricos. Esto se hace porque esta variable representa el número de habitaciones en el hogar y se espera que sea una variable numérica.\nstep_impute_mode(all_nominal_predictors()) imputa los valores faltantes en todas las variables nominales (factores) con el modo (valor más común) de cada columna.\nstep_impute_mean(all_double()) imputa los valores faltantes en todas las variables continuas con la media de cada columna.\nstep_zv(all_predictors()) elimina las variables que tienen una varianza cero. Esto se hace para asegurarse de que las variables que no cambian en todo el conjunto de datos no estén incluidas en el modelo.\nstep_normalize(all_double_predictors()) normaliza todas las variables continuas para que tengan media cero y varianza unitaria. Esto se hace para asegurarse de que las variables estén en la misma métrica\n\nset.seed(2231)\n\nmini_datos &lt;- data_icfes |&gt;\n  select(contains(\"fami\"), starts_with(\"estu\"), \"punt_matematicas_11\") |&gt;\n  select(contains(\"9\"), \"punt_matematicas_11\") |&gt; tidyREDCap::drop_labels()\n\ndatos_divididos &lt;- initial_split(mini_datos, prop = 0.8)\n\ndatos_entrenamiento &lt;- training(datos_divididos)\ndatos_prueba &lt;- testing(datos_divididos)\n\nmean(datos_entrenamiento$punt_matematicas_11, na.rm = T)\nmean(datos_prueba$punt_matematicas_11, na.rm = T)\n\n\nreceta_lasso_2 &lt;- \n  recipe(punt_matematicas_11 ~ ., data = datos_entrenamiento) |&gt;\n  step_mutate(across(everything(), ~ if_else(.x == \"NA\", NA, .x))) |&gt;\n  step_mutate(estu_cod_mcpio_presentacion_9 = as_factor(estu_cod_mcpio_presentacion_9)) |&gt;\n  step_mutate(estu_cod_depto_presentacion_9 = as_factor(estu_cod_depto_presentacion_9)) |&gt;\n  step_mutate(estu_edad_9 = as.numeric(str_extract_all(estu_edad_9, \"\\\\d+\"))) |&gt;\n  step_mutate(fami_cuartoshogar_9 = if_else(fami_cuartoshogar_9 == \"NA\", NA, \n                                            fami_cuartoshogar_9)) |&gt;\n  step_mutate(fami_cuartoshogar_9 = as.numeric(fami_cuartoshogar_9)) |&gt;\n  step_impute_mode(all_nominal_predictors()) |&gt;\n  step_impute_mean(all_double()) |&gt;\n  step_zv(all_predictors()) |&gt;\n  step_normalize(all_double_predictors()) |&gt;\n  step_dummy(all_factor_predictors())\n\nAplicar la receta y obtener los datos transformados.\n\ndespues_receta &lt;- prep(receta_lasso) |&gt; bake(new_data = datos_entrenamiento)\n\n\nspec_lasso &lt;-\n  linear_reg(penalty = 0.5, mixture = 1) |&gt;\n  # En glmnet, mixture = 1 es un modelo lasso. Mixture = 0 es ridge regression.\n  set_engine(\"glmnet\") |&gt;\n  set_mode(\"regression\")\n\nEl segundo paso es crear un workflow. A ese workflow le vamos añadir diferentes pasos. Agregamos el modelo.\n\nwf2 &lt;-\n  workflow() |&gt;\n  add_model(spec_lasso)\n\nDespués agregarmos las transformaciones que debemos realizar a las variables.\n\nDummy\nCentrar\nEscalar\n\nCentrar los datos significa restar la media de una variable de los datos. Escalar los datos significa dividir sobre la desviación estándar.\nAhora podemos agregar la receta al workflow, para que se aplique a los datos antes de estimar el modelo\n\nwf2 &lt;- wf2 |&gt;\n  add_recipe(receta_lasso_2)\n\nEstimar el error en el training\n\nlasso_fit &lt;- wf2 |&gt; \n  last_fit(datos_divididos)\n\ncollect_metrics(lasso_fit)\n\n\nwf2 %&gt;%\n  fit(datos_entrenamiento) %&gt;%\n  extract_fit_parsnip() %&gt;%\n  vip::vi() %&gt;%\n  mutate(\n    Importance = abs(Importance),\n    Variable = fct_reorder(Variable, Importance)\n  ) %&gt;%\n  head(20) |&gt;\n  ggplot(aes(x = Importance, y = Variable, fill = Sign)) +\n  geom_col() +\n  scale_x_continuous(expand = c(0, 0)) +\n  labs(y = NULL) +\n  facet_wrap(~Sign, scales = \"free_y\") +\n  theme(legend.position = \"none\")\n\nEl paquete usemodels propone una manera de hacer el recipe, el engine y el workflow\n\nusemodels::use_ranger(punt_matematicas_11 ~ ., data = datos_entrenamiento)\n\n\n\n\nMachine Learning"
  },
  {
    "objectID": "archive/2023-10-Unal/crear-tablas.html#documentar-el-análisis-de-datos",
    "href": "archive/2023-10-Unal/crear-tablas.html#documentar-el-análisis-de-datos",
    "title": "Crear tablas en R",
    "section": "1.1 Documentar el análisis de datos",
    "text": "1.1 Documentar el análisis de datos\n\n\nReplicabilidad: Permite a otros investigadores o evaluadores replicar tus hallazgos.\nTransparencia: La documentación completa demuestra la integridad del proceso de investigación, lo que aumenta la confianza en los resultados.\nClaridad: Ayuda a clarificar los métodos y resultados.\nComunicación efectiva: Facilita la transferencia de conocimientos.\nRevisión por pares: Hace que el proceso de revisión por pares sea más eficiente.\n\nMejora continua: Te permite volver a visitar y refinar tu análisis en el futuro, o adaptarlo para abordar preguntas de investigación relacionadas.\nFormación y educación: Sirve como un recurso educativo para estudiantes o profesionales que estén aprendiendo cómo llevar a cabo análisis similares.\nResolución de problemas: Facilita la identificación y corrección de errores o inconsistencias en el análisis.\nEconomía de tiempo: Reduce el tiempo necesario para retomar o modificar el proyecto en fases posteriores de la investigación."
  },
  {
    "objectID": "archive/2023-10-Unal/crear-tablas.html#herramientas-para-documentar",
    "href": "archive/2023-10-Unal/crear-tablas.html#herramientas-para-documentar",
    "title": "Crear tablas en R",
    "section": "1.2. Herramientas para documentar",
    "text": "1.2. Herramientas para documentar\n\nCódigo (Programas estadísticos)\nQuarto (Rmarkdown)\nGit (Github)\nR (También sintaxis en spss, stata, etc)"
  },
  {
    "objectID": "archive/2023-10-Unal/crear-tablas.html#quarto",
    "href": "archive/2023-10-Unal/crear-tablas.html#quarto",
    "title": "Crear tablas en R",
    "section": "1.2.1 Quarto",
    "text": "1.2.1 Quarto\n\nQuarto permite crear documentos en varios formatos (PDF, HTML, Word).\nPermite integrar código de R, Python, etc.\nIntegrar tablas y gráficos.\nUnir código y texto."
  },
  {
    "objectID": "archive/2023-10-Unal/crear-tablas.html#descripción-de-la-base-de-datos",
    "href": "archive/2023-10-Unal/crear-tablas.html#descripción-de-la-base-de-datos",
    "title": "Crear tablas en R",
    "section": "2.1 Descripción de la base de datos",
    "text": "2.1 Descripción de la base de datos\nDatos de 71 participantes sobre sus evaluaciones sociomorales en cuatro situaciones de transgresión legal: 1) daño ambiental por minería ilegal, 2) linchamiento en caso de robo, 3) tráfico de químicos para cocaína y 4) porte de armas en público. El estudio examina juicios y justificaciones sobre si hay transgresión, la gravedad de dichas transgresiones y el castigo merecido. También se evalúan las creencias sobre si las transgresiones se deben a características disposicionales de los involucrados."
  },
  {
    "objectID": "archive/2023-10-Unal/crear-tablas.html#variables",
    "href": "archive/2023-10-Unal/crear-tablas.html#variables",
    "title": "Crear tablas en R",
    "section": "Variables",
    "text": "Variables\n\nlibrary(dataWorkshopUN)\nlibrary(gtsummary)\nlibrary(tidyverse)\nlibrary(gt)\n\ndata(datos_ley_moral)\n\n\n\nRows: 6,837\nColumns: 7\n$ ID          &lt;dbl&gt; 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2…\n$ SITUACIONES &lt;chr&gt; \"Daño ambiental\", \"Daño ambiental\", \"Daño ambiental\", \"Dañ…\n$ EDAD        &lt;dbl&gt; 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17…\n$ SEXO        &lt;chr&gt; \"H\", \"H\", \"H\", \"H\", \"H\", \"H\", \"H\", \"H\", \"H\", \"H\", \"H\", \"H\"…\n$ CATEGORIAS  &lt;chr&gt; \"Expectativa de transgresón\", \"Justificación de los desenl…\n$ CODIGOS     &lt;chr&gt; \"Transgresión\", \"Desconfianza institucional\", \"Recursos bá…\n$ RESPUESTA   &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1…"
  },
  {
    "objectID": "archive/2023-10-Unal/crear-tablas.html#información-en-la-base-de-datos",
    "href": "archive/2023-10-Unal/crear-tablas.html#información-en-la-base-de-datos",
    "title": "Crear tablas en R",
    "section": "Información en la base de datos",
    "text": "Información en la base de datos"
  },
  {
    "objectID": "archive/2023-10-Unal/crear-tablas.html#select",
    "href": "archive/2023-10-Unal/crear-tablas.html#select",
    "title": "Crear tablas en R",
    "section": "select()",
    "text": "select()\nEsta función permite seleccionar columnas.\n\ndatos_ley_moral  |&gt; \nselect(SITUACIONES, CODIGOS, RESPUESTA)  |&gt; \nhead(10)  |&gt; \ngt()\n\n\n\n\n\n  \n    \n    \n      SITUACIONES\n      CODIGOS\n      RESPUESTA\n    \n  \n  \n    Daño ambiental\nTransgresión\n0\n    Daño ambiental\nDesconfianza institucional\n0\n    Daño ambiental\nRecursos básicos, necesidades y oportunidades\n0\n    Daño ambiental\nObjetivos personales y conveniencia\n0\n    Daño ambiental\nCreencias y prácticas culturales\n0\n    Daño ambiental\nJustificaciones morales\n0\n    Daño ambiental\nReferencia a la experiencia\n0\n    Daño ambiental\nAutoridad, reglas y consecuencias\n0\n    Daño ambiental\nPrudencial\n0\n    Daño ambiental\nOtros\n1"
  },
  {
    "objectID": "archive/2023-10-Unal/crear-tablas.html#filter",
    "href": "archive/2023-10-Unal/crear-tablas.html#filter",
    "title": "Crear tablas en R",
    "section": "filter()",
    "text": "filter()\nEsta función permite filtrar columnas.\n\ndatos_ley_moral  |&gt; \nselect(SITUACIONES, CODIGOS, RESPUESTA)  |&gt; \nfilter(SITUACIONES == \"Linchamiento\")  |&gt; \nhead(10)  |&gt; \ngt()\n\n\n\n\n\n  \n    \n    \n      SITUACIONES\n      CODIGOS\n      RESPUESTA\n    \n  \n  \n    Linchamiento\nTransgresión\n1\n    Linchamiento\nDesconfianza institucional\n0\n    Linchamiento\nRecursos básicos, necesidades y oportunidades\n0\n    Linchamiento\nObjetivos personales y conveniencia\n0\n    Linchamiento\nCreencias y prácticas culturales\n1\n    Linchamiento\nJustificaciones morales\n0\n    Linchamiento\nReferencia a la experiencia\n0\n    Linchamiento\nAutoridad, reglas y consecuencias\n0\n    Linchamiento\nPrudencial\n0\n    Linchamiento\nOtros\n0"
  },
  {
    "objectID": "archive/2023-10-Unal/crear-tablas.html#mutate",
    "href": "archive/2023-10-Unal/crear-tablas.html#mutate",
    "title": "Crear tablas en R",
    "section": "mutate()",
    "text": "mutate()\nEsta función permite crear o modificar columnas\n\ndatos_ley_moral  |&gt; \nmutate(Edad_años = paste0(EDAD, \" años\"))  |&gt; \nselect(ID, Edad_años) |&gt; \nunique()  |&gt; \nhead(10)  |&gt; \ngt()\n\n\n\n\n\n  \n    \n    \n      ID\n      Edad_años\n    \n  \n  \n    2\n17 años\n    3\n22 años\n    5\n52 años\n    7\n30 años\n    8\n40 años\n    10\n30 años\n    11\n16 años\n    13\n17 años\n    14\n15 años\n    15\n44 años"
  },
  {
    "objectID": "archive/2023-10-Unal/crear-tablas.html#tbl_summary",
    "href": "archive/2023-10-Unal/crear-tablas.html#tbl_summary",
    "title": "Crear tablas en R",
    "section": "tbl_summary()",
    "text": "tbl_summary()\ngtsummary es un paquete que permite crear tablas de resumen de datos. Algunas de sus ventajas son:\n\nPermite crear tablas de resumen de datos con una sintaxis sencilla.\nTablas de resumen para regresiones.\nExportar tablas a varios formatos (Word, PDF, HTML).\nPermite crear tablas con diferentes estilos.\nCalcula estadísticos y p-valores."
  },
  {
    "objectID": "archive/2023-10-Unal/crear-tablas.html#tbl_summary-1",
    "href": "archive/2023-10-Unal/crear-tablas.html#tbl_summary-1",
    "title": "Crear tablas en R",
    "section": "tbl_summary()",
    "text": "tbl_summary()\n\nCalcular la frecuencia y el porcentajes de participantes hombres y mujeres.\n\ndatos_ley_moral  |&gt; \nselect(ID, SEXO)  |&gt; \nunique()  |&gt; \ntbl_summary(include=-ID)\n\n\n\n\n\n\n\n\n  \n    \n    \n      Characteristic\n      N = 531\n    \n  \n  \n    SEXO\n\n        H\n35 (66%)\n        M\n18 (34%)\n  \n  \n  \n    \n      1 n (%)"
  },
  {
    "objectID": "archive/2023-10-Unal/crear-tablas.html#tbl_summary-2",
    "href": "archive/2023-10-Unal/crear-tablas.html#tbl_summary-2",
    "title": "Crear tablas en R",
    "section": "tbl_summary()",
    "text": "tbl_summary()\nCalcular medidas de tendencia y dispersión\n\n\n\ndatos_ley_moral  |&gt; \nselect(ID, EDAD)  |&gt; \nunique()  |&gt; \ntbl_summary(include=EDAD)\n\n\n\n\n\n\n\n\n  \n    \n    \n      Characteristic\n      N = 231\n    \n  \n  \n    EDAD\n29 (23, 45)\n  \n  \n  \n    \n      1 Median (IQR)"
  },
  {
    "objectID": "archive/2023-10-Unal/crear-tablas.html#tbl_summary-3",
    "href": "archive/2023-10-Unal/crear-tablas.html#tbl_summary-3",
    "title": "Crear tablas en R",
    "section": "tbl_summary()",
    "text": "tbl_summary()\nElegir los estadísticos que se muestran en la tabla o el idioma.\n\n\n\ntheme_gtsummary_language(language = \"es\")\n\ndatos_ley_moral  |&gt; \nselect(EDAD)  |&gt; \nunique()  |&gt; \ntbl_summary(\nstatistic = EDAD ~ \"{mean} ({sd})\")\n\n\n\n\n\n\n\n\n  \n    \n    \n      Característica\n      N = 231\n    \n  \n  \n    EDAD\n33 (13)\n  \n  \n  \n    \n      1 Media (DE)"
  },
  {
    "objectID": "archive/2023-10-Unal/crear-tablas.html#tbl_summary-4",
    "href": "archive/2023-10-Unal/crear-tablas.html#tbl_summary-4",
    "title": "Crear tablas en R",
    "section": "tbl_summary()",
    "text": "tbl_summary()\n\n\n\ndatos_ley_moral  |&gt;\ndatos_organizados(\"Justificación de los desenlaces\")  |&gt; \ntbl_summary(include=-c(ID, SITUACIONES, SEXO, EDAD))  \n\n\n\n\n\n  \n    \n    \n      Característica\n      N = 1591\n    \n  \n  \n    Desconfianza institucional\n17 (11%)\n    Recursos básicos, necesidades y oportunidades\n23 (14%)\n    Objetivos personales y conveniencia\n49 (31%)\n    Creencias y prácticas culturales\n50 (31%)\n    Justificaciones morales\n25 (16%)\n    Referencia a la experiencia\n6 (3.8%)\n    Autoridad, reglas y consecuencias\n13 (8.2%)\n    Prudencial\n2 (1.3%)\n    Otros\n7 (4.4%)\n  \n  \n  \n    \n      1 n (%)\n    \n  \n\n\n\n\n\n\ndatos_ley_moral  |&gt;\ndatos_organizados(\"Justificación de los desenlaces\")  |&gt; \nselect(-c(ID, SITUACIONES, SEXO, EDAD)) |&gt; \ntbl_summary()   |&gt; \nmodify_table_body(\n    fun = ~ dplyr::arrange(.x, desc(readr::parse_number(stat_0)))\n  )\n\n\n\n\n\n  \n    \n    \n      Característica\n      N = 1591\n    \n  \n  \n    Creencias y prácticas culturales\n50 (31%)\n    Objetivos personales y conveniencia\n49 (31%)\n    Justificaciones morales\n25 (16%)\n    Recursos básicos, necesidades y oportunidades\n23 (14%)\n    Desconfianza institucional\n17 (11%)\n    Autoridad, reglas y consecuencias\n13 (8.2%)\n    Otros\n7 (4.4%)\n    Referencia a la experiencia\n6 (3.8%)\n    Prudencial\n2 (1.3%)\n  \n  \n  \n    \n      1 n (%)"
  },
  {
    "objectID": "archive/2023-10-Unal/crear-tablas.html#tbl_summary-5",
    "href": "archive/2023-10-Unal/crear-tablas.html#tbl_summary-5",
    "title": "Crear tablas en R",
    "section": "tbl_summary()",
    "text": "tbl_summary()\nLa opción by permite crear tablas por grupos.\n\ndatos_ley_moral  |&gt;\ndatos_organizados(\"Justificación de los desenlaces\")  |&gt; \ntbl_summary(by=SITUACIONES,\ninclude=-c(ID, SEXO, EDAD))  |&gt; \nmodify_table_body(\n    fun = ~ dplyr::arrange(.x, desc(readr::parse_number(stat_1)))\n  )  \n\n\n\n\n\n  \n    \n    \n      Característica\n      Daño ambiental, N = 531\n      Linchamiento, N = 531\n      Narcotráfico, N = 531\n    \n  \n  \n    Objetivos personales y conveniencia\n24 (45%)\n1 (1.9%)\n24 (45%)\n    Autoridad, reglas y consecuencias\n12 (23%)\n0 (0%)\n1 (1.9%)\n    Justificaciones morales\n7 (13%)\n16 (30%)\n2 (3.8%)\n    Creencias y prácticas culturales\n6 (11%)\n30 (57%)\n14 (26%)\n    Referencia a la experiencia\n4 (7.5%)\n1 (1.9%)\n1 (1.9%)\n    Otros\n4 (7.5%)\n2 (3.8%)\n1 (1.9%)\n    Desconfianza institucional\n0 (0%)\n17 (32%)\n0 (0%)\n    Recursos básicos, necesidades y oportunidades\n0 (0%)\n0 (0%)\n23 (43%)\n    Prudencial\n0 (0%)\n0 (0%)\n2 (3.8%)\n  \n  \n  \n    \n      1 n (%)"
  },
  {
    "objectID": "archive/2023-10-Unal/crear-tablas.html#añadir-detalles-a-las-tabla",
    "href": "archive/2023-10-Unal/crear-tablas.html#añadir-detalles-a-las-tabla",
    "title": "Crear tablas en R",
    "section": "Añadir detalles a las tabla",
    "text": "Añadir detalles a las tabla\n\ndatos_ley_moral  |&gt;\ndatos_organizados(\"Justificación de los juicios\")  |&gt; \ntbl_summary(\n    by = SITUACIONES,\n    include=-c(ID, SEXO, EDAD))   |&gt; \n     modify_table_body(\n    fun = ~ dplyr::arrange(.x, desc(readr::parse_number(stat_1)))\n  )  |&gt;\n    modify_header(\n        label= \"**Justificación de los juicios**\"\n    )"
  },
  {
    "objectID": "archive/2023-10-Unal/crear-tablas.html#añadir-detalles-a-las-tabla-1",
    "href": "archive/2023-10-Unal/crear-tablas.html#añadir-detalles-a-las-tabla-1",
    "title": "Crear tablas en R",
    "section": "Añadir detalles a las tabla",
    "text": "Añadir detalles a las tabla\n\n\n\n\n\n\n  \n    \n    \n      Justificación de los juicios\n      Daño ambiental, N = 531\n      Linchamiento, N = 531\n      Narcotráfico, N = 531\n    \n  \n  \n    Justificaciones morales\n51 (96%)\n33 (62%)\n16 (30%)\n    Autoridad, reglas y consecuencias\n2 (3.8%)\n22 (42%)\n23 (43%)\n    Prudencial\n2 (3.8%)\n0 (0%)\n23 (43%)\n    Otros\n2 (3.8%)\n0 (0%)\n4 (7.5%)\n    Recursos básicos, necesidades y oportunidades\n0 (0%)\n2 (3.8%)\n9 (17%)\n    Objetivos personales y conveniencia\n0 (0%)\n0 (0%)\n0 (0%)\n    Creencias y prácticas culturales\n0 (0%)\n0 (0%)\n0 (0%)\n    Desconfianza institucional\n0 (0%)\n12 (23%)\n0 (0%)\n  \n  \n  \n    \n      1 n (%)"
  },
  {
    "objectID": "archive/2023-10-Unal/crear-tablas.html#añadir-detalles-a-las-tabla-2",
    "href": "archive/2023-10-Unal/crear-tablas.html#añadir-detalles-a-las-tabla-2",
    "title": "Crear tablas en R",
    "section": "Añadir detalles a las tabla",
    "text": "Añadir detalles a las tabla\n\ndatos_ley_moral  |&gt;\ndatos_organizados(\"Justificación de los juicios\")  |&gt; \ntbl_summary(\n    by = SITUACIONES,\n    include=-c(ID, SEXO, EDAD))   |&gt; \n     add_overall()  |&gt; \n     modify_table_body(\n    fun = ~ dplyr::arrange(.x, desc(readr::parse_number(stat_0)))\n  )  |&gt;\n    modify_header(\n        label= \"**Justificación de los juicios**\"\n    )  \n\n\n\n\n\n  \n    \n    \n      Justificación de los juicios\n      Global, N = 1591\n      Daño ambiental, N = 531\n      Linchamiento, N = 531\n      Narcotráfico, N = 531\n    \n  \n  \n    Justificaciones morales\n100 (63%)\n51 (96%)\n33 (62%)\n16 (30%)\n    Autoridad, reglas y consecuencias\n47 (30%)\n2 (3.8%)\n22 (42%)\n23 (43%)\n    Prudencial\n25 (16%)\n2 (3.8%)\n0 (0%)\n23 (43%)\n    Desconfianza institucional\n12 (7.5%)\n0 (0%)\n12 (23%)\n0 (0%)\n    Recursos básicos, necesidades y oportunidades\n11 (6.9%)\n0 (0%)\n2 (3.8%)\n9 (17%)\n    Otros\n6 (3.8%)\n2 (3.8%)\n0 (0%)\n4 (7.5%)\n    Objetivos personales y conveniencia\n0 (0%)\n0 (0%)\n0 (0%)\n0 (0%)\n    Creencias y prácticas culturales\n0 (0%)\n0 (0%)\n0 (0%)\n0 (0%)\n  \n  \n  \n    \n      1 n (%)"
  },
  {
    "objectID": "archive/2023-10-Unal/crear-tablas.html#add_p-value",
    "href": "archive/2023-10-Unal/crear-tablas.html#add_p-value",
    "title": "Crear tablas en R",
    "section": "Add_p value",
    "text": "Add_p value\n\ndatos_ley_moral  |&gt;\ndatos_organizados(\"Justificación de los juicios\")  |&gt; \ntbl_summary(\n    by = SITUACIONES,\n    include=-c(ID, SEXO, EDAD))   |&gt; \n     add_overall()  |&gt; \n     modify_table_body(\n    fun = ~ dplyr::arrange(.x, desc(readr::parse_number(stat_0)))\n  )  |&gt;\n    modify_header(\n        label= \"**Justificación de los juicios**\"\n    )   |&gt; \n    add_p()\n\n\n\n\n\n  \n    \n    \n      Justificación de los juicios\n      Global, N = 1591\n      Daño ambiental, N = 531\n      Linchamiento, N = 531\n      Narcotráfico, N = 531\n      p-valor2\n    \n  \n  \n    Justificaciones morales\n100 (63%)\n51 (96%)\n33 (62%)\n16 (30%)\n&lt;0.001\n    Autoridad, reglas y consecuencias\n47 (30%)\n2 (3.8%)\n22 (42%)\n23 (43%)\n&lt;0.001\n    Prudencial\n25 (16%)\n2 (3.8%)\n0 (0%)\n23 (43%)\n&lt;0.001\n    Desconfianza institucional\n12 (7.5%)\n0 (0%)\n12 (23%)\n0 (0%)\n&lt;0.001\n    Recursos básicos, necesidades y oportunidades\n11 (6.9%)\n0 (0%)\n2 (3.8%)\n9 (17%)\n0.001\n    Otros\n6 (3.8%)\n2 (3.8%)\n0 (0%)\n4 (7.5%)\n0.2\n    Objetivos personales y conveniencia\n0 (0%)\n0 (0%)\n0 (0%)\n0 (0%)\n\n    Creencias y prácticas culturales\n0 (0%)\n0 (0%)\n0 (0%)\n0 (0%)\n\n  \n  \n  \n    \n      1 n (%)\n    \n    \n      2 prueba chi cuadrado de independencia; test exacto de Fisher"
  },
  {
    "objectID": "archive/2023-10-Unal/crear-tablas.html#escalas-gravedad-y-castigo",
    "href": "archive/2023-10-Unal/crear-tablas.html#escalas-gravedad-y-castigo",
    "title": "Crear tablas en R",
    "section": "Escalas gravedad y castigo",
    "text": "Escalas gravedad y castigo\n\n\n\n\n\n\n  \n    \n    \n      Característica\n      Global, N = 1591\n      Daño ambiental, N = 531\n      Linchamiento, N = 531\n      Narcotráfico, N = 531\n    \n  \n  \n    Escala de gravedad\n\n\n\n\n        1\n5 (3.1%)\n0 (0%)\n4 (7.5%)\n1 (1.9%)\n        2\n6 (3.8%)\n0 (0%)\n4 (7.5%)\n2 (3.8%)\n        3\n20 (13%)\n1 (1.9%)\n9 (17%)\n10 (19%)\n        4\n29 (18%)\n5 (9.4%)\n11 (21%)\n13 (25%)\n        5\n99 (62%)\n47 (89%)\n25 (47%)\n27 (51%)\n    Escala de castigo\n\n\n\n\n        1\n11 (6.9%)\n0 (0%)\n7 (13%)\n4 (7.5%)\n        2\n10 (6.3%)\n0 (0%)\n7 (13%)\n3 (5.7%)\n        3\n46 (29%)\n3 (5.7%)\n15 (28%)\n28 (53%)\n        4\n38 (24%)\n16 (30%)\n14 (26%)\n8 (15%)\n        5\n54 (34%)\n34 (64%)\n10 (19%)\n10 (19%)\n  \n  \n  \n    \n      1 n (%)"
  },
  {
    "objectID": "archive/2023-10-Unal/crear-tablas.html#escalas-gravedad-y-castigo-1",
    "href": "archive/2023-10-Unal/crear-tablas.html#escalas-gravedad-y-castigo-1",
    "title": "Crear tablas en R",
    "section": "Escalas gravedad y castigo",
    "text": "Escalas gravedad y castigo\n\ndatos_ley_moral  |&gt; \ndatos_organizados(\"Escalas gravedad y castigo\")   |&gt; \nfilter(SITUACIONES %in% c(\"Linchamiento\", \"Narcotráfico\"))  |&gt; \ntbl_summary(\n    by = SITUACIONES,\n    include=-c(ID, SEXO, EDAD),\n    type= list(`Escala de gravedad` ~ \"continuous\", \n    `Escala de castigo` ~ \"continuous\"), \n    statistic = all_continuous() ~ \"{mean}, ({sd})\")   |&gt; \n    add_p(test = list(\n          all_continuous() ~ \"paired.wilcox.test\"),\n        group = ID)  \n\n\n\n\n\n  \n    \n    \n      Característica\n      Linchamiento, N = 531\n      Narcotráfico, N = 531\n      p-valor2\n    \n  \n  \n    Escala de gravedad\n3.92, (1.28)\n4.19, (1.00)\n0.2\n    Escala de castigo\n3.25, (1.28)\n3.32, (1.09)\n0.7\n  \n  \n  \n    \n      1 Media, (DE)\n    \n    \n      2 Wilcoxon signed rank test with continuity correction"
  },
  {
    "objectID": "archive/2023-10-Unal/crear-tablas.html#tablas-para-regresiones",
    "href": "archive/2023-10-Unal/crear-tablas.html#tablas-para-regresiones",
    "title": "Crear tablas en R",
    "section": "Tablas para regresiones",
    "text": "Tablas para regresiones\n\ndatos_ley_moral  |&gt; \n    datos_organizados(\"Escalas gravedad y castigo\")   |&gt; \n    filter(SITUACIONES %in% c(\"Linchamiento\", \"Narcotráfico\"))  %&gt;% \n    lm(`Escala de gravedad` ~ EDAD + SEXO + SITUACIONES, data = .)  \n\n\nCall:\nlm(formula = `Escala de gravedad` ~ EDAD + SEXO + SITUACIONES, \n    data = .)\n\nCoefficients:\n            (Intercept)                     EDAD                    SEXOM  \n               3.835985                 0.001162                 0.163164  \nSITUACIONESNarcotráfico  \n               0.264151  \n\n\nLa función lm() genera un resultado como este:\n\n\n\nCall:\nlm(formula = `Escala de gravedad` ~ EDAD + SEXO + SITUACIONES, \n    data = .)\n\nCoefficients:\n            (Intercept)                     EDAD                    SEXOM  \n               3.835985                 0.001162                 0.163164  \nSITUACIONESNarcotráfico  \n               0.264151"
  },
  {
    "objectID": "archive/2023-10-Unal/crear-tablas.html#tablas-para-regresiones-1",
    "href": "archive/2023-10-Unal/crear-tablas.html#tablas-para-regresiones-1",
    "title": "Crear tablas en R",
    "section": "Tablas para regresiones",
    "text": "Tablas para regresiones\n\ndatos_ley_moral  |&gt; \n    datos_organizados(\"Escalas gravedad y castigo\")   |&gt; \n    filter(SITUACIONES %in% c(\"Linchamiento\", \"Narcotráfico\"))  %&gt;% \n    lm(`Escala de gravedad` ~ EDAD + SEXO + SITUACIONES, data = .)  |&gt; \n    tbl_regression()\n\n\n\n\n\n  \n    \n    \n      Característica\n      Beta\n      95% CI1\n      p-valor\n    \n  \n  \n    EDAD\n0.00\n-0.02, 0.02\n0.9\n    SEXO\n\n\n\n        H\n—\n—\n\n        M\n0.16\n-0.31, 0.64\n0.5\n    SITUACIONES\n\n\n\n        Linchamiento\n—\n—\n\n        Narcotráfico\n0.26\n-0.18, 0.71\n0.2\n  \n  \n  \n    \n      1 CI = Intervalo de confianza"
  },
  {
    "objectID": "archive/2023-10-Unal/crear-tablas.html#exportar-a-tablas-a-word",
    "href": "archive/2023-10-Unal/crear-tablas.html#exportar-a-tablas-a-word",
    "title": "Crear tablas en R",
    "section": "Exportar a tablas a word",
    "text": "Exportar a tablas a word\n\ntabla_gravedad_y_castigo &lt;- datos_ley_moral  |&gt; \ndatos_organizados(\"Escalas gravedad y castigo\")   |&gt; \nfilter(SITUACIONES %in% c(\"Linchamiento\", \"Narcotráfico\"))  |&gt; \ntbl_summary(\n    by = SITUACIONES,\n    include=-c(ID, SEXO, EDAD),\n    type= list(`Escala de gravedad` ~ \"continuous\", \n    `Escala de castigo` ~ \"continuous\"), \n    statistic = all_continuous() ~ \"{mean}, ({sd})\")   |&gt; \n    add_p(test = list(\n          all_continuous() ~ \"paired.wilcox.test\"),\n        group = ID)    |&gt; \n        as_gt()\n\ngt::gtsave(tabla_gravedad_y_castigo, \"tabla_gravedad_y_castigo.docx\")"
  },
  {
    "objectID": "archive/2023-11-icfes/1-introduccion.html#temas",
    "href": "archive/2023-11-icfes/1-introduccion.html#temas",
    "title": "1 - Introducción a Machine Learning",
    "section": "Temas",
    "text": "Temas\n\n\n\nTipos de modelos\n\nDescriptivo\nInferencial\nPredictivo\n\nMachine Learning - Supervised\n\nClasificación\nRegresión - Unsupervised\nClustering\n\nEquilibrio entre la varianza y el sesgo\nValidación Cruzada\n\n\n\nEvaluación de los Modelos - Separación entrenamiento y prueba - Remuestreo\n\nLeave One Out\nK-Fold\nBoostraping"
  },
  {
    "objectID": "archive/2023-11-icfes/1-introduccion.html#tipos-de-modelos",
    "href": "archive/2023-11-icfes/1-introduccion.html#tipos-de-modelos",
    "title": "1 - Introducción a Machine Learning",
    "section": "Tipos de modelos",
    "text": "Tipos de modelos\n\nDescriptivosInferencialPredictivo\n\n\n\nDescribir las características de unos datos\nVisualizar los datos\nResumir los datos\nGenerar hipótesis\n\n\n\n\nEstimar la probabilidad de que ocurra un evento\nProducir una estimación de un parámetro poblacional\nProbar una hipótesis\nIdea predeterminada y se prueba\nValor p, intervalo de confianza\n\n\n\n\nAnticipar el valor de una variable\nAplicar una regla a un evento que no ha ocurrido\nMayor interés en la predicción que en la inferencia\nPuede ser que no importe el mecanismo"
  },
  {
    "objectID": "archive/2023-11-icfes/1-introduccion.html#machine-learning",
    "href": "archive/2023-11-icfes/1-introduccion.html#machine-learning",
    "title": "1 - Introducción a Machine Learning",
    "section": "Machine Learning",
    "text": "Machine Learning\nAlgunos de los modelos que se pueden construir con Machine Learning, van a ser fundamentalmente modelos para predecir. Por ejemplo:\n\nk-Nearest Neighbors\nRandom Forests\nSupport Vector Machines"
  },
  {
    "objectID": "archive/2023-11-icfes/1-introduccion.html#machine-learning-1",
    "href": "archive/2023-11-icfes/1-introduccion.html#machine-learning-1",
    "title": "1 - Introducción a Machine Learning",
    "section": "Machine Learning",
    "text": "Machine Learning\n\nMachine LearningUnsupervisedSupervised\n\n\n\n\n\nNo hay una variable de resultado\n\nComponentes principales\n\n\n\n\nHay una variable de resultado\n\nRegresión: variable de resultado continua\nClasificación: variable de resultado categórica"
  },
  {
    "objectID": "archive/2023-11-icfes/1-introduccion.html#el-proceso-del-análisis-de-datos-en-machine-learning",
    "href": "archive/2023-11-icfes/1-introduccion.html#el-proceso-del-análisis-de-datos-en-machine-learning",
    "title": "1 - Introducción a Machine Learning",
    "section": "El proceso del análisis de datos en Machine Learning",
    "text": "El proceso del análisis de datos en Machine Learning"
  },
  {
    "objectID": "archive/2023-11-icfes/1-introduccion.html#proceso-de-análisis-de-datos",
    "href": "archive/2023-11-icfes/1-introduccion.html#proceso-de-análisis-de-datos",
    "title": "1 - Introducción a Machine Learning",
    "section": "Proceso de análisis de datos",
    "text": "Proceso de análisis de datos\n\n\n\nExplorar los datos (EDA)\n“Ingeniería de variables”- crear nuevas variables\nAjustar-sintonizar los modelos\nEvaluar los modelos"
  },
  {
    "objectID": "archive/2023-11-icfes/1-introduccion.html#tres-ideas-importantes-de-machine-learning",
    "href": "archive/2023-11-icfes/1-introduccion.html#tres-ideas-importantes-de-machine-learning",
    "title": "1 - Introducción a Machine Learning",
    "section": "Tres ideas importantes de Machine Learning",
    "text": "Tres ideas importantes de Machine Learning\n\n\nUtilizar la muestra para estimar el error de generalización\nDescomponer el error en tres fuentes: varianza, sesgo y ruido.\nRegularización para controlar la varianza y el sesgo"
  },
  {
    "objectID": "archive/2023-11-icfes/1-introduccion.html#cuál-es-el-mejor-sofware-para-hacer-esto",
    "href": "archive/2023-11-icfes/1-introduccion.html#cuál-es-el-mejor-sofware-para-hacer-esto",
    "title": "1 - Introducción a Machine Learning",
    "section": "¿Cuál es el mejor sofware para hacer esto?",
    "text": "¿Cuál es el mejor sofware para hacer esto?\n\n\n\nPython\nR\nJulia\nMatlab\nProgramas\n\nMplus\nStata\nSAS\nSPSS"
  },
  {
    "objectID": "archive/2023-11-icfes/1-introduccion.html#tidyverse",
    "href": "archive/2023-11-icfes/1-introduccion.html#tidyverse",
    "title": "1 - Introducción a Machine Learning",
    "section": "Tidyverse",
    "text": "Tidyverse\n\n\nggplot2 - para visualización de gráficos\ndplyr - para el procesamiento de datos\ntidyr - para la transformación de datos en formato “tidy” (ordenado)\nreadr - para la lectura de datos en diferentes formatos (CSV, TSV, etc.)\npurrr - para la programación funcional\ntibble - para la creación de data frames en formato “tidy”\nstringr - para la manipulación de cadenas de texto\nforcats- para la manipulación de factores"
  },
  {
    "objectID": "archive/2023-11-icfes/1-introduccion.html#tidyverse-1",
    "href": "archive/2023-11-icfes/1-introduccion.html#tidyverse-1",
    "title": "1 - Introducción a Machine Learning",
    "section": "Tidyverse",
    "text": "Tidyverse\n\nEstilo\n\nPipe\nnombre_de_los_objetos\nUso de las comillas\nRetorna un objeto de la misma clase\nProgramación funcional\n\n\n\n\n\nMachine Learning"
  },
  {
    "objectID": "archive/2023-11-icfes/index.html",
    "href": "archive/2023-11-icfes/index.html",
    "title": "Taller Introducción a Machine Learning en el 14° Seminario Internacional de Investigación sobre la Calidad de la Educación - SiiCE",
    "section": "",
    "text": "Este taller se llevará a cabo durante el 14° Seminario Internacional de Investigación sobre la Calidad de la Educación - SiiCE. En este taller se presentarán los conceptos básicos de Machine Learning y se realizarán ejercicios prácticos en R. El taller está dirigido a investigadores y estudiantes interesados en aprender sobre Machine Learning y su aplicación en la investigación educativa."
  },
  {
    "objectID": "archive/2023-11-icfes/index.html#organizadores",
    "href": "archive/2023-11-icfes/index.html#organizadores",
    "title": "Taller Introducción a Machine Learning en el 14° Seminario Internacional de Investigación sobre la Calidad de la Educación - SiiCE",
    "section": "Organizadores",
    "text": "Organizadores\nFrancisco Cardozo. Universidad de Miami. Eric C. Brown. Universidad de Miami."
  },
  {
    "objectID": "archive/2023-12-um/workshop_document.html",
    "href": "archive/2023-12-um/workshop_document.html",
    "title": "Imbalanced data in Machine Learning Modeling",
    "section": "",
    "text": "library(tidymodels)\nlibrary(gt)\nlibrary(dataUMworkshop)\ntidymodels_prefer()\n\n\n\nThere are many ways to estimate models in R\n\nlm(formula, data, ...)\nstan_glm(formula, data, family= \"gaussian\",...)\nglmnet(x=matrix, y=vector, family=\"gaussian\",...)\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nlibrary(): Load the tidymodels package into R.\ntidymodels_prefer(): Sets the tidymodels package as the preferred one for modeling functions in R.\nlm(): Fits a linear regression model to the data.\nstan_glm(): Fits a regression model using the stan package.\nglmnet(): Fits a regression model using Lasso or Ridge regularization.\n\n\n\nTidymodels provides a general syntax for estimating models\n\nSpecify the type of model\n\nlinear_reg(), logistic_reg(), decision_tree()\n\nSpecify the type of outcome\n\nRegression for continuous outcomes\nClassification: multinomial, ordinal, binary\n\n\n\nlinear_reg() |&gt;\n  set_engine(\"lm\")\n\nlinear_reg() |&gt;\n  set_engine(\"glmnet\")\n\nlinear_reg() |&gt;\n  set_engine(\"stan\")\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nlinear_reg(): Creates a linear regression model specification in the tidymodels framework.\nset_engine(): Sets the calculation engine for a model specification object. It is set to “lm” for the first call to linear_reg(), “glmnet” for the second call, and “stan” for the third.\n\n\n\nTo estimate a model:\n\n\n\n\nlm_model &lt;-\n  logistic_reg() %&gt;%\n  set_engine(\"glm\", family = \"binomial\") |&gt;\n  set_mode(\"classification\")\n\nSpecify a logistic regression model. Additionally, the modeling mode is set to “classification” to indicate that it is a categorical variable. The result is stored in the lm_model object.\n\n\n\n\n\n\n\n\n\nTip\n\n\n\n\n\n\ndata(dataUMworkshop)\n# The outcome variable is specified as a factor\nthe_data &lt;- dataUMworkshop |&gt;\n  select(-outcome_count) |&gt;\n  mutate(outcome = factor(outcome)) |&gt;\n  rename(P200 = P2)\n\n\n\n\n\nlm_results &lt;- lm_model |&gt;\n  fit(outcome ~ ., data = the_data)\n\nHere the model is fitted-estimated using the fit() function. The response variable (outcome) and the predictors (.) are specified and the the_data object is used as a database.\n\n\n\n\nlm_results |&gt; tidy()\n\n# A tibble: 41 × 5\n   term        estimate std.error statistic    p.value\n   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;      &lt;dbl&gt;\n 1 (Intercept)  -0.851     1.10      -0.773 0.440     \n 2 P2001        -2.08      0.546     -3.81  0.000141  \n 3 P2002         0.754     0.272      2.77  0.00553   \n 4 P2003        -1.44      0.320     -4.49  0.00000707\n 5 P2004        -0.142     0.281     -0.507 0.612     \n 6 P2005        -0.0850    0.445     -0.191 0.849     \n 7 P3           -0.0153    0.0118    -1.30  0.192     \n 8 P4            0.0137    0.0205     0.670 0.503     \n 9 P13          -0.388     0.186     -2.08  0.0374    \n10 P142         -0.209     0.382     -0.546 0.585     \n# ℹ 31 more rows\n\nlm_results |&gt;\n  glance() |&gt;\n  gt()\n\n\n\n\n\n  \n    \n    \n      null.deviance\n      df.null\n      logLik\n      AIC\n      BIC\n      deviance\n      df.residual\n      nobs\n    \n  \n  \n    1356.908\n1375\n-573.3018\n1228.604\n1442.908\n1146.604\n1335\n1376\n  \n  \n  \n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\n\n\n\ntidy(): This function is used to convert the results of a model into a “tidy” data frame that displays the model coefficients, standard errors, t-values, and p-values for each independent variable.\nglance(): This function is used to summarize the results of a model as global model statistics, for example, adjusted R-squared, the AIC, and the BIC.\n\n\nlm_results |&gt; tidy(exp = TRUE, conf.int = TRUE)\n\ntidy(exp=TRUE, conf.int=TRUE): This function is used to convert the results of a model into a “tidy” data frame that displays the model coefficients, standard errors, t-values, and t-values. p for each independent variable. The exp and conf.int arguments are used to include confidence intervals and exponents in the results\n\n\n\n\n\n\nAccuracy: This is how often the model makes correct predictions. It’s a simple ratio of the number of correct predictions to the total number of predictions.\nSensitivity: Also known as “True Positive Rate.” It measures how well the model identifies positive outcomes. In other words, it’s the percentage of actual positives that the model correctly predicts.\nSpecificity: Also known as “True Negative Rate.” This is about how well the model identifies negative outcomes. It tells us the percentage of actual negatives that the model correctly predicts.\nPrecision: This tells us how many of the model’s positive predictions are actually correct. It’s a ratio of true positive predictions to all positive predictions (including false positives).\nRecall: This is the same as sensitivity. It’s about how many of the actual positive cases the model can correctly identify.\nF-measure: This score combines precision and recall into a single number. It helps balance the trade-off between these two metrics. A higher F-measure means better model performance.\nKappa Coefficient: Kappa is about how much better the model is than random guessing. It compares the model’s accuracy with what would be expected by chance. A higher Kappa means the model is much better than just guessing.\n\n\naugmented_results &lt;- lm_results |&gt;\n  augment(the_data)\n\naccuracy(augmented_results,\n  truth = outcome,\n  estimate = .pred_class\n) |&gt; pretty_table()\n\n\n\n\n\n  \n    \n    \n      Metric\n      Estimate\n    \n  \n  \n    Accuracy\n0.818\n  \n  \n  \n\n\n\nsens(augmented_results,\n  truth = outcome,\n  estimate = .pred_class,\n  event_level = \"second\"\n) |&gt; pretty_table()\n\n\n\n\n\n  \n    \n    \n      Metric\n      Estimate\n    \n  \n  \n    Sensitivity\n0.179\n  \n  \n  \n\n\n\nspec(augmented_results,\n  truth = outcome,\n  estimate = .pred_class,\n  event_level = \"second\"\n) |&gt; pretty_table()\n\n\n\n\n\n  \n    \n    \n      Metric\n      Estimate\n    \n  \n  \n    Specificity\n0.972\n  \n  \n  \n\n\n\nf_meas(augmented_results,\n  truth = outcome,\n  estimate = .pred_class,\n  event_level = \"second\"\n) |&gt; pretty_table()\n\n\n\n\n\n  \n    \n    \n      Metric\n      Estimate\n    \n  \n  \n    F1\n0.277"
  },
  {
    "objectID": "archive/2023-12-um/workshop_document.html#estimating-a-model-in-r",
    "href": "archive/2023-12-um/workshop_document.html#estimating-a-model-in-r",
    "title": "Imbalanced data in Machine Learning Modeling",
    "section": "",
    "text": "There are many ways to estimate models in R\n\nlm(formula, data, ...)\nstan_glm(formula, data, family= \"gaussian\",...)\nglmnet(x=matrix, y=vector, family=\"gaussian\",...)\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nlibrary(): Load the tidymodels package into R.\ntidymodels_prefer(): Sets the tidymodels package as the preferred one for modeling functions in R.\nlm(): Fits a linear regression model to the data.\nstan_glm(): Fits a regression model using the stan package.\nglmnet(): Fits a regression model using Lasso or Ridge regularization.\n\n\n\nTidymodels provides a general syntax for estimating models\n\nSpecify the type of model\n\nlinear_reg(), logistic_reg(), decision_tree()\n\nSpecify the type of outcome\n\nRegression for continuous outcomes\nClassification: multinomial, ordinal, binary\n\n\n\nlinear_reg() |&gt;\n  set_engine(\"lm\")\n\nlinear_reg() |&gt;\n  set_engine(\"glmnet\")\n\nlinear_reg() |&gt;\n  set_engine(\"stan\")\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nlinear_reg(): Creates a linear regression model specification in the tidymodels framework.\nset_engine(): Sets the calculation engine for a model specification object. It is set to “lm” for the first call to linear_reg(), “glmnet” for the second call, and “stan” for the third.\n\n\n\nTo estimate a model:"
  },
  {
    "objectID": "archive/2023-12-um/workshop_document.html#specify-the-model",
    "href": "archive/2023-12-um/workshop_document.html#specify-the-model",
    "title": "Imbalanced data in Machine Learning Modeling",
    "section": "",
    "text": "lm_model &lt;-\n  logistic_reg() %&gt;%\n  set_engine(\"glm\", family = \"binomial\") |&gt;\n  set_mode(\"classification\")\n\nSpecify a logistic regression model. Additionally, the modeling mode is set to “classification” to indicate that it is a categorical variable. The result is stored in the lm_model object."
  },
  {
    "objectID": "archive/2023-12-um/workshop_document.html#estimate-the-model",
    "href": "archive/2023-12-um/workshop_document.html#estimate-the-model",
    "title": "Imbalanced data in Machine Learning Modeling",
    "section": "",
    "text": "Tip\n\n\n\n\n\n\ndata(dataUMworkshop)\n# The outcome variable is specified as a factor\nthe_data &lt;- dataUMworkshop |&gt;\n  select(-outcome_count) |&gt;\n  mutate(outcome = factor(outcome)) |&gt;\n  rename(P200 = P2)\n\n\n\n\n\nlm_results &lt;- lm_model |&gt;\n  fit(outcome ~ ., data = the_data)\n\nHere the model is fitted-estimated using the fit() function. The response variable (outcome) and the predictors (.) are specified and the the_data object is used as a database."
  },
  {
    "objectID": "archive/2023-12-um/workshop_document.html#check-the-model-results",
    "href": "archive/2023-12-um/workshop_document.html#check-the-model-results",
    "title": "Imbalanced data in Machine Learning Modeling",
    "section": "",
    "text": "lm_results |&gt; tidy()\n\n# A tibble: 41 × 5\n   term        estimate std.error statistic    p.value\n   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;      &lt;dbl&gt;\n 1 (Intercept)  -0.851     1.10      -0.773 0.440     \n 2 P2001        -2.08      0.546     -3.81  0.000141  \n 3 P2002         0.754     0.272      2.77  0.00553   \n 4 P2003        -1.44      0.320     -4.49  0.00000707\n 5 P2004        -0.142     0.281     -0.507 0.612     \n 6 P2005        -0.0850    0.445     -0.191 0.849     \n 7 P3           -0.0153    0.0118    -1.30  0.192     \n 8 P4            0.0137    0.0205     0.670 0.503     \n 9 P13          -0.388     0.186     -2.08  0.0374    \n10 P142         -0.209     0.382     -0.546 0.585     \n# ℹ 31 more rows\n\nlm_results |&gt;\n  glance() |&gt;\n  gt()\n\n\n\n\n\n  \n    \n    \n      null.deviance\n      df.null\n      logLik\n      AIC\n      BIC\n      deviance\n      df.residual\n      nobs\n    \n  \n  \n    1356.908\n1375\n-573.3018\n1228.604\n1442.908\n1146.604\n1335\n1376\n  \n  \n  \n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\n\n\n\ntidy(): This function is used to convert the results of a model into a “tidy” data frame that displays the model coefficients, standard errors, t-values, and p-values for each independent variable.\nglance(): This function is used to summarize the results of a model as global model statistics, for example, adjusted R-squared, the AIC, and the BIC.\n\n\nlm_results |&gt; tidy(exp = TRUE, conf.int = TRUE)\n\ntidy(exp=TRUE, conf.int=TRUE): This function is used to convert the results of a model into a “tidy” data frame that displays the model coefficients, standard errors, t-values, and t-values. p for each independent variable. The exp and conf.int arguments are used to include confidence intervals and exponents in the results"
  },
  {
    "objectID": "archive/2023-12-um/workshop_document.html#metrics-to-evaluate-the-model",
    "href": "archive/2023-12-um/workshop_document.html#metrics-to-evaluate-the-model",
    "title": "Imbalanced data in Machine Learning Modeling",
    "section": "",
    "text": "Accuracy: This is how often the model makes correct predictions. It’s a simple ratio of the number of correct predictions to the total number of predictions.\nSensitivity: Also known as “True Positive Rate.” It measures how well the model identifies positive outcomes. In other words, it’s the percentage of actual positives that the model correctly predicts.\nSpecificity: Also known as “True Negative Rate.” This is about how well the model identifies negative outcomes. It tells us the percentage of actual negatives that the model correctly predicts.\nPrecision: This tells us how many of the model’s positive predictions are actually correct. It’s a ratio of true positive predictions to all positive predictions (including false positives).\nRecall: This is the same as sensitivity. It’s about how many of the actual positive cases the model can correctly identify.\nF-measure: This score combines precision and recall into a single number. It helps balance the trade-off between these two metrics. A higher F-measure means better model performance.\nKappa Coefficient: Kappa is about how much better the model is than random guessing. It compares the model’s accuracy with what would be expected by chance. A higher Kappa means the model is much better than just guessing.\n\n\naugmented_results &lt;- lm_results |&gt;\n  augment(the_data)\n\naccuracy(augmented_results,\n  truth = outcome,\n  estimate = .pred_class\n) |&gt; pretty_table()\n\n\n\n\n\n  \n    \n    \n      Metric\n      Estimate\n    \n  \n  \n    Accuracy\n0.818\n  \n  \n  \n\n\n\nsens(augmented_results,\n  truth = outcome,\n  estimate = .pred_class,\n  event_level = \"second\"\n) |&gt; pretty_table()\n\n\n\n\n\n  \n    \n    \n      Metric\n      Estimate\n    \n  \n  \n    Sensitivity\n0.179\n  \n  \n  \n\n\n\nspec(augmented_results,\n  truth = outcome,\n  estimate = .pred_class,\n  event_level = \"second\"\n) |&gt; pretty_table()\n\n\n\n\n\n  \n    \n    \n      Metric\n      Estimate\n    \n  \n  \n    Specificity\n0.972\n  \n  \n  \n\n\n\nf_meas(augmented_results,\n  truth = outcome,\n  estimate = .pred_class,\n  event_level = \"second\"\n) |&gt; pretty_table()\n\n\n\n\n\n  \n    \n    \n      Metric\n      Estimate\n    \n  \n  \n    F1\n0.277"
  },
  {
    "objectID": "archive/2023-12-um/workshop_document.html#split-the-data",
    "href": "archive/2023-12-um/workshop_document.html#split-the-data",
    "title": "Imbalanced data in Machine Learning Modeling",
    "section": "Split the data",
    "text": "Split the data\n\nSplit the data into two sets\n\nTraining\n\nMost of the data (70%, 80%?)\nHere the model is adjusted\n\nTest\n\nA small data set\nHere the final model will be evaluated\n\n\n\nTest data is used only once, if it is used more than once it becomes part of the training process.\n\n\n\n\n\n\nWarning\n\n\n\nThe division of the data is done at the level of the independent unit of observation.\nAvoid contamination of test data (information leakage) at all costs, that is, information cannot be leaked from one database to the other.\n\n\nSo, one can create two databases with for example 80% and 20% of the data. But how do you do this in R?\n\nset.seed(193945)\n\nsplit_data &lt;- initial_split(the_data, prop = 0.8, strata = \"outcome\")\n\ntraining_data &lt;- training(split_data)\ntest_data &lt;- testing(split_data)\n\nThe strata option is so that the training and test data have the same distribution of the variable score\nSometimes random sample selection is not simple, for example when there is a time component to the data.\n\n\n\n\n\n\nTip\n\n\n\n\n\nset.seed() - Used to set a seed for random number generation in R. In this case, it is used to set the seed to 193945, ensuring that the results are reproducible. This is especially important when working with machine learning models, as results can vary depending on the seed used for random number generation.\ninitial_split(): This function is used to split a data frame into training and test sets. In this case, it is used to split the “the_data” object into training and test sets in an 80/20 ratio, and stratifying by the “outcome” column.\ntraining(): This function is used to extract the training set from an object created with the initial_split() function. In this case, it is used to extract the training set from the “split_data” object.\ntesting(): This function is used to extract the test set from an object created with the initial_split() function. In this case, it is used to extract the test set from the “split_data” object.\n\n\n\nNow, we can repeat the previous model estimation steps, but we will use the training data."
  },
  {
    "objectID": "archive/2023-12-um/workshop_document.html#estimate-the-model-1",
    "href": "archive/2023-12-um/workshop_document.html#estimate-the-model-1",
    "title": "Imbalanced data in Machine Learning Modeling",
    "section": "2. Estimate the model",
    "text": "2. Estimate the model\nModel Estimation: The lm_model() and fit() function is used to fit a linear regression model. The outcome ~ . indicates that the score variable is being modeled as a function of all the other variables in the “training_data” dataframe.\n\nlm_results &lt;- lm_model |&gt;\n  fit(outcome ~ ., data = training_data)"
  },
  {
    "objectID": "archive/2023-12-um/workshop_document.html#model-results",
    "href": "archive/2023-12-um/workshop_document.html#model-results",
    "title": "Imbalanced data in Machine Learning Modeling",
    "section": "3. Model results",
    "text": "3. Model results\nView model results: The tidy function is used to obtain a clean and tidy summary of the model results.\n\nlm_results |&gt;\n  tidy()\n\n# A tibble: 41 × 5\n   term        estimate std.error statistic     p.value\n   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;       &lt;dbl&gt;\n 1 (Intercept) -0.244      1.22      -0.199 0.842      \n 2 P2001       -1.98       0.555     -3.56  0.000368   \n 3 P2002        0.696      0.300      2.32  0.0204     \n 4 P2003       -2.02       0.390     -5.19  0.000000208\n 5 P2004       -0.189      0.308     -0.613 0.540      \n 6 P2005       -0.378      0.502     -0.752 0.452      \n 7 P3          -0.0243     0.0132    -1.84  0.0664     \n 8 P4           0.00650    0.0228     0.285 0.776      \n 9 P13         -0.257      0.210     -1.22  0.221      \n10 P142        -0.482      0.449     -1.07  0.283      \n# ℹ 31 more rows\n\n\nPredictions: The augment function is used to obtain the predictions of the model on the training data.\n\nlm_augmented_results &lt;- lm_results |&gt;\n  augment(training_data)\n\nMetrics: The custom_metrics function is used to calculate the accuracy, sensitivity, specificity, and F-measure of the model on the training data. The results are stored in the “lm_metrics” object.\n\ncustom_metrics &lt;- metric_set(accuracy, sens, spec, f_meas)\n\ncustom_metrics(lm_augmented_results,\n  truth = outcome,\n  estimate = .pred_class,\n  event_level = \"second\"\n) |&gt; pretty_table()\n\n\n\n\n\n  \n    \n    \n      Metric\n      Estimate\n    \n  \n  \n    Accuracy\n0.817\n    Sensitivity\n0.168\n    Specificity\n0.974\n    F1\n0.264\n  \n  \n  \n\n\n\n\nWe can save them on a table. The results are stored in the “lm_results” object.\n\nlm_metrics_training &lt;- custom_metrics(lm_augmented_results,\n  truth = outcome,\n  estimate = .pred_class,\n  event_level = \"second\"\n) |&gt;\n  mutate(model = \"lm\")\n\nCan we improve the model?"
  },
  {
    "objectID": "archive/2023-12-um/workshop_document.html#decision-trees",
    "href": "archive/2023-12-um/workshop_document.html#decision-trees",
    "title": "Imbalanced data in Machine Learning Modeling",
    "section": "Decision trees",
    "text": "Decision trees\nDecision trees are a type of machine learning model used to solve classification and regression problems. The goal is to make decisions based on questions and answers asked of the data to reach a conclusion or prediction. In a decision tree, each point or “node” represents a characteristic of the data we are studying. Each “branch” of the tree shows a possible response to that characteristic.\n\nModel specification: A decision tree model is specified. The rpart package is used and the mode is set to classification.\n\n\ntree_spec &lt;-\n  decision_tree() |&gt;\n  set_engine(\"rpart\") |&gt;\n  set_mode(\"classification\")\n\n\nModel fitting: The decision tree model is fitted using the formula outcome ~ ., which means that score is being modeled as a function of all the other variables in the training_data dataframe.\n\n\ntree_results &lt;- tree_spec |&gt;\n  fit(outcome ~ ., data = training_data)\n\n\nDecision tree display: The fitted model is extracted from the fitting result and displayed using the tree_diagram() function of the treemisc package.\n\n\ncart_tree_fit &lt;- tree_results$fit\n\ntreemisc::tree_diagram(cart_tree_fit, roundint = FALSE)\n\n\n\n\nHow do you decide where to cut data in a decision tree? see this\nLet’s calculate the metrics\n\ntree_metrics_training &lt;- tree_results |&gt;\n  augment(training_data) |&gt;\n  custom_metrics(\n    truth = outcome,\n    estimate = .pred_class,\n    event_level = \"second\"\n  ) |&gt;\n  mutate(model = \"tree\")\n\nrbind(tree_metrics_training, lm_metrics_training) |&gt;\n  pivot_wider(names_from = model, values_from = .estimate) |&gt;\n  pretty_table()\n\n\n\n\n\n  \n    \n    \n      Metric\n      Tree\n      Lm\n    \n  \n  \n    Accuracy\n0.843\n0.817\n    Sensitivity\n0.290\n0.168\n    Specificity\n0.976\n0.974\n    F1\n0.418\n0.264"
  },
  {
    "objectID": "archive/2023-12-um/workshop_document.html#cart-with-hyperparameters",
    "href": "archive/2023-12-um/workshop_document.html#cart-with-hyperparameters",
    "title": "Imbalanced data in Machine Learning Modeling",
    "section": "CART with hyperparameters",
    "text": "CART with hyperparameters\nHyperparameters are model-specific values that can be adjusted and that allow you to control the training process of a model.\n\ntree_spec_hyp_manual &lt;-\n  decision_tree(min_n = 5, cost_complexity = 0.001) |&gt;\n  set_mode(\"classification\") |&gt;\n  set_engine(\"rpart\")\n\nIn this case, two hyperparameters are being indicated for the decision tree:\n\nmin_n: It is the minimum number of observations required to divide a node in a decision tree. A higher value of min_n implies that the tree will be shallower, since more samples will be required to perform a split at each node.\ncost_complexity: It is a regularization parameter. It is a measure of the penalty that is applied to the tree based on its complexity. A higher value of cost_complexity implies a stronger penalty on the complexity of the tree, leading to a smaller and shallower tree.\n\nNow to estimate the model\n\ntree_spec_hyp_manual_results &lt;- tree_spec_hyp_manual |&gt;\n  fit(outcome ~ ., data = training_data)\n\nWe can get the predictions\n\ntree_spec_hyp_manual_training &lt;- tree_spec_hyp_manual_results |&gt;\n  augment(training_data) |&gt;\n  custom_metrics(,\n    truth = outcome,\n    estimate = .pred_class,\n    event_level = \"second\"\n  ) |&gt;\n  mutate(model = \"Tree hyp manual\")\n\nAnd finally, we can compare the models\n\nrbind(\n  lm_metrics_training,\n  tree_metrics_training,\n  tree_spec_hyp_manual_training\n) |&gt;\n  pivot_wider(names_from = model, values_from = .estimate) |&gt;\n  pretty_table()\n\n\n\n\n\n  \n    \n    \n      Metric\n      Lm\n      Tree\n      Tree_hyp_manual\n    \n  \n  \n    Accuracy\n0.817\n0.843\n0.939\n    Sensitivity\n0.168\n0.290\n0.818\n    Specificity\n0.974\n0.976\n0.968\n    F1\n0.264\n0.418\n0.839"
  },
  {
    "objectID": "archive/2023-12-um/workshop_document.html#but-all-this-happens-in-the-training-data",
    "href": "archive/2023-12-um/workshop_document.html#but-all-this-happens-in-the-training-data",
    "title": "Imbalanced data in Machine Learning Modeling",
    "section": "But all this happens in the training data!",
    "text": "But all this happens in the training data!"
  },
  {
    "objectID": "archive/2023-12-um/workshop_document.html#why-is-it-bad",
    "href": "archive/2023-12-um/workshop_document.html#why-is-it-bad",
    "title": "Imbalanced data in Machine Learning Modeling",
    "section": "Why is it bad?",
    "text": "Why is it bad?\nWe can create a model that has zero errors in the training data. But how do we know that the model is good?\nWe could evaluate the model in unseen data, but we only have one test data set.\n\n# Use the test data to predict the score using the logistic regression model\nlm_predictions_test &lt;- lm_model |&gt;\n  last_fit(outcome ~ ., split_data,\n    metrics = custom_metrics,\n    control = control_resamples(event_level = \"second\")\n  ) |&gt;\n  collect_metrics() |&gt;\n  mutate(model = \"lm\")\n\n# Use the test data to predict the score using the decision tree model\ntree_prediction_test &lt;- tree_spec |&gt;\n  last_fit(outcome ~ ., split_data,\n    metrics = custom_metrics,\n    control = control_resamples(event_level = \"second\")\n  ) |&gt;\n  collect_metrics() |&gt;\n  mutate(model = \"Tree\")\n\n\n# Use the test data to predict the score using the hyperparameter decision tree model\ntree_hyp_predictions_test &lt;- tree_spec_hyp_manual |&gt;\n  last_fit(outcome ~ ., split_data,\n    metrics = custom_metrics,\n    control = control_resamples(event_level = \"second\")\n  ) |&gt;\n  collect_metrics() |&gt;\n  mutate(model = \"Tree Hype\")\n\n# Join the results\nall_models_test &lt;-\n  rbind(lm_predictions_test, tree_prediction_test, tree_hyp_predictions_test) |&gt;\n  pivot_wider(names_from = model, values_from = .estimate)\n\nall_models_test |&gt;\n  pretty_table()\n\n\n\n\n\n  \n    \n    \n      Metric\n      Lm\n      Tree\n      Tree_hype\n    \n  \n  \n    Accuracy\n0.815\n0.801\n0.674\n    Sensitivity\n0.222\n0.167\n0.259\n    Specificity\n0.959\n0.955\n0.775\n    F1\n0.320\n0.247\n0.237"
  },
  {
    "objectID": "archive/2023-12-um/workshop_document.html#cross-validation",
    "href": "archive/2023-12-um/workshop_document.html#cross-validation",
    "title": "Imbalanced data in Machine Learning Modeling",
    "section": "Cross Validation",
    "text": "Cross Validation\nSuppose we are working on a classification problem and we have a data set with 1000 observations. We want to evaluate the performance of a logistic regression model using k-fold cross-validation.\nStep-by-step k-fold cross-validation process:\nDivide the data set: First, we divide the data set into k subsets (folds) of equal size. In this example, we choose k=10, which means we divide the data set into 10 subsets of 100 records each.\nTrain and evaluate the model: Then, we do the following for each of the k subsets:\nto. We take one subset as the test (validation) set and the remaining k-1 subsets as the training set. For example, in the first iteration, we use the first subset as the test set and subsets 2 to 10 as the training set.\n\nWe train the logistic regression model using the training set.\nWe evaluate the performance of the model on the test set using an appropriate metric, such as precision, completeness, or F1-score. We write down the result of the metric for this iteration.\n\nAveraging results: After completing k iterations, we average the metric results for all iterations. This means providing us with a more robust estimate of the model’s performance since the model has been evaluated on different subsets of the data set.\nMore information here and here"
  },
  {
    "objectID": "archive/2023-12-um/workshop_document.html#first-path-cross-validation-object-to-estimate-performance",
    "href": "archive/2023-12-um/workshop_document.html#first-path-cross-validation-object-to-estimate-performance",
    "title": "Imbalanced data in Machine Learning Modeling",
    "section": "First path: cross-validation object to estimate performance",
    "text": "First path: cross-validation object to estimate performance\nThe first thing we are going to need is to create an object in R that contains the data organized in such a way that we can implement cross-validation. For this, we are going to use the vfold_cv() function from the rsample package.\n\ncrossvalidation &lt;-\n  vfold_cv(training_data,\n    v = 5, # number of boxes\n    strata = \"outcome\"\n  ) # variable to stratify\n\n\nlm_model_resamples &lt;- lm_model |&gt;\n  fit_resamples(outcome ~ ., crossvalidation,\n    metrics = custom_metrics,\n    control = control_resamples(event_level = \"second\")\n  ) |&gt;\n  collect_metrics() |&gt;\n  mutate(model = \"lm_resamples\")\n\ntree_spec_resamples &lt;- tree_spec |&gt;\n  fit_resamples(outcome ~ ., crossvalidation,\n    metrics = custom_metrics,\n    control = control_resamples(event_level = \"second\")\n  ) |&gt;\n  collect_metrics() |&gt;\n  mutate(model = \"tree_resamples\")\n\ntree_spec_hyp_resamples &lt;- tree_spec_hyp_manual |&gt;\n  fit_resamples(outcome ~ ., crossvalidation,\n    metrics = custom_metrics,\n    control = control_resamples(event_level = \"second\")\n  ) |&gt;\n  collect_metrics() |&gt;\n  mutate(model = \"tree_hyp_resamples\")\n\nall_models_resamples &lt;-\n  rbind(lm_model_resamples, tree_spec_resamples, tree_spec_hyp_resamples) |&gt;\n  pivot_wider(names_from = model, values_from = mean, id_cols = .metric)\n\nall_models_resamples |&gt;\n  pretty_table()\n\n\n\n\n\n  \n    \n    \n      Metric\n      Lm_resamples\n      Tree_resamples\n      Tree_hyp_resamples\n    \n  \n  \n    Accuracy\n0.795\n0.776\n0.736\n    F1\n0.219\n0.202\n0.298\n    Sensitivity\n0.150\n0.145\n0.289\n    Specificity\n0.951\n0.929\n0.844"
  },
  {
    "objectID": "archive/2023-12-um/workshop_document.html#second-path-cross-validation-object-to-identify-the-best-model",
    "href": "archive/2023-12-um/workshop_document.html#second-path-cross-validation-object-to-identify-the-best-model",
    "title": "Imbalanced data in Machine Learning Modeling",
    "section": "Second path: cross-validation object to identify the best model",
    "text": "Second path: cross-validation object to identify the best model\nWhen specifying a decision tree model, we will indicate that we want different values of the “min_n” and “cost_complexity” hyperparameters to be tested. For that, we are going to use the tune package.\n\ntree_spe_tune &lt;-\n  decision_tree(\n    cost_complexity = tune(),\n    tree_depth = tune(),\n    min_n = tune()\n  ) |&gt;\n  set_mode(\"classification\") |&gt;\n  set_engine(\"rpart\")\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nCost_complexity: Cost_complexity is a regularization parameter. It is a measure of the penalty that is applied to the tree based on its complexity. A higher value of cost_complexity implies a stronger penalty on the complexity of the tree, leading to a smaller and shallower tree. The idea is to find an optimal value of cost_complexity that balances the precision and complexity of the tree, reducing both bias and variance.\nTree_depth (tree depth): Tree_depth refers to the maximum length of the longest path from the root to a leaf in a decision tree. A deeper tree is more complex and can capture more complicated relationships in the data.\n\n\n\nNow, let’s specify the search grid. The lookup grid is a table that contains the values to test for each combination of hyperparameters.\n\ntree_grid &lt;- grid_regular(\n  cost_complexity(range = c(-3, -2)),\n  tree_depth(range = c(4L, 10L)),\n  min_n(range = c(10L, 40L))\n)\n\nThe next step is to estimate the performance of the models on the validation data, using the models created with the different combinations of hyperparameters. For this, we are going to use the tune_grid() function from the tune package.\n\ndoParallel::registerDoParallel()\n\nset.seed(345)\ntree_rs &lt;-\n  tune_grid(\n    tree_spe_tune,\n    outcome ~ .,\n    resamples = crossvalidation,\n    control = control_resamples(event_level = \"second\"),\n    grid = tree_grid,\n    metrics = custom_metrics\n  )\n\ndoParallel::stopImplicitCluster()\n\n\n\n\n\n\n\nTip\n\n\n\n\n\ndoParallel is an excellent package created to facilitate parallel programming in R. Using R in “parallel” allows you to take advantage of the power of computers to save time.\n\n\n\nThis will give us a table with the results of each model, and we can ask it to show us the combination of hyperparameters that had the best performance.\n\nautoplot(tree_rs)\n\n\n\n\n\nshow_best(tree_rs, metric = \"sens\")\n\n# A tibble: 5 × 9\n  cost_complexity tree_depth min_n .metric .estimator  mean     n std_err\n            &lt;dbl&gt;      &lt;int&gt; &lt;int&gt; &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt;\n1         0.001           10    10 sens    binary     0.294     5  0.0471\n2         0.00316         10    10 sens    binary     0.285     5  0.0422\n3         0.00316         10    25 sens    binary     0.238     5  0.0482\n4         0.001            7    10 sens    binary     0.233     5  0.0325\n5         0.001           10    25 sens    binary     0.233     5  0.0474\n# ℹ 1 more variable: .config &lt;chr&gt;\n\n\nFinally, we can select the best model and estimate it with the training data.\n\nbest_hyp_tree &lt;- select_best(tree_rs, min_n, metric = \"sens\")\n\ntree_tuned_final &lt;- finalize_model(tree_spe_tune, best_hyp_tree)\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nThe finalize_model function allows updating the model specification with the selected hyperparameters.\n\n\n\nNow, we go back to doing what we have been doing: estimating the model with the training data.\nWe already know how to evaluate the model, so let’s do it. For that, we’re going to use the fit_resamples() function, which is going to do a lot of work for us. This function will estimate the model with the training data and calculate the evaluation metrics on the validation data.\n\n# We will need this later to compare the models in the table metrics from training, which is not very useful, but fun.\ntree_tuned_training &lt;- tree_tuned_final |&gt;\n  fit(outcome ~ ., data = training_data) |&gt;\n  augment(training_data) |&gt;\n  custom_metrics(,\n    truth = outcome,\n    estimate = .pred_class,\n    event_level = \"second\"\n  ) |&gt;\n  mutate(model = \"Tree tunned\")\n\n\ntree_tuned_resample &lt;- tree_tuned_final |&gt;\n  fit_resamples(outcome ~ ., crossvalidation,\n    metrics = custom_metrics,\n    control = control_resamples(event_level = \"second\")\n  ) |&gt;\n  collect_metrics() |&gt;\n  mutate(model = \"Tree tunned\")\n\n\nall_models_resamples &lt;-\n  rbind(\n    lm_model_resamples,\n    tree_spec_resamples,\n    tree_spec_hyp_resamples,\n    tree_tuned_resample\n  ) |&gt;\n  pivot_wider(names_from = model, values_from = mean, id_cols = .metric)\n\nall_models_resamples |&gt; pretty_table()\n\n\n\n\n\n  \n    \n    \n      Metric\n      Lm_resamples\n      Tree_resamples\n      Tree_hyp_resamples\n      Tree_tunned\n    \n  \n  \n    Accuracy\n0.795\n0.776\n0.736\n0.752\n    F1\n0.219\n0.202\n0.298\n0.314\n    Sensitivity\n0.150\n0.145\n0.289\n0.294\n    Specificity\n0.951\n0.929\n0.844\n0.862\n  \n  \n  \n\n\n\n\n\nSecret ring: trees are very good at learning the distribution of training data, but sometimes, they tend to over-specialize on the data they are trained on. One way to solve this is to make many trees, which we can then average."
  },
  {
    "objectID": "archive/2023-12-um/workshop_document.html#random-forest",
    "href": "archive/2023-12-um/workshop_document.html#random-forest",
    "title": "Imbalanced data in Machine Learning Modeling",
    "section": "Random Forest",
    "text": "Random Forest\nWe already know why it is Forest, but why is it random?\n\nNumber of predictors used for each tree (mtry)\nNumber of observations per tree\n\nThe steps are the same, only the model specification changes.\n\nrf_spec &lt;-\n  rand_forest() |&gt;\n  set_mode(\"classification\") |&gt;\n  set_engine(\"ranger\", importance = \"permutation\")\n\nThere are some methods to try to identify which variables were most relevant when making the best predictions.\n\nrf_results_training &lt;- rf_spec |&gt;\n  fit(outcome ~ ., data = training_data)\n\nlibrary(vip)\nimportance_plot_rf &lt;-\n  rf_results_training |&gt;\n  vip() +\n  ggtitle(\"Random Forest\") +\n  theme_minimal() +\n  geom_bar(\n    stat = \"identity\",\n    color = \"green\", fill = \"green\", alpha = 0.2\n  )\nimportance_plot_rf\n\n\n\n\nNow, fit in resamples and collect metrics.\n\nrf_spec_resamples &lt;- rf_spec |&gt;\n  fit_resamples(outcome ~ ., crossvalidation,\n    metrics = custom_metrics,\n    control = control_resamples(event_level = \"second\")\n  ) |&gt;\n  collect_metrics() |&gt;\n  mutate(model = \"Random Forest\")\n\nall_models_resamples &lt;-\n  rbind(\n    lm_model_resamples,\n    tree_spec_resamples,\n    tree_spec_hyp_resamples,\n    tree_tuned_resample,\n    rf_spec_resamples\n  ) |&gt;\n  pivot_wider(names_from = model, values_from = mean, id_cols = .metric) |&gt;\n  pretty_table()\n\nall_models_resamples\n\n\n\n\n\n  \n    \n    \n      Metric\n      Lm_resamples\n      Tree_resamples\n      Tree_hyp_resamples\n      Tree_tunned\n      Random_forest\n    \n  \n  \n    Accuracy\n0.795\n0.776\n0.736\n0.752\n0.803\n    F1\n0.219\n0.202\n0.298\n0.314\n0.055\n    Sensitivity\n0.150\n0.145\n0.289\n0.294\n0.023\n    Specificity\n0.951\n0.929\n0.844\n0.862\n0.991"
  },
  {
    "objectID": "archive/2023-12-um/workshop_document.html#bias-and-variance",
    "href": "archive/2023-12-um/workshop_document.html#bias-and-variance",
    "title": "Imbalanced data in Machine Learning Modeling",
    "section": "Bias and variance",
    "text": "Bias and variance\nThese two concepts are crucial to understanding the balance between model complexity and its ability to generalize to new data.\nBias: Bias is the difference between the average prediction of our model and the true value we are trying to predict. Bias, in statistical terms, refers to the systematic difference between the expectation (or average) of the estimates produced by an estimator and the real value of the parameter to be estimated.\n\nExample: A linear regression model could have high bias if the actual data has a nonlinear relationship.\nImplications: A model with high bias is too simple and does not capture the underlying structure of the data. This leads to poor performance on the training and test set.\n\nVariance: Variance is the amount of variability in the model’s predictions for a piece of data. A model with high variance is very sensitive to small variations in the training data, which can result in overfitting. That is, the model fits the training data very well but performs poorly on unseen or test data.\n\nExample: A very deep decision tree model could have high variance since it is very sensitive to small variations in the training data.\nImplications: A model with high variance tends to overfit the training data, resulting in good performance on the training set but poor performance on the test set."
  },
  {
    "objectID": "archive/2023-12-um/workshop_document.html#upsampling",
    "href": "archive/2023-12-um/workshop_document.html#upsampling",
    "title": "Imbalanced data in Machine Learning Modeling",
    "section": "Upsampling",
    "text": "Upsampling\nUpsampling is a method that consists of increasing the number of observations in the minority class to match the number of observations in the majority class. This is done by randomly selecting observations from the minority class with replacement. This method is used when the data set is small and the minority class is very small.\n\nupsampling_rec &lt;-\n  recipe(outcome ~ ., training_data) |&gt;\n  step_upsample(outcome)\n\nupsampling_rec |&gt;\n  prep(retain = TRUE) |&gt;\n  bake(new_data = NULL) |&gt;\n  count(outcome)\n\n# A tibble: 2 × 2\n  outcome     n\n  &lt;fct&gt;   &lt;int&gt;\n1 0         886\n2 1         886\n\nupsampling_workflow &lt;-\n  workflow() |&gt;\n  add_recipe(upsampling_rec) |&gt;\n  add_model(lm_model)\n\nlet’s fit the model\n\nupsample_fit &lt;- upsampling_workflow |&gt;\n  fit(data = training_data)\n\nFinally, let’s evaluate the model in the validation data\n\nupsample_fit_resamples &lt;- upsampling_workflow |&gt;\n  fit_resamples(\n    resamples = crossvalidation,\n    metrics = custom_metrics,\n    control = control_resamples(event_level = \"second\")\n  )\n\nupsample_resamples &lt;- collect_metrics(upsample_fit_resamples) |&gt;\n  mutate(model = \"upsampling\")\n\n\nall_models_resamples &lt;-\n  rbind(\n    lm_model_resamples,\n    downsample_resamples,\n    upsample_resamples,\n    tree_spec_resamples,\n    tree_spec_hyp_resamples,\n    tree_tuned_resample,\n    rf_spec_resamples\n  ) |&gt;\n  pivot_wider(names_from = model, values_from = mean, id_cols = .metric)\n\nall_models_resamples |&gt; pretty_table()\n\n\n\n\n\n  \n    \n    \n      Metric\n      Lm_resamples\n      Downsample\n      Upsampling\n      Tree_resamples\n      Tree_hyp_resamples\n      Tree_tunned\n      Random_forest\n    \n  \n  \n    Accuracy\n0.795\n0.631\n0.658\n0.776\n0.736\n0.752\n0.803\n    F1\n0.219\n0.409\n0.419\n0.202\n0.298\n0.314\n0.055\n    Sensitivity\n0.150\n0.654\n0.626\n0.145\n0.289\n0.294\n0.023\n    Specificity\n0.951\n0.625\n0.666\n0.929\n0.844\n0.862\n0.991"
  },
  {
    "objectID": "archive/2024-02-konrad/2-procesamiento.html#agenda",
    "href": "archive/2024-02-konrad/2-procesamiento.html#agenda",
    "title": "2. Procesamiento de datos con tidyverse",
    "section": "Agenda",
    "text": "Agenda\n\nBase de datos de La Corporación Nuevos Rumbos\nTidyverse\nExplorar los datos\nEstimar un modelo\nPráctica"
  },
  {
    "objectID": "archive/2024-02-konrad/2-procesamiento.html#base-de-datos-corporación-nuevos-rumbos",
    "href": "archive/2024-02-konrad/2-procesamiento.html#base-de-datos-corporación-nuevos-rumbos",
    "title": "2. Procesamiento de datos con tidyverse",
    "section": "Base de datos Corporación Nuevos Rumbos",
    "text": "Base de datos Corporación Nuevos Rumbos\n\n\nOrganización sin ánimo de lucro: Enfocada en la investigación y prevención de problemas sociales.\nÁreas de Interés: Consumo de sustancias, delincuencia, y violencia.\nAlcance Geográfico: Colombia y América Latina.\n\nFundación y Trayectoria\n\nEstablecida en Bogotá: Octubre de 2002.\nTrayectoria: Más de dos décadas comprometidas con la prevención y la investigación.\n\nColaboraciones y Alianzas\n\nOrganizaciones Locales: Alcaldías y gobernaciones, Ministerios de Salud y de Justicia, Instituto Colombiano de Bienestar Familiar.\nOrganizaciones Internacionales: Organización Panamericana de la Salud, Comisión Europea, CICAD/OEA.\nInstituciones Académicas: Universidades de New Jersey, Washington, y Miami.\n\nMás información aquí"
  },
  {
    "objectID": "archive/2024-02-konrad/2-procesamiento.html#base-de-datos",
    "href": "archive/2024-02-konrad/2-procesamiento.html#base-de-datos",
    "title": "2. Procesamiento de datos con tidyverse",
    "section": "Base de datos",
    "text": "Base de datos\n\nFactores de riesgo y de protección\n\nDisponibilidad percibida de drogas\nActitudes de la comunidad frente al consumo de drogas\nActitudes de los padres frente al consumo de drogas\nInvolucramiento en actividades comunitarias\n\nConsumo de alcohol y otras drogas\n\nConsumo de alcohol en la vida, 12 meses últimos 30 días\nHaber estado en una pelea\n\nCaracterísticas demográficas\n\nEdad\nSexo\nGrado"
  },
  {
    "objectID": "archive/2024-02-konrad/2-procesamiento.html#importar-la-base-de-datos",
    "href": "archive/2024-02-konrad/2-procesamiento.html#importar-la-base-de-datos",
    "title": "2. Procesamiento de datos con tidyverse",
    "section": "Importar la base de datos",
    "text": "Importar la base de datos\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.4.4     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(DataWorkshopKL)\nlos_datos &lt;- DataWorkshopKL::base_NR\n\nlos_datos  |&gt; \n  glimpse()\n\nRows: 23,220\nColumns: 529\n$ YEAR                   &lt;fct&gt; 2014, 2012-2013, 2012-2013, 2014, 2014, 2014, 2…\n$ GRADE                  &lt;dbl&gt; 9, 8, 11, 6, 7, 7, 9, 10, 10, 8, 7, 9, 7, 9, 6,…\n$ GENDER                 &lt;fct&gt; Femenino, Masculino, Femenino, Femenino, Mascul…\n$ AGE                    &lt;dbl&gt; 16, 12, 17, 11, 13, 12, 14, 16, 16, 15, 13, 14,…\n$ EDAALC                 &lt;fct&gt; 10, NA, 15, 10, NA, 10, 14, 14, -9, 10, 10, 13,…\n$ EDACIG                 &lt;fct&gt; 14, NA, NA, NA, NA, NA, NA, 15, NA, NA, NA, NA,…\n$ EDAMAR                 &lt;fct&gt; 14, NA, NA, NA, NA, NA, NA, 15, NA, NA, NA, NA,…\n$ EDACOC                 &lt;fct&gt; 15, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ EDABAS                 &lt;fct&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ EDAINH                 &lt;fct&gt; 15, NA, NA, NA, NA, NA, NA, NA, -9, NA, NA, NA,…\n$ EDAEXT                 &lt;fct&gt; 11, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ EDAVIT                 &lt;fct&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ EDAHON                 &lt;fct&gt; 15, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ EDAACD                 &lt;fct&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ EDATRAN                &lt;fct&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ EDAPOP                 &lt;fct&gt; 12, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ EDAANF                 &lt;fct&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ EDAHER                 &lt;fct&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ EDADIC                 &lt;fct&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ FRAALC                 &lt;fct&gt; 2, 0, 4, 4, 0, 2, 1, 4, 1, 1, 2, 2, 0, 0, 0, 0,…\n$ FRACIG                 &lt;fct&gt; 3, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ FRAMAR                 &lt;fct&gt; 4, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ FRACOC                 &lt;fct&gt; 4, 0, NA, 0, 0, 0, 0, 0, NA, 0, NA, NA, NA, 0, …\n$ FRABAS                 &lt;fct&gt; 0, 0, NA, 0, 0, 0, 0, 0, NA, 0, NA, NA, NA, 0, …\n$ FRAINH                 &lt;fct&gt; 2, 0, NA, 0, 0, 0, 0, 0, 2, 0, NA, NA, NA, 0, N…\n$ FRAEXT                 &lt;fct&gt; 0, 0, NA, 0, 0, 0, 0, 0, NA, 0, NA, NA, NA, 0, …\n$ FRAVIT                 &lt;fct&gt; NA, 0, NA, NA, NA, NA, NA, NA, NA, 0, NA, NA, N…\n$ FRAHON                 &lt;fct&gt; 0, 0, NA, 0, 0, 0, 0, 0, NA, 0, NA, NA, NA, 0, …\n$ FRAACI                 &lt;fct&gt; 0, 0, NA, 0, 0, 0, 0, 0, NA, 0, NA, NA, NA, 0, …\n$ FRATRA                 &lt;fct&gt; 0, 0, NA, 0, 0, 0, 0, 0, NA, 0, NA, NA, NA, 0, …\n$ FRAPOP                 &lt;fct&gt; 0, 0, NA, 0, 0, 0, 0, 0, NA, 0, NA, NA, NA, 0, …\n$ FRAANF                 &lt;fct&gt; 0, 0, NA, 0, 0, 0, 0, 0, NA, 0, NA, NA, NA, 0, …\n$ FRAHER                 &lt;fct&gt; 0, 0, NA, 0, 0, 0, 0, 0, NA, 0, NA, NA, NA, 0, …\n$ FRADIC                 &lt;fct&gt; 0, 0, NA, 0, 0, 0, 0, 0, NA, 0, NA, NA, NA, 0, …\n$ ALC30DY                &lt;fct&gt; Sí ha consumido, No ha consumido, Sí ha consumi…\n$ CIG30DY                &lt;fct&gt; Sí ha consumido, No ha consumido, No ha consumi…\n$ MAR30DY                &lt;fct&gt; Sí ha consumido, No ha consumido, No ha consumi…\n$ COKE30DY               &lt;fct&gt; Sí ha consumido, No ha consumido, No ha consumi…\n$ BASU30DY               &lt;fct&gt; No ha consumido, No ha consumido, No ha consumi…\n$ INHL30DY               &lt;fct&gt; No ha consumido, No ha consumido, No ha consumi…\n$ MDMA30DY               &lt;fct&gt; No ha consumido, No ha consumido, No ha consumi…\n$ FAKE30DY               &lt;fct&gt; No ha consumido, No ha consumido, No ha consumi…\n$ MUSH30DY               &lt;fct&gt; No ha consumido, No ha consumido, No ha consumi…\n$ LSD30DY                &lt;fct&gt; No ha consumido, No ha consumido, No ha consumi…\n$ TRAN30DY               &lt;fct&gt; No ha consumido, No ha consumido, No ha consumi…\n$ POP30DY                &lt;fct&gt; No ha consumido, No ha consumido, No ha consumi…\n$ AMPH30DY               &lt;fct&gt; No ha consumido, No ha consumido, No ha consumi…\n$ HERO30DY               &lt;fct&gt; No ha consumido, No ha consumido, No ha consumi…\n$ DICK30DY               &lt;fct&gt; No ha consumido, No ha consumido, No ha consumi…\n$ EMBALG                 &lt;fct&gt; SI, NO, SI, NO, NO, NO, SI, SI, NA, SI, NA, NA,…\n$ EMBPRI                 &lt;dbl&gt; 11, NA, 15, NA, NA, NA, 14, 14, NA, 15, NA, NA,…\n$ EMBCOL                 &lt;fct&gt; NO, NO, NO, NO, NO, NO, NO, NO, NA, NO, NA, NA,…\n$ EMBDCO                 &lt;fct&gt; NO, NO, NO, NO, NO, NO, NO, NO, NA, SI, NA, NA,…\n$ GETALC                 &lt;fct&gt; Muy fácil, Fácil, Fácil, Fácil, Muy fácil, Un p…\n$ GETCIG                 &lt;fct&gt; Muy fácil, Fácil, Un poco difícil, Muy difìcil,…\n$ GETDRUG                &lt;fct&gt; Muy fácil, Un poco difícil, Muy difìcil, Muy di…\n$ GETMAR                 &lt;fct&gt; Muy fácil, Fácil, Fácil, Muy difìcil, Muy fácil…\n$ AWRMAR                 &lt;fct&gt; No tan mal, Muy mal, Muy mal, Muy mal, Muy mal,…\n$ AWRALC                 &lt;fct&gt; No tan mal, No tan mal, Mal, Muy mal, Muy mal, …\n$ AWRCIG                 &lt;fct&gt; Para nada mal, Mal, Muy mal, Muy mal, Muy mal, …\n$ WRPRALC                &lt;fct&gt; Muy mal, Muy mal, No tan mal, No tan mal, Muy m…\n$ WRPRCIG                &lt;fct&gt; Muy mal, Muy mal, Muy mal, Muy mal, Muy mal, Mu…\n$ WRPRMAR                &lt;fct&gt; Muy mal, Muy mal, Muy mal, Muy mal, Muy mal, Mu…\n$ WRPRDRW                &lt;fct&gt; Mal, Muy mal, Mal, Muy mal, Muy mal, Muy mal, N…\n$ WRPRSTL                &lt;fct&gt; Muy mal, Muy mal, Muy mal, Muy mal, Muy mal, Mu…\n$ WRPRFGT                &lt;fct&gt; Mal, Muy mal, Mal, Muy mal, Muy mal, Muy mal, M…\n$ POLMAR                 &lt;fct&gt; No, Definitivamente no, No, Si, Definitivamente…\n$ POLALC                 &lt;fct&gt; Definitivamente no, Definitivamente no, No, Def…\n$ POLGUN                 &lt;fct&gt; Si, Si, Definitivamente si, Si, Si, NA, No, Si,…\n$ POLCIG                 &lt;fct&gt; Definitivamente no, Definitivamente no, Definit…\n$ FAMRULE                &lt;fct&gt; Definitivamente si, Definitivamente si, Definit…\n$ HMWORK                 &lt;fct&gt; No, Si, Definitivamente si, No, Si, Definitivam…\n$ PARKNOW                &lt;fct&gt; Definitivamente no, Definitivamente si, Definit…\n$ CMHOME                 &lt;fct&gt; Definitivamente si, Definitivamente si, Definit…\n$ CATCHAL                &lt;fct&gt; Definitivamente si, Definitivamente si, Definit…\n$ CLRRULE                &lt;fct&gt; Definitivamente si, Definitivamente si, Definit…\n$ CATCHGN                &lt;fct&gt; Si, Definitivamente si, Si, Si, Definitivamente…\n$ CATCHSK                &lt;fct&gt; No, Si, Si, Si, Definitivamente si, Definitivam…\n$ SCHIMP                 &lt;fct&gt; Rara vez, Frecuentemente, Frecuentemente, Frecu…\n$ SCHINT                 &lt;fct&gt; Un poco aburridas, Bastante interesantes, Un po…\n$ SCHLRN                 &lt;fct&gt; Un poco interesantes, Muy interesantes y estimu…\n$ MISSC                  &lt;fct&gt; Ningún, Ningún, Ningún, Ningún, Ningún, Ningún,…\n$ ENJSCH                 &lt;fct&gt; Casi siempre, A veces, A veces, Casi siempre, A…\n$ HTSCH                  &lt;fct&gt; A veces, Nunca, A veces, Nunca, Nunca, A veces,…\n$ BWSCH                  &lt;fct&gt; Casi siempre, Nunca, A veces, Casi siempre, Cas…\n$ HMCIG                  &lt;fct&gt; Riesgo ligero, Riesgo moderado, Mucho riesgo, M…\n$ HMMARO                 &lt;fct&gt; Riesgo ligero, Mucho riesgo, Riesgo ligero, Rie…\n$ HMMARR                 &lt;fct&gt; Sin riesgo, Mucho riesgo, Mucho riesgo, Riesgo …\n$ HMALC                  &lt;fct&gt; Mucho riesgo, Riesgo moderado, Mucho riesgo, Si…\n$ P44E                   &lt;fct&gt; Riesgo moderado, Riesgo moderado, Mucho riesgo,…\n$ WRALC                  &lt;fct&gt; Mal, Muy mal, Muy mal, No tan mal, Muy mal, Muy…\n$ WRCIG                  &lt;fct&gt; No tan mal, Muy mal, Muy mal, Mal, Muy mal, Muy…\n$ WRMAR                  &lt;fct&gt; Para nada mal, Muy mal, Muy mal, NA, Muy mal, M…\n$ WRDRUG                 &lt;fct&gt; Para nada mal, Muy mal, Muy mal, Muy mal, Muy m…\n$ WRGUN                  &lt;fct&gt; No tan mal, Muy mal, Muy mal, Muy mal, Muy mal,…\n$ WRSTL                  &lt;fct&gt; Mal, Muy mal, Muy mal, Muy mal, Muy mal, Muy ma…\n$ WRFGT                  &lt;fct&gt; Mal, Mal, Muy mal, No tan mal, Muy mal, Muy mal…\n$ WRATT                  &lt;fct&gt; Muy mal, Muy mal, Muy mal, Muy mal, Muy mal, Mu…\n$ WRSKIP                 &lt;fct&gt; No tan mal, Mal, Mal, Muy mal, Muy mal, Muy mal…\n$ FRCIG                  &lt;dbl&gt; 5, 1, 4, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1,…\n$ FRALC                  &lt;fct&gt; 2 amigos, Ninguno de mis amigos, 2 amigos, 2 am…\n$ FRMAR                  &lt;fct&gt; 4 amigos, Ninguno de mis amigos, Ninguno de mis…\n$ FRDRUG                 &lt;fct&gt; 4 amigos, Ninguno de mis amigos, Ninguno de mis…\n$ FRSUS                  &lt;fct&gt; 4 amigos, Ninguno de mis amigos, Ninguno de mis…\n$ FRGUN                  &lt;fct&gt; 4 amigos, Ninguno de mis amigos, Ninguno de mis…\n$ FRSOLD                 &lt;fct&gt; 2 amigos, Ninguno de mis amigos, Ninguno de mis…\n$ FRSTL                  &lt;fct&gt; Ninguno de mis amigos, Ninguno de mis amigos, N…\n$ FRARST                 &lt;fct&gt; 1 amigo, Ninguno de mis amigos, Ninguno de mis …\n$ FRDROP                 &lt;fct&gt; 1 amigo, Ninguno de mis amigos, Ninguno de mis …\n$ FRGANG                 &lt;fct&gt; 1 amigo, 0, 0, Ninguno de mis amigos, 0, 0, 0, …\n$ TCHNOT                 &lt;fct&gt; Definitivamente no, Si, No, Definitivamente si,…\n$ SAFESCH                &lt;fct&gt; Definitivamente no, No, No, Si, No, Definitivam…\n$ SCHPAR                 &lt;fct&gt; Definitivamente no, Si, No, Definitivamente si,…\n$ TCHPRA                 &lt;fct&gt; Definitivamente no, No, No, No, No, No, Si, No,…\n$ ENJMOM                 &lt;fct&gt; Definitivamente si, Definitivamente si, Definit…\n$ ENJDAD                 &lt;fct&gt; Si, Definitivamente si, Definitivamente si, Def…\n$ ASKHELP                &lt;fct&gt; No, Definitivamente si, Definitivamente si, Def…\n$ FAMFUN                 &lt;fct&gt; Si, Si, Definitivamente si, Definitivamente si,…\n$ FAMDEC                 &lt;fct&gt; No, Definitivamente si, Definitivamente si, Def…\n$ PARNOT                 &lt;fct&gt; A veces, Con frecuencia, Con frecuencia, A vece…\n$ PROUD                  &lt;fct&gt; Nunca o casi nunca, Todo el tiempo, Con frecuen…\n$ VDORMB                 &lt;dbl&gt; 1, NA, NA, NA, NA, NA, NA, 1, NA, NA, NA, NA, N…\n$ VPROBD                 &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ VPROBP                 &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ VCOLEN                 &lt;dbl&gt; 1, NA, 1, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ VROBTR                 &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ VPROCB                 &lt;dbl&gt; 1, NA, 1, NA, NA, NA, NA, 1, NA, NA, NA, NA, NA…\n$ VNCOT                  &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ VPELET                 &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ VSBDTM                 &lt;dbl&gt; NA, NA, 1, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ VCOLGB                 &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ VPELNOV                &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, 1, NA, NA, NA, NA, …\n$ VPROFT                 &lt;fct&gt; NA, NO, NA, NA, NA, NA, NA, SI, NA, NA, NA, NA,…\n$ ALCLIFE                &lt;fct&gt; Sí ha consumido, No ha consumido, Sí ha consumi…\n$ CIGLIFE                &lt;fct&gt; Sí ha consumido, No ha consumido, No ha consumi…\n$ MARLIFE                &lt;fct&gt; Sí ha consumido, No ha consumido, No ha consumi…\n$ COKELIFE               &lt;fct&gt; Sí ha consumido, No ha consumido, No ha consumi…\n$ BASULIFE               &lt;fct&gt; No ha consumido, No ha consumido, No ha consumi…\n$ INHLLIFE               &lt;fct&gt; Sí ha consumido, No ha consumido, No ha consumi…\n$ MDMALIFE               &lt;fct&gt; Sí ha consumido, No ha consumido, No ha consumi…\n$ FAKELIFE               &lt;fct&gt; No ha consumido, No ha consumido, No ha consumi…\n$ MUSHLIFE               &lt;fct&gt; Sí ha consumido, No ha consumido, No ha consumi…\n$ LSDLIFE                &lt;fct&gt; No ha consumido, No ha consumido, No ha consumi…\n$ TRANLIFE               &lt;fct&gt; No ha consumido, No ha consumido, No ha consumi…\n$ POPLIFE                &lt;fct&gt; Sí ha consumido, No ha consumido, No ha consumi…\n$ AMPHLIFE               &lt;fct&gt; No ha consumido, No ha consumido, No ha consumi…\n$ HEROLIFE               &lt;fct&gt; No ha consumido, No ha consumido, No ha consumi…\n$ DICKLIFE               &lt;fct&gt; No ha consumido, No ha consumido, No ha consumi…\n$ PYALC                  &lt;fct&gt; Sí ha consumido, No ha consumido, Sí ha consumi…\n$ PYCIG                  &lt;fct&gt; Sí ha consumido, No ha consumido, No ha consumi…\n$ PYMAR                  &lt;fct&gt; Sí ha consumido, No ha consumido, No ha consumi…\n$ PYCOKE                 &lt;fct&gt; Sí ha consumido, No ha consumido, No ha consumi…\n$ PYBASU                 &lt;fct&gt; No ha consumido, No ha consumido, No ha consumi…\n$ PYINHL                 &lt;fct&gt; Sí ha consumido, No ha consumido, No ha consumi…\n$ PYMDMA                 &lt;fct&gt; No ha consumido, No ha consumido, No ha consumi…\n$ PYFAKE                 &lt;fct&gt; NA, No ha consumido, No ha consumido, No ha con…\n$ PYMUSH                 &lt;fct&gt; No ha consumido, No ha consumido, No ha consumi…\n$ PYLSD                  &lt;fct&gt; No ha consumido, No ha consumido, No ha consumi…\n$ PYTRAN                 &lt;fct&gt; No ha consumido, No ha consumido, No ha consumi…\n$ PYPOP                  &lt;fct&gt; No ha consumido, No ha consumido, No ha consumi…\n$ PYAMPH                 &lt;fct&gt; No ha consumido, No ha consumido, No ha consumi…\n$ PYHERO                 &lt;fct&gt; No ha consumido, No ha consumido, No ha consumi…\n$ PYDICK                 &lt;fct&gt; No ha consumido, No ha consumido, No ha consumi…\n$ AGEDRUNK               &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 10, NA,…\n$ DRUNK                  &lt;fct&gt; NA, NA, NA, NA, NA, NA, NA, NA, NO, NA, SI, NO,…\n$ ARGUE                  &lt;fct&gt; NA, NA, NA, NA, NA, NA, NA, NA, 4, NA, 3, 3, 2,…\n$ SERARG                 &lt;fct&gt; NA, NA, NA, NA, NA, NA, NA, NA, 2, NA, 3, 3, 2,…\n$ FAMYELL                &lt;fct&gt; NA, NA, NA, NA, NA, NA, NA, NA, 2, NA, 2, 2, 2,…\n$ TIMESCH                &lt;fct&gt; NA, NA, NA, NA, NA, NA, NA, NA, 1, NA, 2, 2, 5,…\n$ SPORT                  &lt;fct&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 1, NA, …\n$ SCOUT                  &lt;fct&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 1, NA, …\n$ RELIG                  &lt;fct&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 2, NA, …\n$ ARTS                   &lt;fct&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 1, NA, …\n$ SERCLUB                &lt;fct&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 1, NA, …\n$ SIBALC                 &lt;fct&gt; NA, NA, NA, NA, NA, NA, NA, NA, 5, NA, NA, 1, 1…\n$ SIBMAR                 &lt;fct&gt; NA, NA, NA, NA, NA, NA, NA, NA, 1, NA, NA, 1, 1…\n$ SIBCIG                 &lt;fct&gt; NA, NA, NA, NA, NA, NA, NA, NA, 1, NA, NA, 1, 1…\n$ SIBGUN                 &lt;fct&gt; NA, NA, NA, NA, NA, NA, NA, NA, 1, NA, NA, 1, 1…\n$ SIBSUS                 &lt;fct&gt; NA, NA, NA, NA, NA, NA, NA, NA, 1, NA, NA, 1, 1…\n$ FAMPROB                &lt;fct&gt; NA, NA, NA, NA, NA, NA, NA, NA, 5, NA, NA, 5, 1…\n$ AGEALCR                &lt;fct&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 10 o me…\n$ AGEATT                 &lt;fct&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, Nunca l…\n$ AGESUS                 &lt;fct&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, Nunca l…\n$ AGEARST                &lt;fct&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, Nunca l…\n$ NHCRIME                &lt;fct&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 3, NA, …\n$ NHFIGHT                &lt;fct&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 2, NA, …\n$ NHGARB                 &lt;fct&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 2, NA, …\n$ NHGRAFF                &lt;fct&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 2, NA, …\n$ NHEMPTY                &lt;fct&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 3, NA, …\n$ NHDARK                 &lt;fct&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 2, NA, …\n$ NHPARK                 &lt;fct&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 1, NA, …\n$ ADUDRUG                &lt;fct&gt; NA, NA, NA, NA, NA, NA, NA, NA, 1, NA, 2, 1, 1,…\n$ ADSTEAL                &lt;fct&gt; NA, NA, NA, NA, NA, NA, NA, NA, 4, NA, 2, 1, 1,…\n$ ADDRUNK                &lt;fct&gt; NA, NA, NA, NA, NA, NA, NA, NA, 4, NA, 2, 1, 1,…\n$ ADSDRUG                &lt;fct&gt; NA, NA, NA, NA, NA, NA, NA, NA, 1, NA, 1, 1, 1,…\n$ AGEGUN                 &lt;fct&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, nunca l…\n$ COOLMAR                &lt;fct&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 1, NA, …\n$ COOLCIG                &lt;fct&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 1, NA, …\n$ COOLALC                &lt;fct&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 1, NA, …\n$ COOLGUN                &lt;fct&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 1, NA, …\n$ COOLKNF                &lt;fct&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 1, NA, …\n$ AGEKNF                 &lt;fct&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, Nunca l…\n$ TALKNEI                &lt;fct&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 2, NA, …\n$ NHGJOB                 &lt;fct&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 2, NA, …\n$ NHPROUD                &lt;fct&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 1, NA, …\n$ NHENC                  &lt;fct&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 1, NA, …\n$ SCHDISC                &lt;fct&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 2, NA, …\n$ SCHACT                 &lt;fct&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 3, NA, …\n$ SCHPRO                 &lt;fct&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 2, NA, …\n$ SCHCLUB                &lt;fct&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 2, NA, …\n$ TALKTCH                &lt;fct&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 2, NA, …\n$ COOLSCH                &lt;fct&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 3, NA, …\n$ COOLDEF                &lt;fct&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 3, NA, …\n$ COOLVOL                &lt;fct&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 3, NA, …\n$ COOLCOM                &lt;fct&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 4, NA, …\n$ FRCOM                  &lt;fct&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 1, NA, …\n$ FRCLUB                 &lt;fct&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 5, NA, …\n$ FRSCH                  &lt;fct&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 5, NA, …\n$ FRLKSCH                &lt;fct&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 5, NA, …\n$ FRREL                  &lt;fct&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 5, NA, …\n$ SOLDDRUG               &lt;fct&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 1, NA, …\n$ ARRESTED               &lt;fct&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 1, NA, …\n$ ATTACKED               &lt;fct&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 1, NA, …\n$ CARRYGUN               &lt;fct&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 1, NA, …\n$ CARRYKNF               &lt;fct&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 1, NA, …\n$ YRTAKE                 &lt;fct&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 1, NA, …\n$ YRCLUB                 &lt;fct&gt; NA, NA, NA, NA, NA, NA, NA, NA, 2, NA, 2, 2, 4,…\n$ YREXTRA                &lt;fct&gt; NA, NA, NA, NA, NA, NA, NA, NA, 2, NA, 3, 1, 2,…\n$ YRVOL                  &lt;fct&gt; NA, NA, NA, NA, NA, NA, NA, NA, 1, NA, 1, 1, 2,…\n$ SAFENH                 &lt;fct&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, SÍ, NA,…\n$ GETGUN                 &lt;fct&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, Difícil…\n$ GANG                   &lt;fct&gt; NA, NA, NA, NA, NA, NA, NA, NA, 0, NA, 0, 0, 0,…\n$ GANGNM                 &lt;fct&gt; NA, NA, NA, NA, NA, NA, NA, NA, 3, NA, 3, 3, 3,…\n$ AGEGANG                &lt;fct&gt; NA, NA, NA, NA, NA, NA, NA, NA, 1, NA, 1, 1, 1,…\n$ AERCIG                 &lt;fct&gt; NA, NA, NA, NA, NA, NA, NA, NA, 1, NA, NA, 1, 2…\n$ INSCH                  &lt;fct&gt; NA, NA, NA, NA, NA, NA, NA, NA, NO, NA, NA, NO,…\n$ BFSCH                  &lt;fct&gt; NA, NA, NA, NA, NA, NA, NA, NA, NO, NA, NA, NO,…\n$ RWSCH                  &lt;fct&gt; NA, NA, NA, NA, NA, NA, NA, NA, 3, NA, NA, 1, 3…\n$ SEELP                  &lt;fct&gt; NA, NA, NA, NA, NA, NA, NA, NA, 1, NA, NA, 1, 1…\n$ POLICE                 &lt;fct&gt; NA, NA, NA, NA, NA, NA, NA, NA, 1, NA, NA, 1, 1…\n$ FIGTH                  &lt;fct&gt; NA, NA, NA, NA, NA, NA, NA, NA, 1, NA, NA, 1, 1…\n$ HANG                   &lt;fct&gt; NA, NA, NA, NA, NA, NA, NA, NA, 1, NA, NA, 1, 1…\n$ STOLEN                 &lt;fct&gt; NA, NA, NA, NA, NA, NA, NA, NA, 1, NA, NA, 1, 1…\n$ HOMPROB                &lt;fct&gt; NA, NA, NA, NA, NA, NA, NA, NA, 1, NA, NA, 1, 1…\n$ SKIPDRI                &lt;fct&gt; NA, NA, NA, NA, NA, NA, NA, NA, 1, NA, NA, 1, 1…\n$ BAROUT                 &lt;fct&gt; NA, NA, NA, NA, NA, NA, NA, NA, 5, NA, NA, 1, 1…\n$ BOTTLE                 &lt;fct&gt; NA, NA, NA, NA, NA, NA, NA, NA, 1, NA, NA, 1, 1…\n$ POLOLO                 &lt;fct&gt; NA, NA, NA, NA, NA, NA, NA, NA, 1, NA, NA, 1, 1…\n$ POLMARr                &lt;dbl&gt; 3, 4, 3, 2, 4, 3, 4, 2, 3, 1, 3, 3, 2, 3, 2, 2,…\n$ POLALCr                &lt;dbl&gt; 4, 4, 3, 4, 3, 4, 4, 2, 1, 4, 3, 3, 2, 3, 4, 3,…\n$ POLGUNr                &lt;dbl&gt; 2, 2, 1, 2, 2, NA, 3, 2, 1, 1, 2, 2, 2, 3, 2, 1…\n$ POLCIGr                &lt;dbl&gt; 4, 4, 4, 3, 4, 1, 4, 4, 3, 4, 3, 3, 2, 3, 4, 4,…\n$ FAMRULEr               &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, NA, 2, 2, 1, 1, 1…\n$ HMWORKr                &lt;dbl&gt; 3, 2, 1, 3, 2, 1, 2, 1, 1, 2, NA, 3, 2, 1, 2, 1…\n$ PARKNOWr               &lt;dbl&gt; 4, 1, 1, NA, 3, 1, 1, 2, 1, 2, NA, 1, 2, 1, 1, …\n$ CMHOMEr                &lt;dbl&gt; 1, 1, 1, 4, 2, 1, 1, 3, 1, 2, NA, 2, 2, 1, 1, 1…\n$ CATCHALr               &lt;dbl&gt; 1, 1, 1, 4, 2, 1, 3, 3, 3, 3, NA, 2, 2, 1, 1, 1…\n$ CLRRULEr               &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, NA, 1, 2, 1, 1, 1…\n$ CATCHGNr               &lt;dbl&gt; 2, 1, 2, 2, 1, 1, 2, 1, 1, 1, NA, 1, 2, 1, 2, 1…\n$ CATCHSKr               &lt;dbl&gt; 3, 2, 2, 2, 1, 1, 3, 3, 1, 1, NA, 2, 2, 1, 1, 2…\n$ SCHIMPr                &lt;dbl&gt; 4, 2, 2, 2, 3, 4, 3, 2, 4, 2, 4, 3, 3, 3, 2, 1,…\n$ MISSCr                 &lt;dbl&gt; 1.00, 1.00, 1.00, 1.00, 1.00, 1.00, 1.00, 1.00,…\n$ ENJSCHr                &lt;dbl&gt; 1, 3, 3, 1, 3, 1, 2, 2, 2, 1, 3, 5, 2, 3, NA, 2…\n$ BWSCHr                 &lt;dbl&gt; 1, 5, 3, 1, 1, 2, 2, 2, NA, 1, 1, NA, NA, 2, NA…\n$ HMCIGr                 &lt;dbl&gt; 2, 1, NA, NA, NA, NA, NA, 3, NA, 3, NA, 2, 1, N…\n$ HMMAROr                &lt;dbl&gt; 2, NA, 2, 1, NA, NA, 2, 3, 2, 3, NA, 3, 2, 1, N…\n$ HMMARRr                &lt;dbl&gt; 3, NA, NA, 1, NA, NA, 1, 3, NA, 3, NA, 1, 1, NA…\n$ HMALCr                 &lt;dbl&gt; NA, 1, NA, 3, NA, NA, NA, 2, NA, 1, NA, NA, 1, …\n$ FRCIGr                 &lt;dbl&gt; 4, 0, 3, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ FRALCr                 &lt;dbl&gt; 2, 0, 2, 2, 0, 0, 2, 4, 1, 4, 0, 2, 0, 4, 0, 0,…\n$ FRMARr                 &lt;dbl&gt; 4, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ FRDRUGr                &lt;dbl&gt; 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ FRSUSr                 &lt;dbl&gt; 4, 0, 0, 0, 0, 2, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0,…\n$ FRGUNr                 &lt;dbl&gt; 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ FRSOLDr                &lt;dbl&gt; 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ FRSTLr                 &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ FRARSTr                &lt;dbl&gt; 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ FRDROPr                &lt;dbl&gt; 1, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,…\n$ CATHAL                 &lt;fct&gt; NA, NA, NA, NA, NA, NA, NA, NA, -9, NA, NA, NA,…\n$ SAFENHr                &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 2, NA, …\n$ FAMPROBr               &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ sibling                &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ SIBALCr                &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 1, …\n$ SIBMARr                &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, 1, NA, NA, 1, 1…\n$ SIBCIGr                &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, 1, NA, NA, 1, 1…\n$ SIBGUNr                &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, 1, NA, NA, 1, 1…\n$ SIBSUSr                &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, 1, NA, NA, 1, 1…\n$ AGESUSr                &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 0, NA, …\n$ AGEARSTr               &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 0, NA, …\n$ AGEGUNr                &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 0, NA, …\n$ AGEATTr                &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 0, NA, …\n$ GANGr                  &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, 0, NA, 0, 0, 0,…\n$ GANGNMr                &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, 0, NA, 0, 0, 0,…\n$ FRGANGr                &lt;dbl&gt; 4, 0, 0, 2, 0, 0, 0, 0, 8, 0, 0, 0, 0, 0, 0, 0,…\n$ AGEGANGr               &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, 0, NA, 0, 0, 0,…\n$ SPORTr                 &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 4, NA, …\n$ SCOUTr                 &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 4, NA, …\n$ ARTSr                  &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 4, NA, …\n$ RELIGr                 &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 1, NA, …\n$ SERCLUBr               &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 4, NA, …\n$ FRCLUBr                &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 4, NA, …\n$ FRCOMr                 &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 0, NA, …\n$ FRLKSCHr               &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 4, NA, …\n$ FRRELr                 &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 4, NA, …\n$ FRSCHR                 &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 4, NA, …\n$ OTHRYR                 &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, 1, NA, NA, NA, …\n$ OTHER1                 &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, 1, NA, NA, NA, …\n$ OTHER2                 &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ OTHER3                 &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, 1, NA, NA, NA, …\n$ OTHRMTH                &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, 1, NA, NA, NA, …\n$ OTHRLF                 &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ CRPAD                  &lt;dbl&gt; 4.00, 2.75, 2.25, 1.50, 4.00, 2.00, 1.50, 3.25,…\n$ CRLNFD                 &lt;dbl&gt; 3.166667, 2.666667, 1.833333, 1.833333, 2.00000…\n$ FRPFD                  &lt;dbl&gt; 1.000000, 1.000000, 1.666667, 1.666667, 1.00000…\n$ FRPFM                  &lt;dbl&gt; 2.000000, 1.250000, 1.250000, 2.428571, 1.62500…\n$ SRLCS                  &lt;dbl&gt; 2.142857, 2.428571, 2.571429, 1.714286, 1.85714…\n$ PRPRD                  &lt;dbl&gt; 2.333333, NA, NA, 1.666667, NA, NA, NA, 2.75000…\n$ PRFAD                  &lt;dbl&gt; 3.25, 1.00, 1.00, 2.00, 1.00, 1.00, 1.25, 3.00,…\n$ PRATA                  &lt;dbl&gt; 2.2, 1.4, 1.2, 1.4, 1.0, 1.0, 2.4, 1.2, 2.0, NA…\n$ PRFUD                  &lt;dbl&gt; 3.50, 0.00, 1.25, 0.50, 0.00, 0.00, 0.50, 2.00,…\n$ CPOPI                  &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 2.7, NA…\n$ CPRPI                  &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 1.33333…\n$ SPOPI                  &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 2.2, NA…\n$ PPPI                   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 2.00000…\n$ PPRPI                  &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 3.25, N…\n$ PRIAP                  &lt;dbl&gt; 2.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0…\n$ FPOPI                  &lt;dbl&gt; 2.333333, 3.666667, 4.000000, 4.000000, 2.66666…\n$ FPRPI                  &lt;dbl&gt; 2.50, 3.75, 3.50, 2.75, 3.25, 3.25, 3.00, 3.75,…\n$ SPRPI                  &lt;dbl&gt; 1.00, 2.50, 2.00, 3.25, 2.25, 2.50, 3.00, 2.75,…\n$ CRCDO                  &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 2.4, NA…\n$ CRPAG                  &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 2, NA, …\n$ FRFAB                  &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, 1.750000, NA, N…\n$ PREAB                  &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 0, NA, …\n$ PRRAI                  &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 1.00000…\n$ PPIPP                  &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 3.2, NA…\n$ FRFC                   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, 2.666667, NA, 2…\n$ FRPAB                  &lt;dbl&gt; 1.666667, 1.000000, 1.666667, 1.000000, 1.00000…\n$ PRGI                   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, 2, NA, 0, 0, 0,…\n$ P16A                   &lt;fct&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ P16A1                  &lt;chr&gt; \"                                              …\n$ P16A10                 &lt;chr&gt; \"                  \", \"                  \", \"  …\n$ P16B                   &lt;fct&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ P16B1                  &lt;chr&gt; \"                                              …\n$ P16B10                 &lt;chr&gt; \"                  \", \"                  \", \"  …\n$ POC                    &lt;dbl&gt; NA, NA, 0, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ P16C                   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ CSID                   &lt;chr&gt; \"                                          \", \"…\n$ ENCUES02               &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, 0, NA, NA, NA, …\n$ ENCUESTA               &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, 31, NA, 212207,…\n$ base                   &lt;fct&gt; NA, NA, NA, NA, NA, NA, NA, NA, lanziano, NA, N…\n$ ETNIA                  &lt;fct&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ CUESTION               &lt;fct&gt; NA, NA, NA, NA, NA, NA, NA, NA, 3, NA, B, 3, 3,…\n$ ELIMINAR               &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, NA, NA, 0, NA,…\n$ crhdo_rs               &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 1, NA, …\n$ crpag_rs               &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 1, NA, …\n$ frfab_rs               &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, 0, NA, NA, NA, …\n$ preip_rs               &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 0, NA, …\n$ prrai_rs               &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 0, NA, …\n$ cpopi_ps               &lt;fct&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, Below c…\n$ cprpi_ps               &lt;fct&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, Below c…\n$ spopi_ps               &lt;fct&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, Below c…\n$ pppi_ps                &lt;fct&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, Below c…\n$ pprpi_ps               &lt;fct&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, Above c…\n$ frfcn_rs               &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, 1, NA, 1, NA, N…\n$ frpab_rs               &lt;dbl&gt; 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, NA, NA, 0, NA,…\n$ prgan_rs               &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, 1, NA, 0, NA, N…\n$ crpad_NRs              &lt;dbl&gt; 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, NA, NA, NA, 1, NA…\n$ crlnfd_NRs             &lt;dbl&gt; 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, NA, NA, 0, NA,…\n$ FRPFM_NRs              &lt;dbl&gt; 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, NA, NA, NA, 0, NA…\n$ srlcs_NRs              &lt;dbl&gt; 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, NA, NA, 0, NA,…\n$ FRPFD_NRs              &lt;dbl&gt; 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, NA, NA, 0, NA,…\n$ PRPRD_NRs              &lt;dbl&gt; 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, NA, NA, NA, 0, NA…\n$ prata_nrs              &lt;dbl&gt; 1, 0, 0, 1, 0, 0, 1, 0, 1, NA, 0, NA, NA, 1, NA…\n$ PRFAD_NRS              &lt;dbl&gt; 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, NA, NA, 0, NA,…\n$ prfud_nrs              &lt;dbl&gt; 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, NA, NA, 0, NA,…\n$ priap_nrs              &lt;dbl&gt; 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, NA, NA, 0, NA,…\n$ FRPAB_NRS              &lt;dbl&gt; 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, NA, NA, 0, NA,…\n$ FPOPI_NRS              &lt;dbl&gt; 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, NA, NA, NA, 1, NA…\n$ SPRPI_NRS              &lt;dbl&gt; 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, NA, NA, 0, NA,…\n$ FPRPI_NRS              &lt;dbl&gt; 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, NA, NA, 1, NA,…\n$ crlnfd_rs              &lt;dbl&gt; 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, NA, NA, 0, NA,…\n$ crpad_rs               &lt;dbl&gt; 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, NA, NA, NA, 1, NA…\n$ frpfm_rs               &lt;dbl&gt; 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, NA, NA, NA, 0, NA…\n$ frpfd_rs               &lt;dbl&gt; 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, NA, NA, 0, NA,…\n$ srlcs_rs               &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, NA, NA, 0, NA,…\n$ prata_rs               &lt;dbl&gt; 1, 0, 0, 1, 0, 0, 1, 0, 1, NA, 0, NA, NA, 1, NA…\n$ PRFAD_RS               &lt;dbl&gt; 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, NA, NA, 0, NA,…\n$ prprd_rs               &lt;dbl&gt; 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, NA, NA, NA, 0, NA…\n$ priap_rs               &lt;dbl&gt; 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, NA, NA, 1, NA,…\n$ prfud_rs               &lt;dbl&gt; 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, NA, NA, 0, NA,…\n$ PPRPI_NRs2             &lt;dbl&gt; NA, 0, NA, NA, NA, NA, NA, NA, NA, 0, 1, NA, NA…\n$ PRRAI_NRs2             &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 0, NA, …\n$ INSTITUCION            &lt;fct&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ FREQALC30DY            &lt;fct&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 2, …\n$ FREQSM30DY             &lt;fct&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 1, …\n$ FREQMAR30DY            &lt;fct&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 1, …\n$ CLARRULE               &lt;fct&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ SCHLRM                 &lt;fct&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ WRPACIG                &lt;fct&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ FSOLD                  &lt;fct&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ ADSSTEAL               &lt;fct&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ COLLCIG                &lt;fct&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ SAVESCH                &lt;fct&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ AGEGUM                 &lt;fct&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ CARRYIGU               &lt;fct&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ JORNADA                &lt;fct&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ ENJSCHI                &lt;fct&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ WAPASTL                &lt;fct&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ TRVOL                  &lt;fct&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ HONESTIDAD2            &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 0, …\n$ HONESTIDADedad         &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 0, …\n$ CONTROLEDADBRRA        &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 0, …\n$ HONESTIDADEMBORRACHADO &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 0, …\n$ HONESTIDADficty        &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 0, …\n$ Honestidad             &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 3, …\n$ HONESTIDAD3            &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 0, …\n$ HONESTIDAD4            &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 0, …\n$ NOHONS                 &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 0, …\n$ actmean                &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ CRLNFD_NRs2            &lt;dbl&gt; 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0,…\n$ PRFAD_NRs2             &lt;dbl&gt; 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0,…\n$ CRCDO_NRs2             &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 1, NA, …\n$ CRPAG_NRs2             &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 1, NA, …\n$ FRFAB_NRs2             &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, 1, NA, NA, 0, 0…\n$ FRFC_NRs2              &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, 1, NA, 1, 1, 0,…\n$ PREAB_NRs2             &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 0, NA, …\n$ CPOPI_NRs2             &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ FPOPI_NRs2             &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ FPRPI_NRs2             &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ SPOPI_NRs2             &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ PPPI_NRs2              &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ SPRPI_NRs2             &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ GRUPO1                 &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ DROGA                  &lt;dbl&gt; 6, 0, 0, 0, 0, 0, 0, 1, NA, 0, 0, 0, 0, 0, 0, 0…\n$ DROGMES                &lt;dbl&gt; 4, 0, 1, 0, 0, 1, 1, 1, 2, 1, 0, 3, 2, 0, 2, 0,…\n$ DROGMESI               &lt;dbl&gt; 2, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 2, 2, 0, 2, 0,…\n$ DROGY                  &lt;dbl&gt; NA, 0, 1, 1, NA, 1, NA, 3, 2, 1, 1, 1, 0, NA, 0…\n$ ANYANTISO              &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ FRGUNrD                &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ FRSOLDrD               &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ FRSTLrD                &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ FRARSTrD               &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ FRDROPrD               &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ JUICIO67               &lt;dbl&gt; NA, NA, NA, 1, 1, 1, NA, NA, NA, NA, 1, NA, 1, …\n$ JUICIO89               &lt;dbl&gt; 0, 1, NA, NA, NA, NA, 1, NA, NA, 1, NA, 1, NA, …\n$ PROBLEMA89             &lt;dbl&gt; 1, 0, NA, NA, NA, NA, 0, NA, NA, 0, NA, 0, NA, …\n$ JUICIO11               &lt;dbl&gt; NA, NA, 1, NA, NA, NA, NA, 0, NA, NA, NA, NA, N…\n$ PROBLEMA11             &lt;dbl&gt; NA, NA, 0, NA, NA, NA, NA, 1, NA, NA, NA, NA, N…\n$ GRUPO67                &lt;dbl&gt; NA, NA, NA, 0, 0, 0, NA, NA, NA, NA, 0, NA, 0, …\n$ GRUPO89                &lt;dbl&gt; 1, 0, NA, NA, NA, NA, 0, NA, NA, 0, NA, 0, NA, …\n$ GRUPO11                &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ fpopi_ps               &lt;fct&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, Bel…\n$ fprpi_ps               &lt;fct&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, Bel…\n$ sprpi_ps               &lt;fct&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, Bel…\n$ protect                &lt;fct&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, Low…\n$ PROBLEMA67             &lt;dbl&gt; NA, NA, NA, 0, 0, 0, NA, NA, NA, NA, 0, NA, 0, …\n$ OTRO67                 &lt;dbl&gt; NA, NA, NA, 0, 0, 0, NA, NA, NA, NA, 0, NA, 0, …\n$ GRUPO1011              &lt;dbl&gt; NA, NA, 0, NA, NA, NA, NA, 1, NA, NA, NA, NA, N…\n$ PRRAI_BH               &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 0, NA, …\n$ SRLCS_BH               &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, NA, 0…\n$ CRLNFD_BH              &lt;dbl&gt; 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0,…\n$ PRATA_BH               &lt;dbl&gt; 1, 0, 0, 1, 0, 0, 1, 0, 1, NA, 0, 0, 0, 1, 0, 0…\n$ PRFAD_BH               &lt;dbl&gt; 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1,…\n$ FRPFD_BH               &lt;dbl&gt; 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,…\n$ CRPAD_BH               &lt;dbl&gt; 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, NA, 0, 0, 1, 0, 0…\n$ FRPAB_BH               &lt;dbl&gt; 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1,…\n$ FRPFM_BH               &lt;dbl&gt; 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, NA, 0, 1, 0, 0, 0…\n$ CRPAG_BH               &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 1, NA, …\n$ FRFAB_BH               &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, 0, NA, NA, 0, 0…\n$ FRFC_BH                &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, 1, NA, 1, 1, 0,…\n$ PRPRD_BH               &lt;dbl&gt; 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, NA, 1, 1, 0, 1, 0…\n$ PRFUD_BH               &lt;dbl&gt; 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0,…\n$ PRGI_BH                &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, 1, NA, 0, 0, 0,…\n$ CRCDO_BH               &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 1, NA, …\n$ PREAB_BH               &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 0, NA, …\n$ PRIAP_BH               &lt;dbl&gt; 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0,…\n$ SRLCS_MAD6             &lt;dbl&gt; NA, NA, NA, 0.2857286, NA, NA, NA, NA, NA, NA, …\n$ SRLCS_MAD7             &lt;dbl&gt; NA, NA, NA, NA, 4.285714e-05, 1.429000e-01, NA,…\n$ SRLCS_MAD8             &lt;dbl&gt; NA, 0.1428571, NA, NA, NA, NA, NA, NA, NA, 0.14…\n$ SRLCS_MAD9             &lt;dbl&gt; 0.4285714, NA, NA, NA, NA, NA, 0.2857143, NA, N…\n$ SRLCS_MAD10            &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, 0.1429000, 0.635433…\n$ SRLCS_MAD11            &lt;dbl&gt; NA, NA, 0.2857143, NA, NA, NA, NA, NA, NA, NA, …\n$ SRLCS_G6N              &lt;dbl&gt; NA, NA, NA, 1.8254, NA, NA, NA, NA, NA, NA, NA,…\n$ SRLCS_NRs3             &lt;dbl&gt; 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, NA, 0…\n$ SRLCS_G7N              &lt;dbl&gt; NA, NA, NA, NA, 1.971025, 1.971025, NA, NA, NA,…\n$ SRLCS_G8N              &lt;dbl&gt; NA, 2.1179, NA, NA, NA, NA, NA, NA, NA, 2.1179,…\n$ SRLCS_G9N              &lt;dbl&gt; 2.1137, NA, NA, NA, NA, NA, 2.1137, NA, NA, NA,…\n$ SRLCS_G10N             &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, 2.2557, 2.2557, NA,…\n$ SRLCS_G11N             &lt;dbl&gt; NA, NA, 2.108425, NA, NA, NA, NA, NA, NA, NA, N…\n$ CPOPI_MAD6             &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ CPOPI_MAD7             &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 0.2, NA…\n$ CPOPI_MAD8             &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ CPOPI_MAD9             &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ CPOPI_MAD10            &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ CPOPI_MAD11            &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ CPOPI_G6N              &lt;dbl&gt; NA, NA, NA, 2.628175, NA, NA, NA, NA, NA, NA, N…\n$ CPOPI_G7N              &lt;dbl&gt; NA, NA, NA, NA, 2.62305, 2.62305, NA, NA, NA, N…\n$ CPOPI_G8N              &lt;dbl&gt; NA, 2.61985, NA, NA, NA, NA, NA, NA, NA, 2.6198…\n$ CPOPI_G9N              &lt;dbl&gt; 2.61255, NA, NA, NA, NA, NA, 2.61255, NA, NA, N…\n$ CPOPI_G10N             &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, 2.61495, 2.61495, N…\n$ CPOPI_G11N             &lt;dbl&gt; NA, NA, 2.712075, NA, NA, NA, NA, NA, NA, NA, N…\n$ CPOPI_NRs3             &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 1, NA, …\n$ FPOPI_MAD6             &lt;dbl&gt; NA, NA, NA, 0.6667000, NA, NA, NA, NA, NA, NA, …\n$ FPOPI_MAD7             &lt;dbl&gt; NA, NA, NA, NA, 0.6666333, 0.6667000, NA, NA, N…\n$ FPOPI_MAD8             &lt;dbl&gt; NA, 0.6666667, NA, NA, NA, NA, NA, NA, NA, 0.66…\n$ FPOPI_MAD9             &lt;dbl&gt; 0.6666667, NA, NA, NA, NA, NA, 0.3333333, NA, N…\n$ FPOPI_MAD10            &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, 1.0000000, 0.333333…\n$ FPOPI_MAD11            &lt;dbl&gt; NA, NA, 1, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ FPOPI_G6N              &lt;dbl&gt; NA, NA, NA, 3.4741, NA, NA, NA, NA, NA, NA, NA,…\n$ FPOPI_G7N              &lt;dbl&gt; NA, NA, NA, NA, 3.473625, 3.473625, NA, NA, NA,…\n$ FPOPI_G8N              &lt;dbl&gt; NA, 3.143225, NA, NA, NA, NA, NA, NA, NA, 3.143…\n$ FPOPI_G9N              &lt;dbl&gt; 3.141725, NA, NA, NA, NA, NA, 3.141725, NA, NA,…\n$ FPOPI_G10N             &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, 3.146325, 3.146325,…\n$ FPOPI_G11N             &lt;dbl&gt; NA, NA, 3.1413, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ FPOPI_NRs3             &lt;dbl&gt; 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, NA, 0, 0, 1, 0, 1…\n$ FPRPI_MAD6             &lt;dbl&gt; NA, NA, NA, 0.5, NA, NA, NA, NA, NA, NA, NA, NA…\n$ FPRPI_MAD7             &lt;dbl&gt; NA, NA, NA, NA, 0.00, 0.00, NA, NA, NA, NA, 1.2…\n$ FPRPI_MAD8             &lt;dbl&gt; NA, 0.75, NA, NA, NA, NA, NA, NA, NA, 1.00, NA,…\n$ FPRPI_MAD9             &lt;dbl&gt; 0.50, NA, NA, NA, NA, NA, 0.00, NA, NA, NA, NA,…\n$ FPRPI_MAD10            &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, 0.75, 0.00, NA, NA,…\n$ FPRPI_MAD11            &lt;dbl&gt; NA, NA, 0.5, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ FPRPI_G6N              &lt;dbl&gt; NA, NA, NA, 3.385175, NA, NA, NA, NA, NA, NA, N…\n$ FPRPI_G7N              &lt;dbl&gt; NA, NA, NA, NA, 3.383675, 3.383675, NA, NA, NA,…\n$ FPRPI_G8N              &lt;dbl&gt; NA, 3.1356, NA, NA, NA, NA, NA, NA, NA, 3.1356,…\n$ FPRPI_G9N              &lt;dbl&gt; 3.132525, NA, NA, NA, NA, NA, 3.132525, NA, NA,…\n$ FPRPI_G10N             &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, 3.1307, 3.1307, NA,…\n$ FPRPI_G11N             &lt;dbl&gt; NA, NA, 3.1307, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ FPRPI_NRs3             &lt;dbl&gt; 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1,…\n$ CRPAG_NRs              &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n\n\n\n\n\n\n\n\n\nTip\n\n\n\n|&gt;: se puede leer como “siguiente”. Este operador se utiliza para encadenar varias operaciones juntas en una sola línea de código. En este caso, se utiliza para encadenar los datos los_datos a la función glimpse().\nglimpse(): imprimir una vista previa de los datos, incluyendo el tipo de datos de cada columna y algunos valores. En este caso, se utiliza para explorar los datos almacenados en el objeto “los_datos”."
  },
  {
    "objectID": "archive/2024-02-konrad/2-procesamiento.html#select",
    "href": "archive/2024-02-konrad/2-procesamiento.html#select",
    "title": "2. Procesamiento de datos con tidyverse",
    "section": "select()",
    "text": "select()\nEsta función selecciona columnas de una base de datos.\nEn este ejemplo, quiero una nueva base de datos que tenga la variable NHPROUD (“Hay gente en mi barrio que se siente orgullosa de mí cuando hago algo bien”)\n\n\nlos_datos |&gt; \n  select(NHPROUD) |&gt;\n  distinct()\n\n# A tibble: 5 × 1\n  NHPROUD\n  &lt;fct&gt;  \n1 &lt;NA&gt;   \n2 1      \n3 2      \n4 3      \n5 4      \n\n\n\n\n\n\n\n\n\nTip\n\n\n\nselect(): seleccionar columnas específicas de un data frame. En este caso, se utiliza para seleccionar la columna “NHPROUD” del objeto “los_datos”.\ndistinct(): eliminar filas duplicadas de un data frame. En este caso, se utiliza para eliminar filas duplicadas de la columna “NHPROUD” del objeto “los_datos”."
  },
  {
    "objectID": "archive/2024-02-konrad/2-procesamiento.html#select-1",
    "href": "archive/2024-02-konrad/2-procesamiento.html#select-1",
    "title": "2. Procesamiento de datos con tidyverse",
    "section": "select()",
    "text": "select()\nSeleccionar las variables GENDER, AWRMAR, AWRALC, AWRCIG\n\nGENDER: Sexo\n\n“Qué tan mal ven la mayoría de los adultos de tu barrio (aquellos más cercanos a ti) el que los jóvenes de tu edad…”\n\nAWRMAR = fumen marihuana\nAWRALC = Consuman alcohol\nAWRCIG = fumen cigarrillo\n\n\nlos_datos |&gt; \n  select(GENDER, AWRMAR, AWRALC, AWRCIG)\n\n# A tibble: 23,220 × 4\n   GENDER    AWRMAR     AWRALC     AWRCIG       \n   &lt;fct&gt;     &lt;fct&gt;      &lt;fct&gt;      &lt;fct&gt;        \n 1 Femenino  No tan mal No tan mal Para nada mal\n 2 Masculino Muy mal    No tan mal Mal          \n 3 Femenino  Muy mal    Mal        Muy mal      \n 4 Femenino  Muy mal    Muy mal    Muy mal      \n 5 Masculino Muy mal    Muy mal    Muy mal      \n 6 Femenino  Muy mal    Muy mal    Muy mal      \n 7 Femenino  Mal        No tan mal Para nada mal\n 8 Femenino  Muy mal    Mal        Muy mal      \n 9 Masculino Muy mal    No tan mal &lt;NA&gt;         \n10 Masculino Muy mal    No tan mal Muy mal      \n# ℹ 23,210 more rows"
  },
  {
    "objectID": "archive/2024-02-konrad/2-procesamiento.html#mutate",
    "href": "archive/2024-02-konrad/2-procesamiento.html#mutate",
    "title": "2. Procesamiento de datos con tidyverse",
    "section": "mutate()",
    "text": "mutate()\nEsta función crea una nueva variable -añade una nueva columna a la base de datos- o tranforma una variable que esté presente en la base de datos.\nPor ejemplo, si quiero transformar las tres variables del ejemplo anterior para asignar un puntaje de las percepciones de los estudiantes sobre las creencias de los adultos…\n¿Qué debo hacer?\n\nTransformar el valor que hay en la base por los valores: 1, 2, 3 y 4.\nCrear una nueva variable que calcule la media de los puntajes."
  },
  {
    "objectID": "archive/2024-02-konrad/2-procesamiento.html#mutate-1",
    "href": "archive/2024-02-konrad/2-procesamiento.html#mutate-1",
    "title": "2. Procesamiento de datos con tidyverse",
    "section": "mutate()",
    "text": "mutate()\nLas funciones en R son sus mejores amigas y pueden hacer mucho por usted. En este caso, la función transformar_respuesta toma un argumento x y devuelve un valor numérico en función de la comparación de x con los valores de mi diccionario.\n\n\ntransformar_respuesta &lt;- function(x) {\n  case_when(\n    x == \"Muy mal\" ~ 1,\n    x == \"Mal\" ~ 2,\n    x == \"Notan mal\" ~ 3,\n    x == \"Para nada mal\" ~ 4,\n    TRUE ~ NA_real_\n  )\n}"
  },
  {
    "objectID": "archive/2024-02-konrad/2-procesamiento.html#mutate-2",
    "href": "archive/2024-02-konrad/2-procesamiento.html#mutate-2",
    "title": "2. Procesamiento de datos con tidyverse",
    "section": "mutate()",
    "text": "mutate()\nCalcular el promedio de las tres variables\n\nlos_datos |&gt; \n  select(AWRMAR, AWRALC, AWRCIG) |&gt; \n  mutate(across(everything(), transformar_respuesta)) |&gt; \n  mutate(TOTAL = (AWRMAR + AWRALC + AWRCIG)/3)\n\n# A tibble: 23,220 × 4\n   AWRMAR AWRALC AWRCIG TOTAL\n    &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;\n 1     NA     NA      4 NA   \n 2      1     NA      2 NA   \n 3      1      2      1  1.33\n 4      1      1      1  1   \n 5      1      1      1  1   \n 6      1      1      1  1   \n 7      2     NA      4 NA   \n 8      1      2      1  1.33\n 9      1     NA     NA NA   \n10      1     NA      1 NA   \n# ℹ 23,210 more rows\n\n\n\n\n\n\n\n\n\nTip\n\n\n\ncase_when(): realizar una serie de comparaciones y asignar valores en función de las comparaciones. En este caso, se utiliza para asignar un valor numérico a la columna “AWRMAR” del objeto “los_datos” en función de los valores del diccionario.\nacross(): aplicar una función a varias columnas de un data frame. En este caso, se utiliza para aplicar la función transformar_respuesta() a todas las columnas del objeto “los_datos”.\neverything(): seleccionar todas las columnas de un data frame o tibble. En este caso, se utiliza para aplicar la función transformar_respuesta() a todas las columnas del objeto “los_datos”."
  },
  {
    "objectID": "archive/2024-02-konrad/2-procesamiento.html#filter",
    "href": "archive/2024-02-konrad/2-procesamiento.html#filter",
    "title": "2. Procesamiento de datos con tidyverse",
    "section": "filter()",
    "text": "filter()\nPermite seleccionar filas de la base de datos según una condición.\nVoy a utilizar un filtro para seleccionar solamente las filas en las que los adultos respondieron “No tan mal” cuando preguntaron por sus actitudes frente al consumo de marihuana (AWRMAR).\n\n\nlos_datos |&gt; \n  select(GENDER, AWRMAR, AWRALC, AWRCIG) |&gt; \n  filter(AWRMAR == \"No tan mal\")\n\n# A tibble: 1,501 × 4\n   GENDER    AWRMAR     AWRALC        AWRCIG       \n   &lt;fct&gt;     &lt;fct&gt;      &lt;fct&gt;         &lt;fct&gt;        \n 1 Femenino  No tan mal No tan mal    Para nada mal\n 2 Femenino  No tan mal No tan mal    No tan mal   \n 3 Femenino  No tan mal No tan mal    Mal          \n 4 Masculino No tan mal No tan mal    No tan mal   \n 5 Femenino  No tan mal No tan mal    No tan mal   \n 6 Femenino  No tan mal No tan mal    No tan mal   \n 7 Femenino  No tan mal No tan mal    No tan mal   \n 8 Masculino No tan mal No tan mal    Para nada mal\n 9 Masculino No tan mal No tan mal    &lt;NA&gt;         \n10 Masculino No tan mal Para nada mal No tan mal   \n# ℹ 1,491 more rows\n\n\n\nCon este filtro puedo ver que en los primeros 10 casos, cuando un adulto seleccionó que no está tan mal fumar marihuana, sus respuestas sobre el consumo de alcohol y cigarrillo parecen seguir un patrón similar."
  },
  {
    "objectID": "archive/2024-02-konrad/2-procesamiento.html#filter-1",
    "href": "archive/2024-02-konrad/2-procesamiento.html#filter-1",
    "title": "2. Procesamiento de datos con tidyverse",
    "section": "filter()",
    "text": "filter()\nAhora, miremos qué pasa si filtro por la opción “Muy mal”\n\n\nlos_datos |&gt; \n  select(GENDER, AWRMAR, AWRALC, AWRCIG) |&gt; \n  filter(AWRMAR == \"Muy mal\")\n\n# A tibble: 15,480 × 4\n   GENDER    AWRMAR  AWRALC     AWRCIG \n   &lt;fct&gt;     &lt;fct&gt;   &lt;fct&gt;      &lt;fct&gt;  \n 1 Masculino Muy mal No tan mal Mal    \n 2 Femenino  Muy mal Mal        Muy mal\n 3 Femenino  Muy mal Muy mal    Muy mal\n 4 Masculino Muy mal Muy mal    Muy mal\n 5 Femenino  Muy mal Muy mal    Muy mal\n 6 Femenino  Muy mal Mal        Muy mal\n 7 Masculino Muy mal No tan mal &lt;NA&gt;   \n 8 Masculino Muy mal No tan mal Muy mal\n 9 Femenino  Muy mal Muy mal    &lt;NA&gt;   \n10 &lt;NA&gt;      Muy mal Muy mal    Muy mal\n# ℹ 15,470 more rows\n\n\n\nComo en el ejemplo anterior, se observa que el patrón de respuestas es más o menos consistente.\n\n\n\n\n\n\nTip\n\n\n\nfilter(): seleccionar filas específicas de un data frame en función de una o varias condiciones. En este caso, se utiliza para seleccionar las filas del objeto “los_datos” en las que la columna “AWRMAR” es igual a “No tan mal”."
  },
  {
    "objectID": "archive/2024-02-konrad/2-procesamiento.html#summarize",
    "href": "archive/2024-02-konrad/2-procesamiento.html#summarize",
    "title": "2. Procesamiento de datos con tidyverse",
    "section": "summarize()",
    "text": "summarize()\nEsta función permiten obtener medidas de resumen de la base de datos, como por ejemplo, la media, moda, frecuencias, desviación estándar, etc.\n\n\n# Para marihuana\n\nlos_datos |&gt; \n  select(GENDER, AWRMAR, AWRALC, AWRCIG) |&gt; \n  mutate(across(starts_with(\"A\"),transformar_respuesta)) |&gt; \n  summarise(mean_AWRMAR = mean(AWRMAR, na.rm = TRUE),\n            sd_AWRMAR = sd(AWRMAR, na.rm = TRUE), \n            max_AWRMAR = max(AWRMAR, na.rm = TRUE), \n            min_AWRMAR = min(AWRMAR, na.rm = TRUE))\n\n# A tibble: 1 × 4\n  mean_AWRMAR sd_AWRMAR max_AWRMAR min_AWRMAR\n        &lt;dbl&gt;     &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;\n1        1.39     0.792          4          1\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nsummarise(): calcular medidas de resumen de un data frame. En este caso, se utiliza para obtener la media, la desviación estándar, el valor máximo y el valor mínimo de la columna “AWRMAR” del objeto “los_datos”.\nstarts_with(): seleccionar columnas que comienzan con un determinado prefijo. En este caso, se utiliza para seleccionar las columnas que comienzan con “A” del objeto “los_datos”."
  },
  {
    "objectID": "archive/2024-02-konrad/2-procesamiento.html#explorar-los-datos-1",
    "href": "archive/2024-02-konrad/2-procesamiento.html#explorar-los-datos-1",
    "title": "2. Procesamiento de datos con tidyverse",
    "section": "Explorar los datos 1",
    "text": "Explorar los datos 1\n\nCrear un subset con las variables de interés\n\n\nfactores_de_riesgo &lt;- c(\"CRPAD\", \"CRLNFD\", \"FRPFD\", \"FRPFM\", \"SRLCS\", \"PRFAD\", \"PRATA\", \"PRFUD\", \"PRIAP\", \"FPOPI\", \"FPRPI\", \"SPRPI\")\ndemograficas &lt;- c(\"YEAR\", \"GRADE\", \"GENDER\", \"AGE\")\nconsumo_alcohol &lt;- c(\"PYALC\")\n\n\nObservar las variables de interés\n\n\nlos_datos  |&gt; \n  select(all_of(factores_de_riesgo), \n         all_of(demograficas), \n         all_of(consumo_alcohol))  |&gt; \n  glimpse()\n\nRows: 23,220\nColumns: 17\n$ CRPAD  &lt;dbl&gt; 4.00, 2.75, 2.25, 1.50, 4.00, 2.00, 1.50, 3.25, 2.50, 2.00, NA,…\n$ CRLNFD &lt;dbl&gt; 3.166667, 2.666667, 1.833333, 1.833333, 2.000000, 2.000000, 3.3…\n$ FRPFD  &lt;dbl&gt; 1.000000, 1.000000, 1.666667, 1.666667, 1.000000, 1.000000, 1.3…\n$ FRPFM  &lt;dbl&gt; 2.000000, 1.250000, 1.250000, 2.428571, 1.625000, 1.000000, 1.8…\n$ SRLCS  &lt;dbl&gt; 2.142857, 2.428571, 2.571429, 1.714286, 1.857143, 1.714286, 1.7…\n$ PRFAD  &lt;dbl&gt; 3.25, 1.00, 1.00, 2.00, 1.00, 1.00, 1.25, 3.00, 1.75, 1.50, 1.7…\n$ PRATA  &lt;dbl&gt; 2.2, 1.4, 1.2, 1.4, 1.0, 1.0, 2.4, 1.2, 2.0, NA, 1.0, 1.2, 1.2,…\n$ PRFUD  &lt;dbl&gt; 3.50, 0.00, 1.25, 0.50, 0.00, 0.00, 0.50, 2.00, 0.25, 1.00, 0.0…\n$ PRIAP  &lt;dbl&gt; 2.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 1.000000…\n$ FPOPI  &lt;dbl&gt; 2.333333, 3.666667, 4.000000, 4.000000, 2.666667, 4.000000, 2.6…\n$ FPRPI  &lt;dbl&gt; 2.50, 3.75, 3.50, 2.75, 3.25, 3.25, 3.00, 3.75, 3.00, 4.00, 2.0…\n$ SPRPI  &lt;dbl&gt; 1.00, 2.50, 2.00, 3.25, 2.25, 2.50, 3.00, 2.75, 2.50, 3.25, 2.0…\n$ YEAR   &lt;fct&gt; 2014, 2012-2013, 2012-2013, 2014, 2014, 2014, 2012-2013, 2012-2…\n$ GRADE  &lt;dbl&gt; 9, 8, 11, 6, 7, 7, 9, 10, 10, 8, 7, 9, 7, 9, 6, 9, 8, 8, 7, 6, …\n$ GENDER &lt;fct&gt; Femenino, Masculino, Femenino, Femenino, Masculino, Femenino, F…\n$ AGE    &lt;dbl&gt; 16, 12, 17, 11, 13, 12, 14, 16, 16, 15, 13, 14, 15, 14, 12, 13,…\n$ PYALC  &lt;fct&gt; Sí ha consumido, No ha consumido, Sí ha consumido, Sí ha consum…"
  },
  {
    "objectID": "archive/2024-02-konrad/2-procesamiento.html#explorar-los-datos-1-1",
    "href": "archive/2024-02-konrad/2-procesamiento.html#explorar-los-datos-1-1",
    "title": "2. Procesamiento de datos con tidyverse",
    "section": "Explorar los datos 1",
    "text": "Explorar los datos 1\n\nGuardo las variables de interés en un nuevo objeto\n\n\nmini_datos &lt;- los_datos %&gt;% \n  select(all_of(factores_de_riesgo), \n         all_of(demograficas), \n         all_of(consumo_alcohol)) \n\n\nDoy una mirada más general de los datos\n\n\nmini_datos |&gt; \n  skimr::skim()\n\n\nData summary\n\n\nName\nmini_datos\n\n\nNumber of rows\n23220\n\n\nNumber of columns\n17\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\nfactor\n3\n\n\nnumeric\n14\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: factor\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nordered\nn_unique\ntop_counts\n\n\n\n\nYEAR\n0\n1.00\nFALSE\n5\n201: 7136, 201: 5842, 201: 4241, 201: 3237\n\n\nGENDER\n471\n0.98\nFALSE\n2\nFem: 11739, Mas: 11010\n\n\nPYALC\n548\n0.98\nFALSE\n2\nSí : 15615, No : 7057\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nCRPAD\n5054\n0.78\n2.09\n0.85\n1.0\n1.25\n2.00\n2.75\n4.00\n▇▃▅▃▂\n\n\nCRLNFD\n400\n0.98\n2.19\n0.54\n1.0\n1.83\n2.17\n2.50\n4.00\n▃▇▆▂▁\n\n\nFRPFD\n1817\n0.92\n1.36\n0.49\n1.0\n1.00\n1.00\n1.67\n4.00\n▇▃▁▁▁\n\n\nFRPFM\n3972\n0.83\n1.73\n0.55\n0.0\n1.25\n1.71\n2.00\n4.00\n▁▇▇▁▁\n\n\nSRLCS\n514\n0.98\n2.18\n0.44\n1.0\n1.86\n2.14\n2.43\n4.86\n▂▇▂▁▁\n\n\nPRFAD\n294\n0.99\n1.70\n0.67\n1.0\n1.00\n1.50\n2.00\n4.00\n▇▅▂▁▁\n\n\nPRATA\n4130\n0.82\n1.52\n0.59\n1.0\n1.00\n1.40\n1.80\n4.00\n▇▂▁▁▁\n\n\nPRFUD\n4135\n0.82\n0.95\n0.97\n0.0\n0.00\n0.75\n1.50\n4.00\n▇▃▂▁▁\n\n\nPRIAP\n1220\n0.95\n0.30\n0.53\n-0.2\n0.00\n0.17\n0.40\n4.00\n▇▁▁▁▁\n\n\nFPOPI\n5430\n0.77\n3.17\n0.72\n1.0\n2.67\n3.33\n3.67\n4.00\n▁▁▃▇▇\n\n\nFPRPI\n6169\n0.73\n3.05\n0.67\n1.0\n2.50\n3.00\n3.50\n4.00\n▁▂▆▆▇\n\n\nSPRPI\n6647\n0.71\n2.78\n0.65\n1.0\n2.50\n2.75\n3.25\n4.00\n▁▂▇▆▃\n\n\nGRADE\n715\n0.97\n8.24\n1.68\n6.0\n7.00\n8.00\n10.00\n11.00\n▇▃▃▃▂\n\n\nAGE\n506\n0.98\n15.00\n8.63\n10.0\n13.00\n14.00\n16.00\n99.00\n▇▁▁▁▁\n\n\n\n\n\n\n\n\nMachine Learning"
  },
  {
    "objectID": "archive/2024-02-konrad/4-arboles.html#agenda",
    "href": "archive/2024-02-konrad/4-arboles.html#agenda",
    "title": "4. Árboles de decisión",
    "section": "Agenda",
    "text": "Agenda\n\n¿Qué es un árbol de decisión?\n¿Cómo se construye un árbol de decisión?\n¿Cómo se evalúa un árbol de decisión?\n¿Cómo se elige un árbol de decisión?"
  },
  {
    "objectID": "archive/2024-02-konrad/4-arboles.html#árboles-de-decisión",
    "href": "archive/2024-02-konrad/4-arboles.html#árboles-de-decisión",
    "title": "4. Árboles de decisión",
    "section": "Árboles de decisión",
    "text": "Árboles de decisión\nLos árboles de decisión son estructuras parecidas a los diagramas de flujo que utilizan nodos y ramas. Los caminos en el árbol separan los datos de tal manera que se pueda llegar a una separación precisa de un conjunto de datos.\nLos árboles de decisión son útiles porque proporcionan una forma fácil de visualizar y entender cómo se toman las decisiones en un modelo.\n\nNodos: grupo de observaciones que comparten una característica.\nRamas: separación de los nodos.\nHojas: resultado final de la separación."
  },
  {
    "objectID": "archive/2024-02-konrad/4-arboles.html#árboles-de-decisión-1",
    "href": "archive/2024-02-konrad/4-arboles.html#árboles-de-decisión-1",
    "title": "4. Árboles de decisión",
    "section": "Árboles de decisión",
    "text": "Árboles de decisión"
  },
  {
    "objectID": "archive/2024-02-konrad/4-arboles.html#qué-es-un-buen-árbol-de-decisión",
    "href": "archive/2024-02-konrad/4-arboles.html#qué-es-un-buen-árbol-de-decisión",
    "title": "4. Árboles de decisión",
    "section": "¿Qué es un buen árbol de decisión?",
    "text": "¿Qué es un buen árbol de decisión?\nEfectivamente separa las observaciones en grupos homogéneos."
  },
  {
    "objectID": "archive/2024-02-konrad/4-arboles.html#cómo-se-construye-un-árbol-de-decisión",
    "href": "archive/2024-02-konrad/4-arboles.html#cómo-se-construye-un-árbol-de-decisión",
    "title": "4. Árboles de decisión",
    "section": "¿Cómo se construye un árbol de decisión?",
    "text": "¿Cómo se construye un árbol de decisión?\n\n\n\nColor\nTamaño (m)\nAnimal\n\n\n\n\nGris oscuro\n5\nTiburón\n\n\nGris oscuro\n6\nTiburón\n\n\nGris claro\n7\nBallena\n\n\nGris oscuro\n15\nTiburón\n\n\nAzul\n20\nBallena\n\n\nGris claro\n25\nBallena"
  },
  {
    "objectID": "archive/2024-02-konrad/4-arboles.html#cómo-se-construye-un-árbol-de-decisión-1",
    "href": "archive/2024-02-konrad/4-arboles.html#cómo-se-construye-un-árbol-de-decisión-1",
    "title": "4. Árboles de decisión",
    "section": "¿Cómo se construye un árbol de decisión?",
    "text": "¿Cómo se construye un árbol de decisión?\nHay que identificar la variable que mejor separa las ballenas de los tiburones. Comencemos con el color."
  },
  {
    "objectID": "archive/2024-02-konrad/4-arboles.html#cómo-se-construye-un-árbol-de-decisión-2",
    "href": "archive/2024-02-konrad/4-arboles.html#cómo-se-construye-un-árbol-de-decisión-2",
    "title": "4. Árboles de decisión",
    "section": "¿Cómo se construye un árbol de decisión?",
    "text": "¿Cómo se construye un árbol de decisión?\nSi la variable es continua, se pueden tratar todos los valores posibles como puntos de corte."
  },
  {
    "objectID": "archive/2024-02-konrad/4-arboles.html#cómo-se-construye-un-árbol-de-decisión-3",
    "href": "archive/2024-02-konrad/4-arboles.html#cómo-se-construye-un-árbol-de-decisión-3",
    "title": "4. Árboles de decisión",
    "section": "¿Cómo se construye un árbol de decisión?",
    "text": "¿Cómo se construye un árbol de decisión?\nAhora, que tenemos todas las posibles separaciones, ¿cómo elegimos la mejor?\nNecessitamos una métrica para evaluar la calidad de la separación.\n\nEntropía\nGanancia de información\nPureza de Gini\nlog loss\n\nPureza de Gini es una medida para evaluar qué tan mezclados están los datos (pureza). Toma valores desde 0 (perfectamente separados) a 0.5 (completamente revueltos).\nhttps://mlu-explain.github.io/decision-tree/"
  },
  {
    "objectID": "archive/2024-02-konrad/4-arboles.html#cómo-se-construye-un-árbol-de-decisión-4",
    "href": "archive/2024-02-konrad/4-arboles.html#cómo-se-construye-un-árbol-de-decisión-4",
    "title": "4. Árboles de decisión",
    "section": "¿Cómo se construye un árbol de decisión?",
    "text": "¿Cómo se construye un árbol de decisión?\nCrear la base de datos.\n\nlibrary(tibble)\nanimales_marinos &lt;- tibble(\n  Color = c(\"Gris oscuro\", \"Gris oscuro\", \"Gris claro\", \"Gris oscuro\", \"Azul\", \"Gris claro\"),\n  Tamano = c(5, 6, 7, 15, 20, 25),\n  Animal = factor(c(\"Tiburón\", \"Tiburón\", \"Ballena\", \"Tiburón\", \"Ballena\", \"Ballena\"))\n)\n\nEspecificar el modelo.\n\ntree_spec &lt;- \n  decision_tree(cost_complexity=0, \n  min_n=0) |&gt; \n  set_mode(\"classification\") |&gt; \n  set_engine(\"rpart\")"
  },
  {
    "objectID": "archive/2024-02-konrad/4-arboles.html#cómo-se-construye-un-árbol-de-decisión-5",
    "href": "archive/2024-02-konrad/4-arboles.html#cómo-se-construye-un-árbol-de-decisión-5",
    "title": "4. Árboles de decisión",
    "section": "¿Cómo se construye un árbol de decisión?",
    "text": "¿Cómo se construye un árbol de decisión?\nEstimar el modelo.\n\ntree_results &lt;- tree_spec |&gt;\n    fit(Animal ~ ., data = animales_marinos)\n\nVisualizar los resultados.\n\ncart_tree_fit &lt;- tree_results$fit\n\ntreemisc::tree_diagram(cart_tree_fit, roundint = FALSE)"
  },
  {
    "objectID": "archive/2024-02-konrad/4-arboles.html#cómo-se-construye-un-árbol-de-decisión-6",
    "href": "archive/2024-02-konrad/4-arboles.html#cómo-se-construye-un-árbol-de-decisión-6",
    "title": "4. Árboles de decisión",
    "section": "¿Cómo se construye un árbol de decisión?",
    "text": "¿Cómo se construye un árbol de decisión?\n\ntree_results &lt;- tree_spec |&gt;\n    fit(Animal ~ Tamano, data = animales_marinos)\n\n\ncart_tree_fit &lt;- tree_results$fit\n\ntreemisc::tree_diagram(cart_tree_fit, roundint = FALSE)"
  },
  {
    "objectID": "archive/2024-02-konrad/4-arboles.html#arbusto",
    "href": "archive/2024-02-konrad/4-arboles.html#arbusto",
    "title": "4. Árboles de decisión",
    "section": "Arbusto",
    "text": "Arbusto\nCrear un árbol de decisión con algunos predictores.\nSeleccionar los predictores.\n\nlos_datos &lt;- DataWorkshopKL::base_NR\n\nmi_primer_arbol &lt;- los_datos |&gt; \n  select(\"PYALC\", \"GETALC\", \"GENDER\", \"GRADE\") \n\nEspecificar el modelo.\n\ntree_spec &lt;- \n  decision_tree() |&gt; \n  set_mode(\"classification\") |&gt; \n  set_engine(\"rpart\")"
  },
  {
    "objectID": "archive/2024-02-konrad/4-arboles.html#estimar-el-modelo",
    "href": "archive/2024-02-konrad/4-arboles.html#estimar-el-modelo",
    "title": "4. Árboles de decisión",
    "section": "Estimar el modelo",
    "text": "Estimar el modelo\nEstimar el modelo\n\ntree_results &lt;- tree_spec |&gt;\n    fit(PYALC ~ ., data = mi_primer_arbol)\n\nVisualizar el árbol.\n\ncart_tree_fit &lt;- tree_results$fit\n\ntreemisc::tree_diagram(cart_tree_fit, roundint = FALSE)"
  },
  {
    "objectID": "archive/2024-02-konrad/4-arboles.html#árboles-de-clasificación-y-regresión-cart",
    "href": "archive/2024-02-konrad/4-arboles.html#árboles-de-clasificación-y-regresión-cart",
    "title": "4. Árboles de decisión",
    "section": "Árboles de clasificación y regresión (CART)",
    "text": "Árboles de clasificación y regresión (CART)\nAhora, utilicemos todos los datos de la base de entrenamiento.\n\ntree_results &lt;- tree_spec |&gt;\n  fit(PYALC ~ ., data = datos_entrenamiento)\n\nCalcular las métricas de desempeño del modelo.\n\npredict(tree_results, predecir_estos_valores)\n\nentrenamiento &lt;- datos_entrenamiento %&gt;%\n  select(-PYALC)\n\nprediccion_tree &lt;- predict(tree_results, entrenamiento)\n\nresultados_prueba_tree &lt;- cbind(prediccion_tree, datos_entrenamiento) |&gt;\nselect(PYALC, .pred_class) |&gt;\n  tibble()"
  },
  {
    "objectID": "archive/2024-02-konrad/4-arboles.html#calcular-las-métrcias",
    "href": "archive/2024-02-konrad/4-arboles.html#calcular-las-métrcias",
    "title": "4. Árboles de decisión",
    "section": "Calcular las métrcias",
    "text": "Calcular las métrcias\nCalcular las metricas que nos interesan.\n\ntree_metrics &lt;- custom_metrics(resultados_prueba_tree,\n  truth = PYALC,\n  estimate = .pred_class\n) |&gt;\n  mutate(model = \"Árbol\")\n\nPoner las métricas en un formato más fácil de comparar.\n\nrbind(tree_metrics, lm_metrics) |&gt;\n  pivot_wider(names_from = model, values_from = .estimate)"
  },
  {
    "objectID": "archive/2024-02-konrad/4-arboles.html#qué-es-un-hiperparámetro",
    "href": "archive/2024-02-konrad/4-arboles.html#qué-es-un-hiperparámetro",
    "title": "4. Árboles de decisión",
    "section": "¿Qué es un hiperparámetro?",
    "text": "¿Qué es un hiperparámetro?\nLos hiperparámetros son valores para los modelos que se pueden ajustar y que permiten controlar el proceso de entrenamiento de un modelo.\nEl proceso de selección de los hiperparámetros se llama ajuste de hiperparámetros (tunning) y se puede hacer de forma manual o automática.\nPor ahora, vamos a hacerlo de forma manual.\n\ntree_spec &lt;- \n  decision_tree(min_n = 3, cost_complexity = 0.001) |&gt;\n  set_mode(\"classification\") |&gt;\n  set_engine(\"rpart\")\n\nEstimar el modelo.\n\ntree_h_results &lt;- tree_spec |&gt;\n    fit(PYALC ~ ., data = datos_entrenamiento)"
  },
  {
    "objectID": "archive/2024-02-konrad/4-arboles.html#calcular-las-métricas",
    "href": "archive/2024-02-konrad/4-arboles.html#calcular-las-métricas",
    "title": "4. Árboles de decisión",
    "section": "Calcular las métricas",
    "text": "Calcular las métricas\nCalcular las métricas que nos interesan.\n\ntree_h_predicciones &lt;- predict(tree_h_results, entrenamiento)\n\nresultados_tree_h &lt;- cbind(tree_h_predicciones, datos_entrenamiento) |&gt;\n  tibble()\n\ntree_h_metrics &lt;- custom_metrics(\n  resultados_tree_h,\n  truth = PYALC,\n  estimate = .pred_class\n) |&gt;\n  mutate(model = \"Árbol hiperparámetros\")\n\nTabla de métricas\n\nrbind(lm_metrics, tree_metrics, tree_h_metrics) |&gt;\n  pivot_wider(names_from = model, values_from = .estimate)"
  },
  {
    "objectID": "archive/2024-02-konrad/4-arboles.html#por-qué-es-malo",
    "href": "archive/2024-02-konrad/4-arboles.html#por-qué-es-malo",
    "title": "4. Árboles de decisión",
    "section": "¿Por qué es malo?",
    "text": "¿Por qué es malo?\nEl objetivo es encontrar un modelo que no solo sea buena en los datos de entrenamiento, sino que también sea bueno en datos futuros. Si solo evaluamos el modelo en los datos de entrenamiento, no sabemos si el modelo es bueno en datos futuros.\n\ndatos_prueba_out &lt;- \n  datos_prueba |&gt; \n    select(PYALC) \n\nlm_predicciones &lt;- cbind(predict(lm_results, datos_prueba), datos_prueba_out)|&gt; mutate(model=\"lm\")\n\ntree_predicciones &lt;- cbind(predict(tree_results, datos_prueba), datos_prueba_out)|&gt; mutate(model=\"Árbol\")\n\ntree_h_predicciones &lt;- cbind(predict(tree_h_results, datos_prueba), datos_prueba_out) |&gt;  mutate(model=\"Árbol hiperparámetros\")"
  },
  {
    "objectID": "archive/2024-02-konrad/4-arboles.html#desempeño-de-los-modelos",
    "href": "archive/2024-02-konrad/4-arboles.html#desempeño-de-los-modelos",
    "title": "4. Árboles de decisión",
    "section": "Desempeño de los modelos",
    "text": "Desempeño de los modelos\n\nall_models &lt;- \nrbind(lm_predicciones, tree_predicciones, tree_h_predicciones) \n\nall_models\n\nTabla con todos los modelos\n\nall_models_prueba &lt;- all_models |&gt; \n  group_split(model) %&gt;%\n   setNames(unique(all_models$model)) %&gt;%\n  map_dfr(., ~custom_metrics(.x,\n               truth = PYALC,\n               estimate = .pred_class), .id = \"names\")\n\nall_models_prueba |&gt; \n  pivot_wider(names_from = names, values_from = .estimate)"
  },
  {
    "objectID": "archive/2024-02-konrad/index.html",
    "href": "archive/2024-02-konrad/index.html",
    "title": "Bienvenidos",
    "section": "",
    "text": "Le damos la bienvenida a este taller que se llevará a cabo en la Fundación Universitaria Konrad Lorenz. los días 26 y 27 de febrero. En el taller nos enfocaremos en algunas de las técnicas de aprendizaje automático más utilizadas en la actualidad. En esta página, hemos compilado todos los materiales necesarios para cada sesión. Esperamos que estos recursos diseñados especialmente para ustedes sean de su agrado.\nEn este taller vamos a trabajar sobre tres ideas principales:\n\nError de generalización\nEquilibrio entre la varianza y el sesgo\nRegularización"
  },
  {
    "objectID": "archive/2024-02-konrad/index.html#pasos-previos-al-taller",
    "href": "archive/2024-02-konrad/index.html#pasos-previos-al-taller",
    "title": "Bienvenidos",
    "section": "Pasos previos al taller",
    "text": "Pasos previos al taller\nPara aprovechar al máximo este taller, es necesario completar las siguientes tareas antes de que inicie el evento:\n\nCreación de una cuenta en Posit Cloud: Si aún no tienes una, por favor, crea una cuenta gratuita en Posit Cloud."
  },
  {
    "objectID": "archive/2024-02-konrad/index.html#agenda-del-workshop",
    "href": "archive/2024-02-konrad/index.html#agenda-del-workshop",
    "title": "Bienvenidos",
    "section": "Agenda del Workshop",
    "text": "Agenda del Workshop\n\nDía 1\n\nIntroducción a Machine Learning\nProcesamiento de datos\nModelos\nÁrboles de decisión\n\n\n\nDía 2\n\nValidación Cruzada\nRandom Forest\nRegularización\n\n\n\nOrganizadores\n\nFrancisco Cardozo (foc9@miami.edu)\nEric C. Brown\nCarlos Eduardo Montoya\nRafael Cendales"
  },
  {
    "objectID": "archive/2024-02-konrad/index.html#día-1-1",
    "href": "archive/2024-02-konrad/index.html#día-1-1",
    "title": "Bienvenidos",
    "section": "Día 1",
    "text": "Día 1\n\n\nIntroducción a Machine Learning\n\n\nProcesamiento de datos\n\n\nRegresión logística"
  },
  {
    "objectID": "archive/2024-02-konrad/index.html#día-2-1",
    "href": "archive/2024-02-konrad/index.html#día-2-1",
    "title": "Bienvenidos",
    "section": "Día 2",
    "text": "Día 2\n\n\nÁrboles de decisión\n\n\nRandom Forest"
  }
]